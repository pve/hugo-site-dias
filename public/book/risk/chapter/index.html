<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>&#39;Risks of digital infrastructures&#39; | Digital Infrastructures at Scale</title>
<meta name="keywords" content="">
<meta name="description" content="
Risk is the flip side of value. For everything that is of value, there can be circumstances threatening that value.
While value is realized in the past and the present, risk is what can happen with that value in the future.
Risk in a digital world is not always easy to think through. While we can borrow a lot from the real world, certain important differences exist.
At the core of every risk assessment there is the thing we worry about the most: the &lsquo;asset&rsquo;.
In a digital world, this is often the data. Think of business-critical data, like our database of customers. Think of data that we have a compliance obligation on, such as personal data.">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/book/risk/chapter/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.678402628decf506127431a1841c9ce87fb7307134098e3601990b6ba55c49b9.css" integrity="sha256-Z4QCYo3s9QYSdDGhhByc6H&#43;3MHE0CY42AZkLa6VcSbk=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/book/risk/chapter/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script src="https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js" integrity="sha256-pDvBr9RG+cTMZqxd1F0C6NZeJvxTROwO94f4jW3bb54=" crossorigin="anonymous"></script>
<script>
  mermaid.initialize({ 
    startOnLoad: true,
  });
</script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Digital Infrastructures at Scale (Alt + H)">Digital Infrastructures at Scale</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/book/" title="Book">
                    <span>Book</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://www.amazon.com/Digital-Power-Infrastructures-Scale-Value/dp/B0FG1NPWLL" title="Hard copy">
                    <span>Hard copy</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="üîé Search (Alt &#43; /)" accesskey=/>
                    <span>üîé Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;¬ª&nbsp;<a href="http://localhost:1313/book/">Contents</a>&nbsp;¬ª&nbsp;<a href="http://localhost:1313/book/risk/">Risks of digital infrastructures</a></div>
    <h1 class="post-title entry-hint-parent">
      &#39;Risks of digital infrastructures&#39;
    </h1>
    <div class="post-meta">

</div>
  </header> 

  
  <i>‚è≥ 34 min read</i>
  
  <div class="post-content"><hr>
<p>Risk is the flip side of value. For everything that is of value, there can be circumstances threatening that value.
While value is realized in the past and the present, risk is what can happen with that value in the <em>future</em>.</p>
<p>Risk in a digital world is not always easy to think through. While we can borrow a lot from the real world, certain important differences exist.</p>
<p>At the core of every risk assessment there is the thing we worry about the most: the &lsquo;<strong>asset</strong>&rsquo;.
In a digital world, this is often the <strong>data</strong>. Think of business-critical data, like our database of customers. Think of data that we have a compliance obligation on, such as personal data.</p>
<p>In information security, like the name implies, we mainly worry about the data.</p>
<p>It is common to distinguish between <em>availability</em>, <em>confidentiality</em>, and <em>integrity</em> risks. All of these can be risks to the business.</p>
<p>Business processes run on data, and if they are not, they can typically be improved by using more data. We cover that in more detail in another place.</p>
<h3 id="availability">Availability<a hidden class="anchor" aria-hidden="true" href="#availability">#</a></h3>
<p>If the data is not available, the business process can suffer, and its value can be reduced.</p>
<p>Let&rsquo;s have a look at some examples of availability.</p>
<blockquote>
<p>Your mobile phone is dependent on a network.
If the network is unavailable, too far away, or congested, you have an availability problem, and the usefulness of having a phone to communicate drops to zero.</p>
<p>As another example, consider a payment terminal: if it does not work, you cannot pay, and probably will not get what you wanted to buy.</p></blockquote>
<h3 id="confidentiality">Confidentiality<a hidden class="anchor" aria-hidden="true" href="#confidentiality">#</a></h3>
<p>If the data leaks out, the business process can suffer, and its value reduced.</p>
<p>Confidentiality is about keeping data secret. Again, the examples are not too hard to find. There are probably pictures on your phone that you do not want to share with the entire world.</p>
<p>In a business context, you don&rsquo;t want your competitors to know about your plans and pricing strategies.</p>
<h3 id="integrity">Integrity<a hidden class="anchor" aria-hidden="true" href="#integrity">#</a></h3>
<p>If the data does not reflect the reality well enough, the business process can suffer, and its value reduced.</p>
<p>Integrity means that the data is sufficiently accurate, complete, and consistent.</p>
<p>For example, if customer order records are missing, they may not receive their products. Or they are not invoiced.
That is a loss to the business.</p>
<p>Search results (or AI chatbots for that matter) can also lack integrity, for example if they report in a biased way, or leave out important answers.</p>
<p>Integrity is a more fluid concept than the others. What is quality data to somebody may be totally inaccurate for somebody else. Consider social media metrics such as &ldquo;likes&rdquo; and &ldquo;shares.&rdquo; A marketer might see a high number of likes as valuable data indicating effective audience engagement. Meanwhile, a data analyst focused on conversion rates might regard likes as less meaningful, prioritizing click-through data and sales metrics as more accurate indicators of campaign success. Thus, while the &rsquo;likes&rsquo; metric is accurate, its perceived quality and relevance differ based on business goals.</p>
<hr>
<p>Let&rsquo;s dive a little deeper into assets.
The most relevant asset in information security is data.
That is what users of information care about most.
In addition, we can also see the processing power that we need as an asset.</p>
<p>Here are some examples of data assets:</p>
<ul>
<li>A customer record in a business system</li>
<li>An MRI scan</li>
<li>A browser cookie (on the server)</li>
<li>A logfile entry</li>
</ul>
<p>As you can guess from these examples, many involve regulatory concerns due to the type of data that they consist of.
One of the tasks of a risk analyst is to figure out what regulations apply exactly.</p>
<p>From a risk analysis, the asset is the unit that we consider.
ENISA, the European Union Agency for Cybersecurity, is one of the many institutes in the world that describe IT risk management.
Its <a href="https://www.enisa.europa.eu/publications/cloud-computing-risk-assessment">cloud security report</a> identified a number of asset types.
Here are a few examples to illustrate its breadth:</p>
<ul>
<li>A4. Intellectual property, this represents value to the organization owning it.</li>
<li>A6. Personal data</li>
<li>A14. Cloud service management interface</li>
<li>A17. Physical hardware</li>
<li>A22. Security logs</li>
</ul>
<p>But the document is still worth a more in depth study.</p>
<h2 id="vulnerabilities-and-threats">Vulnerabilities and Threats<a hidden class="anchor" aria-hidden="true" href="#vulnerabilities-and-threats">#</a></h2>
<p>Now what could <em>possibly</em> go wrong with a data asset?
Who might see your secret pictures?</p>
<p>Various terms are used to talk about this.</p>
<p>ENISA talks about vulnerabilities as &ldquo;Any circumstance or event with the potential to adversely impact an asset&rdquo;.
It is therefore about the damage potential, not the actual damage.</p>
<p>Microsoft in their framework uses these concepts:</p>
<ul>
<li>Threat. A potential occurrence, malicious or otherwise, that might damage or compromise your assets.</li>
<li>Vulnerability. A weakness in some aspect or feature of a system that makes a threat possible. Vulnerabilities might exist at the network, host, or application levels.</li>
<li>Attack (or exploit, leads to bad consequence). An action taken by someone or something that harms an asset. This could be someone following through on a threat or exploiting a vulnerability.</li>
</ul>
<p>Again, it is about how this leads to damage.
Threats and vulnerabilities are hypothetical, they are about things that have not happened yet.
That is, they have not happened to <em>you</em>. Yet.
And that makes them hard to reason about.
We&rsquo;ll return to that.</p>
<p>Here are some cloud specific examples from the ENISA report</p>
<ul>
<li>V1. AAA vulnerabilities (authentication and authorization, i.e. weak or reused passwords)</li>
<li>V4. Remote access to management interface</li>
<li>V5. Hypervisor vulnerabilities</li>
</ul>
<p>An example of the first one is a weak password like &ldquo;password123&rdquo;, especially if it is used on many accounts.
V4 is about cloud access. In a cloud environment, you don&rsquo;t walk up to your computer, you log in to it remotely, possibly over the internet.
That brings additional vulnerabilities.
Especially since this &lsquo;management interface&rsquo; is not just an account, it is an account that rules other accounts.</p>
<p>Finally, a more technical cloud specific example is the hypervisor.
The hypervisor is a technology for dividing up a physical machine into multiple virtual machines.
Each could serve different customers.
If you are one of those customers, you typically don&rsquo;t want another customer to have access to your data.
The hypervisor is an &lsquo;isolation provider&rsquo;, and it creates isolated &rsquo;execution environments&rsquo; (see elsewhere).
Failure to isolate is therefore a vulnerability.</p>
<h2 id="risk">Risk<a hidden class="anchor" aria-hidden="true" href="#risk">#</a></h2>
<p>Vulnerabilities exist all over the place.
All technology has weaknesses.
But what are the ones that matter?</p>
<p>Most vulnerabilities are not easy to exploit, and they are not necessarily leading to a lot of damage.
For example: while hypervisor vulnerabilities exist, they are really esoteric and hard to exploit.
Most of them have been fixed anyway.
And losing your drivers license as it slips out of your pocket is a nuisance, but not something that ends the world.</p>
<p>What matters is how big the resulting damage can be, and what the chances are that it happens.</p>
<p>As we saw earlier, it is common to distinguish three major sources of damage: lack of availability, lack of integrity, lack or confidentiality.</p>
<p>Each of these hints at a business process in which the information is used.
But it is nothing more than a hint.
Part of the job of a risk analyst is to figure out what kinds of damages can happen in real use cases.
The value of that the damage is called the <em>impact</em>, and mostly relates to events outside the information system.
It happens to another stakeholder.
If in a risk analysis you cannot find a credible stakeholder who is impacted, it is not much of a risk.</p>
<p>As risk is always about the future, it often makes sense to think in terms of probabilities.
One way to quantify risks is to assign them a value based on impact and probability.
The impact of losing the corporate&rsquo;s CRM system is quite a bit larger than that of losing the menu of the company&rsquo;s restaurant.
The probability of somebody losing a password is quite a bit higher than the probability of a major cloud provider going out of business.</p>
<p>The aforementioned ENISA report mentions this formula:</p>
<blockquote>
<p>Risk = Impact * Probability</p></blockquote>
<p>The greater the impact and probability, the higher the total loss.</p>
<p>The ENISA report gives the following example:</p>
<blockquote>
<p>A14. Cloud service management interface
+
V1. AAA vulnerabilities
Leads to
R.11 Management interface compromise</p></blockquote>
<p>What this tries to say is that there exists a thing called the cloud service management interface (e.g. the website that you use to control your cloud account), which has a vulnerability (password too simple, or publishing the secret key to it), which when exploited will lead to a management interface compromise.</p>
<p>The report then describes some of the bad things that can happen as a result of this.
For example, a malicious actor can exfiltrate data, or run a Bitcoin farm.</p>
<p>A final note on probabilities.
Some events are really random, for example the chance of a server breaking down.
The server does not &lsquo;know&rsquo; how valuable the data is that you put on it.
Different brands of servers will have different failure probabilities, and you can do actual math on that to predict when it will be cheaper to replace them versus waiting for them to fail.</p>
<p>Malicious actor events, however, are a little harder to quantify.
Generally speaking you can assume that the chances of a script kiddy attacking you is quite high, that chances of being targeted by organized crime quite a bit lower, and the chances of being targeted by a nation-state actor even lower than that.
But this strongly depends on the value that you as a target represent.
A nation-state actor is not going to waste a very valuable unknown vulnerability on discovering your restaurant menu.
But if your data are the crown jewels of your organization, or give access to national critical infrastructure, the stakes are quite a bit higher.</p>
<p>When you have trouble quantifying probabilities, especially for malicious actor events, I find it useful to review the money and resources that the attacker is willing to spend on you, in addition to your value at risk.
But beware organized crime, their operations are highly automated and well tuned, and you might be cheaper to compromise than you know.</p>
<p>Finally, consider the special category of risks that Nassim Taleb calls &ldquo;Black Swan&rdquo; events, things that are so rare but so disruptive that statistics is hardly useful. Think of stock market crashes, or political revolutions.
How to prepare for those would be a chapter in itself.</p>
<hr>
<p>I have found that no discussion on risk is going to lead anywhere if it does not make clear who suffers from it.
Make clear who has the pain.
For my phone and laptop it is easy: if I lose them, I suffer.
In a larger organization it is less clear.
Suppose a server dies.
Whose application then no longer runs?
Who has to pay for a new server?
This gets increasingly harder if we are talking about shared services, because the owner and the consumer are now decoupled.</p>
<p>A related complication pops up when a failing component or service is remote from the organizations main purpose, or mission.
We see this a lot around software vulnerabilities.
A software vulnerability can allow a malicious actor to fully take over a service.
But unless you demonstrate that:</p>
<ol>
<li>this vulnerability can actually be exploited, and</li>
<li>this exploit can cause damage to the mission</li>
</ol>
<p>it would be a waste of time to address it individually.</p>
<p>If you are involved in risk analysis, make sure to complete the reasoning up to the point where the stakeholder with the budget feels the pain.
To do less is a waste of resources.</p>
<h2 id="external-victims">External victims<a hidden class="anchor" aria-hidden="true" href="#external-victims">#</a></h2>
<p>It gets a little more complicated if those who suffer are not part of the organization that controls that risk.
Example: as a merchant accepting credit card payments of your customers, the customers credit card number helps you get paid.
But if you accidentally disclose it, and it falls in the hands of a bad actor, you don&rsquo;t suffer.
The customer does, or their bank.</p>
<p>From the perspective of the customer, your activity impacts something that is of value to them.
Economists call this an externality, and we see various examples of that in the world of risk, and in digital infrastructures at large.</p>
<p>As the example customer, there is little that you can do about it.
Why the credit card system still works is that banks and credit card issuers have an interest in the system working, and they don&rsquo;t want to saddle either the card holder or themselves with these losses.</p>
<p>They have the pain, and their response has been to create a mandatory certification scheme for everybody who touches a credit card number.
You cannot process a credit card, and definitely not at scale, without being PCI/DSS certified.
This is enforced by contract.
If you can&rsquo;t abide, you can&rsquo;t process credit cards, which may be important to you.
This is how they make the credit cards processors suffer.
It is an industry regulation.</p>
<p>Similarly, personal data loss is a risk to the person, not to the organization that collects your personal data.
That is why there are privacy regulations, of which the EU GDPR (General Data Protection Regulation) is the most well-known.</p>
<p>These aren&rsquo;t industry regulations, they are the law.
And if you don&rsquo;t follow the law, countries can fine you.
Unfortunately, as I mention elsewhere, money is a blunt instrument.
So while privacy laws work, they are not a perfect solution.</p>
<p>Summing up, this leads to a new category of risk: compliance risk.
If you do not comply with regulations, whether they are industry or government, you will suffer the pain.</p>
<hr>
<h2 id="controls">Controls<a hidden class="anchor" aria-hidden="true" href="#controls">#</a></h2>
<p>Microsoft: Countermeasure (or control). A safeguard that addresses a threat and mitigates risk.</p>
<p>To be continued.</p>
<p>what other assets?</p>
<p>Where did that file go?
Where did you leave that address?
Who changed your password?</p>
<p>Once we have assets and risks identified, we think of ways to minimize these risks.
Those ways are called controls or measures.
If you have read through an IT risk management book, many of these should be familiar.
For the rest of you, here is a brief outline of some control examples for data.</p>
<ul>
<li>Classification: organizing data in various categories. This could from public to top secret, with a few in between. This is not really a technical control, but rather a means to apply specific controls on that data.</li>
<li>Labelling: similar to classification. Data labels can relate data to specific use cases, such as development versus production, specific applications or owners.</li>
</ul>
<p>One neat way to organize risks is according to a data lifecycle model.</p>
<ul>
<li>Create: classify, label</li>
<li>Store: encryption</li>
<li>Use: logical controls</li>
<li>Share: DLP, encryption</li>
<li>Archive: asset management</li>
<li>Destroy: crypto shredding (encrypting and deleting the key)</li>
</ul>
<hr>
<p>walk in with well spelled out risks, a clear connection to business impact, data, a mitigation plan, and measurable targets.</p>
<p>Providing third-party assurance enables the board to deliver on its risk management responsibilities.</p>
<hr>
<p>While Artificial Intelligence, especially the generative type, is a highly disruptive form of IT innovation, its risk management still follows the same basic principles.
We just need to extend those principles to new forms of data and software.</p>
<ul>
<li>What are the assets?</li>
<li>What are the vulnerabilities and threats to it?</li>
<li>What is the damage that this can bring, realistically?</li>
</ul>
<p>So let&rsquo;s see how what the AI specifics are.</p>
<h2 id="ai-assets">AI Assets<a hidden class="anchor" aria-hidden="true" href="#ai-assets">#</a></h2>
<p>Let&rsquo;s focus on the AI assets that are the product of deep learning.
Deep learning neural networks have represented a shift in AI technology.
Before that, symbolic AI was more common.</p>
<p>The reason to elaborate on this is that there is a fundamental difference between symbolic AI and neural network AI.
Symbolic AI works by following programmatic rules, and is fairly deterministic.
Neural networks are the result of training with large datasets.
They have enabled <em>generative AI</em> which is much less deterministic.</p>
<p>Furthermore, and this is really significant from a security perspective, in its operation, GenAI mixes data and instruction to operate on that data deeply.</p>
<p>For example, anything an external user inputs to the system as data, might also be interpreted as an instruction.
This represents a huge vulnerability for hackers to exploit.</p>
<p>The trained models represent a lot of information, and that information is often hard to identify, and therefore to see the classic information risks of.</p>
<p>Models are effectively software: you stick data in them, and data comes out.
But because they also embody a lot of data (we are talking Gigabytes, Terabytes and beyond of training data) they combine the risks of software with the risks of data.</p>
<p>An AI system has a few more traditional and less traditional data assets associated with it.
Base models, or foundational models, such as Llama, often get additional training or finetuning.
The data used for that may well include proprietary or sensitive data.</p>
<p>Then there are system prompts and additional data sources that are fed into those models, together with user input.</p>
<h2 id="ai-vulnerabilities">AI Vulnerabilities<a hidden class="anchor" aria-hidden="true" href="#ai-vulnerabilities">#</a></h2>
<h2 id="damage">Damage<a hidden class="anchor" aria-hidden="true" href="#damage">#</a></h2>
<hr>
<p>Trust is an essential element in any collaboration.
We want to trust things, people, and organizations to do the right thing, to keep their promises.
Without trust, we will not be able to have confidence in the contribution of others, and that is a risk.</p>
<p>Anything we don&rsquo;t trust is a risk.
Anytime we assume trust that is not warranted is also a risk.
That is one of the core concepts of Zero Trust Security Architecture.</p>
<p>Trust can also be something that is fairly technical, as in: can I trust the webserver to be up all the time?</p>
<p>Trust is an elusive concept, but I do have a couple of ways of looking at it that I have found very useful, because they work in the real world.
One is from &ldquo;the Prisoner&rsquo;s Dilemma,&rdquo; which is a story from game theory.
Another is &ldquo;authority,&rdquo; which is basically &ldquo;I trust somebody, because somebody tells me so&rdquo;.</p>
<hr>
<p>From the moment a security vulnerability is discovered, it represents a negative value to its potential victims.
When it gets exploited, it can lead to loss of data or loss of integrity of the data.
This in turn impacts the victim&rsquo;s business processes.</p>
<p>For example, if personal data is leaked, reputations will be damaged, financial losses and fines can be expected. Credit card abuse forms another example of loss.</p>
<p>This &ldquo;damage potential&rdquo; increases as the vulnerability becomes well-known, progressing from nation state actors, to organized crime, to script kiddies, just to name one example pathway.
At first, few people know about it, but gradually more people will be able to inflict damage with it.
Over time, each step adds to the likelihood of that vulnerability being exploited and causing real damage.
The likelihood starts at near zero, and ends at close to 100% as the vulnerability is completely public.
This only stops when an investment is made to mitigate the vulnerability, for example by updating the software.
And hopefully, that investment is less costly than the damage potential.</p>
<p>This damage potential resembles the concept of &ldquo;work in progress&rdquo; from lean production.
Originally developed as the &ldquo;Toyota Production System&rdquo;, it is also applied to software development.</p>
<p>For example, if your team spends three months with five staff members on building a feature, the work in progress is now valued at fifteen man-months.
That is an investment, which you will only recover once the feature is delivered and accepted.
Only then will you be paid for it, hopefully reflecting more value than you put in as an investment.
The mantra of lean production is to reduce work in progress.
Work in progress represents a liability: it is capital tied up, and maybe it won&rsquo;t bear fruit.
For example, your new piece of software may solve the wrong problem.
This is why entrepreneurs love the idea of a minimum viable product, it reduces work in progress.
You want to drop bad ideas as fast as possible.</p>
<p>Back to vulnerabilities:</p>
<p>The longer you wait with mitigating a vulnerability, the more negative value it accrues.
Fixing it represents an investment, which hopefully has a positive return.</p>
<p>There is a parallel with software development.
In software development, the net value drops as more money is poured into development, which then returns to positive as the feature is delivered and paid for (figuratively speaking).
In cyber security, the net value drops as the vulnerability is accessible to more threat actors, which then returns to zero after an investment is made into its mitigation.
Hopefully the cost of mitigation is less than the net value (i.e. damage potential) at that time.</p>
<p>This may sound pretty abstract, but I think I will be able to show the usefulness of this approach.
It helps us identify where and how investments are most productive in cyber security.</p>
<p>At any given moment in time, a stream of new vulnerabilities is thrown at cyber defenders around the world.
For example, in 2024 around 40.000 vulnerabilities were published in the CVE database (<a href="https://www.cve.org/about/Metrics">source</a>).
Without additional information, all of these carry a negative value to an organization, as all of them have damage potential.</p>
<p>What investments can reduce the damage potential, and more importantly, which of these have the best return on investment?</p>
<p>Let&rsquo;s start at the beginning.
If you can match vulnerabilities to the software you have, you&rsquo;ll find a lot of them are not relevant as they relate to software you don&rsquo;t have.
A proper and accessible software inventory therefore represents an investment that can reduce the total negative value of vulnerabilities.</p>
<blockquote>
<p>Case in point: log4j affected a quarter of the world&rsquo;s organizations.
So, without more information, your organization had a 25% chance of being pretty vulnerable.
But, if you knew that this software was not in use anywhere, your vulnerability dropped to zero.</p></blockquote>
<p>Then, fast forward through the value chain.
How can we reduce the negative value of a vulnerability?
One way is to reduce the damage potential through segmentation and similar Zero Trust techniques.</p>
<p>In a future extension of this unit, we can discuss:</p>
<ul>
<li>actor analysis: we have two types of actors here: malicious actors and potential victims, but there are more actors</li>
<li>self inflicted vulnerabilities such as misconfigurations</li>
<li>the value streams for malicious actors</li>
<li>the value stream for security researchers</li>
<li>the value streams for security service providers</li>
<li>why Zero Trust reduces the negative value of a vulnerability.</li>
</ul>
<hr>
<p>Zero Trust Architecture is an approach to better cybersecurity. To many, it seems daunting to implement. But it does not have to be hard to start.</p>
<p>Consider this hypothetical situation.</p>
<p>You have an application with hundreds of thousands of sensitive records, let‚Äôs say client records. We assume that in this example it seems hard to implement MFA (Multi Factor Authentication) on it. What other controls can you implement to reduce the assumed trust? We can use the Kipling method, which is at the core of Zero Trust architectures, to engineer better controls. In short, the Kipling method is about the &lsquo;who&rsquo;, &lsquo;what&rsquo;, &lsquo;when&rsquo;, etcetera of allowed communication.</p>
<pre class="mermaid">flowchart TD
    subgraph exec[&#34;Execution Environment&#34;]
        app[(App)]
    end
    
    users[Cloud Users]
    fw[Firewall]
    
    users --&gt; fw
    fw --&gt; app
</pre>
<p>We want to allow specific access for specific use cases and be explicit about it. However, to focus our efforts, it makes sense to also identify that our biggest risk is the exfiltration of a lot of those sensitive records: a data breach.</p>
<h3 id="the-allow-rules">The allow rules<a hidden class="anchor" aria-hidden="true" href="#the-allow-rules">#</a></h3>
<p>Let‚Äôs begin with the ‚Äòwho.‚Äô Who is accessing the information? The application in our example probably does authentication and authorization of users. Where do these come from, and how accurate is that information? Ideally, this comes from an up-to-date corporate directory, but even if it‚Äôs not, you can, for example, ask how quickly a departing user has their access revoked.</p>
<p>Then the ‚Äòwhat‚Äô. Which application and resources are we accessing? What are specific users allowed to do? As part of operational risk management, we have probably already identified who, based on their role, can modify records or do other critical actions. But think one step further. As our main fear is exfiltration of large amounts of data, we can look at where we can control that. Maybe we can disallow large downloads, for example, except when a timely ‚Äòfour eyes‚Äô approval is in place.</p>
<p>(By the way, I think it makes sense to look at large downloads as a risk separate from small data leaks. After all, many employees have access to small amounts of information, and that risk is typically already accepted).</p>
<p>Moving on to the ‚Äòwhen‚Äô. It can reduce risk to limit access to specific times of the day for most users. There is not necessarily a reason to allow more.</p>
<p>Next is the ‚Äòwhere‚Äô. Where are the users and the application located? Our case description does not give us a lot of information here. The application could be a server, which then has an IP address. And through a firewall combined with a geographical information feed, we may be able to restrict access to users based on their location.</p>
<p>The ‚Äòwhy‚Äô stands for the business reason. In this case, our data is sensitive, and we don‚Äôt want it to be exfiltrated. And in our analysis, we have identified several possible controls.</p>
<p>How: One layer of enforcement of this would be in the application itself. In the Zero Trust jargon, we are putting a Policy Enforcement Point in the application logic.</p>
<h3 id="the-mirror-allow-rule">The mirror allow rule<a hidden class="anchor" aria-hidden="true" href="#the-mirror-allow-rule">#</a></h3>
<p>However, there is also another set of ‚Äòallow rules‚Äô that is often overlooked. I am tempted to call these the ‚Äòmirror‚Äô rules, but it is not a standard Zero Trust term.</p>
<p>The data and the application reside in a compute environment, for example a server. There may be malware running in that server. After all, one of the tenets of Zero Trust is ‚Äòassume breach‚Äô. If the server has permission to access anything on the internet, that malware might easily exfiltrate large amounts of data.</p>
<p>In addition to looking at the user accessing the data, we are looking at the place where the data resides and see if its compute environment can access the world, and thus exfiltrate data. This is the mirror image of the first rule: you could say that subject and target are switched around.</p>
<p>We can apply the same Kipling method from the perspective of that server (or any compute environment that has the data in it). What is it allowed to do?</p>
<p>The ‚Äòwho‚Äô then is the server, and there are various ways to identify it, depending on how it is set up and how we want to control what it can do. It can be an IP address or domain name, for example.</p>
<p>What can the server access? The more limited that is, the better. It should probably be capable of logging somewhere, but it needs only limited DNS and internet access. There are likely to be integrations with other systems, but these should be enumerated and controlled.</p>
<p>When can the server initiate contact? This seems less relevant to restrict, because logging and many integrations can be operational at any time.</p>
<p>Why is this access needed? As said earlier, any compute environment must be able to connect to certain other services for its functional operation. Yet that does not imply that it needs broad uncontrolled network access. And there are known cases of abusing overly permissive egress.</p>
<p>How can this rule be enforced? One way would be at the outer perimeter of the network, although it is also conceivable to do it through a dedicated firewall or a (network) security group in a cloud environment.</p>
<h3 id="what-is-the-benefit-here">What is the benefit here?<a hidden class="anchor" aria-hidden="true" href="#what-is-the-benefit-here">#</a></h3>
<p>In this example we have looked at a specific case of data that we want to protect. The Zero Trust approach and the Kipling method led us to various options that we have. These options allow us to hammer out implicit trust in an existing application.</p>
<p>The nice thing is that we can rate and rank these options based on their effectiveness, cost, and feasibility, all while focusing on one specific strategic asset that we want to protect. This is in stark contrast to a traditional approach where you start with strengthening the perimeter and just hope that this will have an impact on the one application that you want to protect first.</p>
<p>And we all know: hope is not a strategy.</p>
<h3 id="implication-for-maturity">Implication for maturity<a hidden class="anchor" aria-hidden="true" href="#implication-for-maturity">#</a></h3>
<p>What we can also illustrate with this story is that, even though we can start with an individual application, many of these controls will become better and cheaper if there is some maturity and shared services in the organization. Reliable user identities are helped by proper federated identity management. Fine grained network access rules are easier to do if there is more software defined networking.</p>
<p>Maturity is an investment, and it pays off in cheaper, faster and better security. That is another tradeoff that this example illustrates.</p>
<p>For more information on Zero Trust, visit <a href="https://cczt.clubcloudcomputing.com">https://cczt.clubcloudcomputing.com</a></p>
<p>Also published at <a href="https://www.linkedin.com/pulse/retrofitting-zero-trust-existing-application-peter-hj-van-eijk-zjpte">https://www.linkedin.com/pulse/retrofitting-zero-trust-existing-application-peter-hj-van-eijk-zjpte</a></p>
<hr>
<p>(First public draft)</p>
<p>Imagine that you are part of the government of an average nation, and you have just realized that IT has become a substantial factor in your operation.
Or you have a similar position in a manufacturing industry, or in the financial sector.
As IT increased in volume, you have tried to keep its costs down, it was just a facility.
Outsourcing to more experienced partners was an option, and so was the use of cloud computing, for example for your Office applications.</p>
<p>Now you realize that IT is not just a cost, but that it is also existentially important to your business.</p>
<p>No IT means no business.</p>
<p>This is no longer about cost. It is about survival.</p>
<p>The geopolitical situation and the oligopolistic dominance of big tech are creating a massive challenge.
In the west, we are talking about the US government and the three big hyperscalers. In the east, it is China and their big companies.
All these actors have demonstrated that they can and will exert their influence in a way that can be counter to the interest of IT consumers.</p>
<p>Cloud computing has aggravated the situation.
Where vendor lock-in was already an issue in the early days of computing, most companies could operate independently from their vendors for a while.
In a cloud world, service can stop from one minute to another.</p>
<p>Hence the call for more sovereignty and autonomy.</p>
<p>Sovereignty and autonomy sound nice, and appeal to core human values.
But they are problematic: they are ill-defined, and unattainable in the absolute sense.
On a global level, there are very few countries, if any, that have no dependence on any other country.
So no country is fully sovereign and autonomous.
In my opinion, the most important objective is to reduce the negative effects of that dependence.</p>
<p>In this unit I want to develop a framework for structuring the conversation around business resilience, which I think is the umbrella concept here.</p>
<p>I propose to start with a risk based approach, focussing on the supply chain.
We start by identifying the threats that the call for sovereignty and autonomy is supposed to address.</p>
<p>For example, a nation state order might force a cloud provider to cease operations for a specific customer in a different country.
This leads to an availability risk for that customer.
In this case, they cannot access their email anymore.</p>
<p>The next questions are: what is the bad consequence of that, what are the chances that it happens, and how quick can we reduce the impact of that?</p>
<p>All this is fairly standard risk management procedure.
But for this conversation I suggest to specifically look at the following.</p>
<ul>
<li>What do people mean when they talk about the need for more sovereignty and autonomy?</li>
<li>What are the risks that derive from having a geographically distributed IT supply chain?</li>
<li>What are, in detail, the components of that supply chain? For example, there is a difference between the location of a datacenter, the software that runs in it, and control over the operations of that hardware and software.</li>
<li>How can nation state actors and corporations exert power that is counter to sovereignty and autonomy?</li>
<li>What are the mitigations that cloud providers propose? How tenable are they?</li>
<li>What are mitigations, technical and political, that are applicable for cloud consumers and regulators?</li>
<li>In particular, what alternative sources for IT assets and services exist?</li>
<li>What residual risks do these have? For example, building a large single service provider company has the risk that it will be acquired by a multinational under foreign control. This has happened.</li>
</ul>
<p>I suspect we will also find out that many of the risks and mitigations are not technical, not even legal, but (geo)political.
To fully analyze those, we will need people with these skills.
Understanding the essentials of this technology can be challenging for experts in politics or law.
And, by the way, that is one of the reasons why I have taken up writing <a href="https://digitalinfrastructures.nl">Digital Infrastructures at Scale</a>.</p>
<hr>
<p>Where do you start your IT security journey?
It is important, but it can be confusing.</p>
<p>For many organizations, the trigger is a compliance obligation to show that confidential information remains confidential.
Maybe their customers are asking for an ISO/IEC 27001 certification, demonstrating that an IT risk management system is in place.
Maybe they are handling credit cards and therefore need to worry about compliance to PCI DSS.</p>
<h2 id="controls-1">Controls<a hidden class="anchor" aria-hidden="true" href="#controls-1">#</a></h2>
<p>The common theme in these is that they are <em>control</em> based.
The process is that you realize compliance by implementing a set of controls, such as defining a password policy, or implementing a type of firewall.</p>
<p>There are many positive elements to this approach, especially if it promotes a structured management approach.</p>
<p>The downside of this approach is that not all controls are equally relevant in a given situation.
It also lends itself to a &lsquo;box-ticking&rsquo; approach, where controls are implemented only in a superficial way, and their actual effectiveness remains unclear.</p>
<h2 id="threats">Threats<a hidden class="anchor" aria-hidden="true" href="#threats">#</a></h2>
<p>In the security community, the topic of the day is what the most current <em>threat</em> is.
Money and effort are spent on investigating the latest threats, and discussing how they can be averted.
Every day a seemingly endless stream of new vulnerabilities is discovered, each and every one having the potential to endanger all sensitive data that an organization has.</p>
<p>This can be a relevant approach.
After all, many vulnerabilities have actual exploits associated with them.
Yet, exploitable does not imply that actual damage is imminent.
A server that is hacked but has no valuable data or relevant connectivity does not result in any significant actual damage to the organization.</p>
<h2 id="data">Data<a hidden class="anchor" aria-hidden="true" href="#data">#</a></h2>
<p>A third approach is more strategic, and focuses on the value at risk: the data.
This is the core of the Zero Trust approach: start with one important data set at a time.
That set is isolated, and by tracing where that data is allowed to flow, access to that data can be controlled by a variety of techniques.
While there are a number of described approaches to Zero Trust, including the CCZT (Certificate of Competence in Zero Trust) by the Cloud Security Alliance, there is little guidance on how to implement it within specific technologies.</p>
<h2 id="how-good-are-these">How good are these?<a hidden class="anchor" aria-hidden="true" href="#how-good-are-these">#</a></h2>
<p>The control based approach is top-down, starting with policies, working your way down.
From a management perspective, setting up a system for overseeing IT risk management promises that eventually all risks will be treated.</p>
<p>However, control frameworks can be big.
The CSA Cloud Controls Matrix contains more than 100 controls.
These controls are also quite high-level, and translating them into more  system and technology specific language is hard.
The result is risk management progress that is forever &lsquo;half&rsquo; finished, with unknown gaps.
Or worse, continued effort is spent on rewording the policies to make them more detailed, but never getting specific.
Nevertheless, regulators love this approach, because it speaks to the senior management and board members who need to take responsibility.</p>
<p>The threat based approach is more bottom-up.
Starting with the technologies in place, relevant threats are identified and prioritized.
Often, these are very technical, and need technology specific expertise to be evaluated.
Overlooking just one threat can be disastrous.
As is often said: defenders have to defend everything, attackers need only one path in.</p>
<p>This approach is the one practitioners take, if they have no other way to prioritize their efforts.
Though it sounds cynical, security vendors love this approach because it is an easier sell: the dangers are clear to explain.</p>
<p>The data based approach is inside-out, so to say.
Identifying the most important data deep inside allows to build out layered defenses.
Zero Trust calls this the &lsquo;protect surface&rsquo; as opposed to the &lsquo;attack surface&rsquo;.
As said, the problem with this approach is not knowing where to start, and not understanding how to scale up.</p>
<p>I have seen a few maturity assessments, and while the capabilities differ across organizations, a common theme is insufficient data governance.
And that makes it hard to guide the efforts on the technology side.</p>
<p>Another pitfall of Zero Trust is to get stuck in not trusting anything, so where do you start with trust?
Or, in scaling up, get twisted into &lsquo;implement two factor authentication everywhere&rsquo;, which is neither necessary nor sufficient.</p>
<h2 id="synthesis">Synthesis<a hidden class="anchor" aria-hidden="true" href="#synthesis">#</a></h2>
<p>In the end, these three approaches need to be merged, as they all bring relevant perspectives.</p>
<p>Start with a top down inventory of the most strategic data.
That allows to focus the other approaches and maximizes the risk reduced per invested effort.
Zooming in on the most important data, relevant controls can then be applied there, while identifying the technology that is used.
This helps to more selectively filter the vulnerabilities that have to be taken seriously.</p>
<p>For example, if the most important data is stored in a MySQL database on a Linux system with a single sign on system, only vulnerabilities in those technologies need to be taken into account.</p>
<p>It requires a common perspective on the value of data, that is a bit more nuanced than &rsquo;everything is important&rsquo;.</p>
<p>It also requires a nuanced perspective on risk tolerance in IT.
For example, to an IT security professional leaking an individual record is as bad as leaking the entire database.
After all, if an attacker can access one record, they can access them all, is the thinking.
But from a company risk perspective they are not the same.
Individual record leakage is already an accepted risk, just think of insider threats.
The loss of an entire database is a compliance event, with completely different consequences.
With that background, rate limiting of data exports now becomes one of the relevant controls.</p>
<p>This is the type of common ground that is required for truly effective <em>and</em> efficient IT risk management.</p>
<p>But this requires a fundamentally different dialogue between the business process owners, risk assessors, and technical practitioners.</p>
<p>For starters, it requires that conversations are driven, not by a fear of doing the wrong thing, but by a desire to do the right thing.</p>
<hr>
<p>For people who care about risk in IT, compliance is a mixed blessing.
Compliance regulations can lead to better risk management, but sometimes it is more of a hindrance than a help.</p>
<p>Compliance in IT generally means compliance with regulations that are set up to reduce risk, for example, across a chain of actors.
A great example is the PCI/DSS regulation, which governs everybody who touches a credit card transaction.
The objective of this regulation is to protect card holders and card issuers from credit card fraud.
The reason why the regulation exists in the first place is because negligence at one actor can lead to damages at another actor.</p>
<p>For example, it is not in the merchant&rsquo;s primary interest to keep customer credit card numbers secure.
Keeping that data secure involves work.
The merchant&rsquo;s prime interest is in getting paid, not in spending more money on security than absolutely necessary.</p>
<p>The customers, however, really would like their credit card to be safe, because it is them who bear the fraud risk.
Actions by the merchant, or lack thereof, are an &rsquo;externality&rsquo;, as economists say.</p>
<p>Compliance regulations are a way to force risk management on, in this case, the merchant.</p>
<p>A similar pattern can be seen in privacy regulations.
Personal data disclosure is primarily a risk to the individual involved, not to the organization that holds that data.
Regulations on data privacy, such as the EU GDPR (General Data Protection Regulation), force risk management on the storing of personal data upon a lot of organizations.</p>
<p>Compliance on IT risk management is also becoming a national security issue.
The EU NIS2 (Network and Information Systems) Directive forces critical infrastructure providers, such as telecom and electricity companies to be resilient.
This is because our society is more and more dependent on these infrastructure providers.
Even if these infrastructure providers are not digital infrastructure providers, they need IT to operate.
The threat landscape is also changing, with nation-state actors actively targeting these critical infrastructures.</p>
<p>As a side note, in the early 2000s I was part of a governmental working group investigating these critical infrastructure risks (or vital infrastructures, as we called them).
Our research showed that there were many dependencies between them, but that they all depended on electricity.
This highlights the need for critical infrastructure protection.</p>
<p>While all these initiatives help, compliance does not imply security.
Even if compliance is treated as more than a &lsquo;box-ticking&rsquo; exercise, there are many documented cases of compliant organizations being breached.</p>
<p>Target was PCI DSS compliant in 2013, yet more than 40 million card numbers were stolen.</p>
<p>Equifax was ISO27001 certified in 2017, yet more than 140 million people&rsquo;s personal data were exposed.</p>
<p>Being secure does not automatically mean that you are compliant.</p>
<p>But being compliant can be hard, especially with conflicting or ambiguous government regulations.
For example, GDPR requires adequate protection of personal data.
It requires that protection explicitly when that data is processed outside the EU.
Legally, there have been a number of instruments for this protection deemed to be adequate when personal data is processed at e.g. a US cloud provider (though the situation is by no means US-EU specific).
There have equally been many arguments that the US government still has control over such data, which would make it illegal to process personal data at a US provider.
As an example consider the EU‚ÄìUS Privacy Shield (2016‚Äì2020), which was struck down in the Schrems II (CJEU 2020) ruling.</p>
<p>Every control, be it technical, managerial, or legal, involves interpretation, trade-offs, and residual uncertainty.
Regulators, auditors, or courts may later disagree with your choices.</p>
<p>In the end this means that being compliant also involves a risk decision: you accept the risk that you are not fully compliant, in the same way that you accept the risk that you are not fully secure.</p>
<hr>


  </div>
  




  

  

  

  

  

  

  

  

  

  

  

  

  
    <nav class="book-nav" style="display: flex; justify-content: space-between; margin-top: 2rem;">
      
        
        <a href="/book/risk/uneasy-compliance-risk/">&larr; Compliance is a Risk</a>
      
      
    </nav>
  



  
  <script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ startOnLoad: true });
  </script>
  

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Digital Infrastructures at Scale</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
