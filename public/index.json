[{"content":"Risk is the flip side of value. For everything that is of value, there can be circumstances threatening that value. While value is realized in the past and the present, risk is what can happen with that value in the future.\nRisk in a digital world is not always easy to think through. While we can borrow a lot from the real world, certain important differences exist.\nAt the core of every risk assessment there is the thing we worry about the most: the \u0026lsquo;asset\u0026rsquo;. In a digital world, this is often the data. Think of business-critical data, like our database of customers. Think of data that we have a compliance obligation on, such as personal data.\nIn information security, like the name implies, we mainly worry about the data.\nIt is common to distinguish between availability, confidentiality, and integrity risks. All of these can be risks to the business.\nBusiness processes run on data, and if they are not, they can typically be improved by using more data. We cover that in more detail in another place.\nAvailability If the data is not available, the business process can suffer, and its value can be reduced.\nLet\u0026rsquo;s have a look at some examples of availability.\nYour mobile phone is dependent on a network. If the network is unavailable, too far away, or congested, you have an availability problem, and the usefulness of having a phone to communicate drops to zero.\nAs another example, consider a payment terminal: if it does not work, you cannot pay, and probably will not get what you wanted to buy.\nConfidentiality If the data leaks out, the business process can suffer, and its value reduced.\nConfidentiality is about keeping data secret. Again, the examples are not too hard to find. There are probably pictures on your phone that you do not want to share with the entire world.\nIn a business context, you don\u0026rsquo;t want your competitors to know about your plans and pricing strategies.\nIntegrity If the data does not reflect the reality well enough, the business process can suffer, and its value reduced.\nIntegrity means that the data is sufficiently accurate, complete, and consistent.\nFor example, if customer order records are missing, they may not receive their products. Or they are not invoiced. That is a loss to the business.\nSearch results (or AI chatbots for that matter) can also lack integrity, for example if they report in a biased way, or leave out important answers.\nIntegrity is a more fluid concept than the others. What is quality data to somebody may be totally inaccurate for somebody else. Consider social media metrics such as \u0026ldquo;likes\u0026rdquo; and \u0026ldquo;shares.\u0026rdquo; A marketer might see a high number of likes as valuable data indicating effective audience engagement. Meanwhile, a data analyst focused on conversion rates might regard likes as less meaningful, prioritizing click-through data and sales metrics as more accurate indicators of campaign success. Thus, while the \u0026rsquo;likes\u0026rsquo; metric is accurate, its perceived quality and relevance differ based on business goals.\n","permalink":"/book/risk/intro-to-risk/","title":"Introduction to Risk"},{"content":"Let\u0026rsquo;s dive a little deeper into assets. The most relevant asset in information security is data. That is what users of information care about most. In addition, we can also see the processing power that we need as an asset.\nHere are some examples of data assets:\nA customer record in a business system An MRI scan A browser cookie (on the server) A logfile entry As you can guess from these examples, many involve regulatory concerns due to the type of data that they consist of. One of the tasks of a risk analyst is to figure out what regulations apply exactly.\nFrom a risk analysis, the asset is the unit that we consider. ENISA, the European Union Agency for Cybersecurity, is one of the many institutes in the world that describe IT risk management. Its cloud security report identified a number of asset types. Here are a few examples to illustrate its breadth:\nA4. Intellectual property, this represents value to the organization owning it. A6. Personal data A14. Cloud service management interface A17. Physical hardware A22. Security logs But the document is still worth a more in depth study.\nVulnerabilities and Threats Now what could possibly go wrong with a data asset? Who might see your secret pictures?\nVarious terms are used to talk about this.\nENISA talks about vulnerabilities as \u0026ldquo;Any circumstance or event with the potential to adversely impact an asset\u0026rdquo;. It is therefore about the damage potential, not the actual damage.\nMicrosoft in their framework uses these concepts:\nThreat. A potential occurrence, malicious or otherwise, that might damage or compromise your assets. Vulnerability. A weakness in some aspect or feature of a system that makes a threat possible. Vulnerabilities might exist at the network, host, or application levels. Attack (or exploit, leads to bad consequence). An action taken by someone or something that harms an asset. This could be someone following through on a threat or exploiting a vulnerability. Again, it is about how this leads to damage. Threats and vulnerabilities are hypothetical, they are about things that have not happened yet. That is, they have not happened to you. Yet. And that makes them hard to reason about. We\u0026rsquo;ll return to that.\nHere are some cloud specific examples from the ENISA report\nV1. AAA vulnerabilities (authentication and authorization, i.e. weak or reused passwords) V4. Remote access to management interface V5. Hypervisor vulnerabilities An example of the first one is a weak password like \u0026ldquo;password123\u0026rdquo;, especially if it is used on many accounts. V4 is about cloud access. In a cloud environment, you don\u0026rsquo;t walk up to your computer, you log in to it remotely, possibly over the internet. That brings additional vulnerabilities. Especially since this \u0026lsquo;management interface\u0026rsquo; is not just an account, it is an account that rules other accounts.\nFinally, a more technical cloud specific example is the hypervisor. The hypervisor is a technology for dividing up a physical machine into multiple virtual machines. Each could serve different customers. If you are one of those customers, you typically don\u0026rsquo;t want another customer to have access to your data. The hypervisor is an \u0026lsquo;isolation provider\u0026rsquo;, and it creates isolated \u0026rsquo;execution environments\u0026rsquo; (see elsewhere). Failure to isolate is therefore a vulnerability.\nRisk Vulnerabilities exist all over the place. All technology has weaknesses. But what are the ones that matter?\nMost vulnerabilities are not easy to exploit, and they are not necessarily leading to a lot of damage. For example: while hypervisor vulnerabilities exist, they are really esoteric and hard to exploit. Most of them have been fixed anyway. And losing your drivers license as it slips out of your pocket is a nuisance, but not something that ends the world.\nWhat matters is how big the resulting damage can be, and what the chances are that it happens.\nAs we saw earlier, it is common to distinguish three major sources of damage: lack of availability, lack of integrity, lack or confidentiality.\nEach of these hints at a business process in which the information is used. But it is nothing more than a hint. Part of the job of a risk analyst is to figure out what kinds of damages can happen in real use cases. The value of that the damage is called the impact, and mostly relates to events outside the information system. It happens to another stakeholder. If in a risk analysis you cannot find a credible stakeholder who is impacted, it is not much of a risk.\nAs risk is always about the future, it often makes sense to think in terms of probabilities. One way to quantify risks is to assign them a value based on impact and probability. The impact of losing the corporate\u0026rsquo;s CRM system is quite a bit larger than that of losing the menu of the company\u0026rsquo;s restaurant. The probability of somebody losing a password is quite a bit higher than the probability of a major cloud provider going out of business.\nThe aforementioned ENISA report mentions this formula:\nRisk = Impact * Probability\nThe greater the impact and probability, the higher the total loss.\nThe ENISA report gives the following example:\nA14. Cloud service management interface + V1. AAA vulnerabilities Leads to R.11 Management interface compromise\nWhat this tries to say is that there exists a thing called the cloud service management interface (e.g. the website that you use to control your cloud account), which has a vulnerability (password too simple, or publishing the secret key to it), which when exploited will lead to a management interface compromise.\nThe report then describes some of the bad things that can happen as a result of this. For example, a malicious actor can exfiltrate data, or run a Bitcoin farm.\nA final note on probabilities. Some events are really random, for example the chance of a server breaking down. The server does not \u0026lsquo;know\u0026rsquo; how valuable the data is that you put on it. Different brands of servers will have different failure probabilities, and you can do actual math on that to predict when it will be cheaper to replace them versus waiting for them to fail.\nMalicious actor events, however, are a little harder to quantify. Generally speaking you can assume that the chances of a script kiddy attacking you is quite high, that chances of being targeted by organized crime quite a bit lower, and the chances of being targeted by a nation-state actor even lower than that. But this strongly depends on the value that you as a target represent. A nation-state actor is not going to waste a very valuable unknown vulnerability on discovering your restaurant menu. But if your data are the crown jewels of your organization, or give access to national critical infrastructure, the stakes are quite a bit higher.\nWhen you have trouble quantifying probabilities, especially for malicious actor events, I find it useful to review the money and resources that the attacker is willing to spend on you, in addition to your value at risk. But beware organized crime, their operations are highly automated and well tuned, and you might be cheaper to compromise than you know.\nFinally, consider the special category of risks that Nassim Taleb calls \u0026ldquo;Black Swan\u0026rdquo; events, things that are so rare but so disruptive that statistics is hardly useful. Think of stock market crashes, or political revolutions. How to prepare for those would be a chapter in itself.\n","permalink":"/book/risk/assets/","title":"Information Security Assets"},{"content":"It all starts with bits: digital units of information. It is about how we store these bits, how we move these bits, and how we transform or process these bits.\nThe three major elements of digital infrastructures are:\nStorage Networks Processors In the cloud security world, it is customary to talk about data at rest, data in motion, and data in use. This introduces data as the key common element. But more on cloud security later.\nAll of these elements have a wide variety of different manifestations, with associated quality and performance attributes that matter enormously in the design and management of digital infrastructures.\nYou\u0026rsquo;ll also have to understand that these three concepts are very entangled. A storage system is connected to a network, but it also has network and processing elements inside. The same is true for the other two concepts. Once again, it is a way to draw maps of digital systems, and any map is inaccurate. As said elsewhere, this inaccuracy actually can make it a good map! It reduces complexity so that we can more easily think about it.\nSpeaking of maps, a variety of diagrams is used in the field of IT. I\u0026rsquo;d like to gently expose you some of those diagram types.\nThe link between the digital elements is, in its simplest form, often depicted as follows:\nblock-beta in space env:2 space out in[\u0026#34;Input\u0026#34;] --\u0026gt; env[\u0026#34;Processor\u0026#34;] env--\u0026gt; out[\u0026#34;Output\u0026#34;] style in fill:#fff,color:#000,line:#000;stroke-width:0px,color:#000,stroke-dasharray: 5 5 style out fill:#fff,color:#000,line:#000;stroke-width:0px,color:#000,stroke-dasharray: 5 5 A few comments on what this does, and does not show:\ninput is data, which is transformed into output, also data the diagram does not show if this is a one-off activity, or a stream of events, we need a time-sequence diagram for that there is no explicit mention of any \u0026lsquo;state\u0026rsquo; or \u0026lsquo;persistent data\u0026rsquo; inside the processing. We will see later how this simple model is adequate to describe a vast variety of data processing tasks. A very simple example is adding two numbers. The input is formed by the two numbers, and the output it their sum. An AI example might be the input a voice recording, and output a file with the transcribed conversation.\nIn an interactive world, it is more common to have the output returned to the source of the input. The following diagram illustrates that.\nsequenceDiagram User-\u0026gt;\u0026gt;Processor: Here is my input Processor-\u0026gt;\u0026gt;User: Here is the output A common example would be to send as input a question to a search engine, where the search results are the output. The vertical lines are timelines that show from top to bottom how time flows, and what the sequence of interactions is. That is why we call these time sequence diagrams (TSD).\n","permalink":"/book/diginfra/elements-of-digitalinfrastructures/","title":"Elements of the Digital World"},{"content":"After coding a demo application with Claude Flow it was time to do a larger project.\nClaude Flow has an impressive set of features, supporting a very innovative approach to the agentic software development. But even after a few projects, I still find it hard to grasp the subtleties and intricacies of its various agents, components and options.\nSo I decided to stop worrying and just dive in, while documenting the successes and edge cases. This time my application is a tool to run batches of prompts through various models. The primary use case is to analyze service descriptions against risk and control frameworks. The core step is to give an LLM a question to answer with a lot of specific background, such as those service descriptions and frameworks.\nWe want this tool to help us review variations in the prompts, in the background information, the models, etcetera. Most of the relevant text is tens of thousands of characters long, though the prompt is smaller. So how do you run these evaluations? While there are excellent LLM evaluation tools, I kind of got lost in the weeds reviewing them.\nInstead, I decided to just prompt Claude Flow to create it.\nBy the way, those service descriptions are about LLM applications, so we are now talking about AI on three levels: the application under analysis, the analysis of its risks, and the generation of software to support in that process.\nInits So, how do we get started running this?\nWith agentic systems like these running around, I prefer to have a \u0026lsquo;devcontainer\u0026rsquo; to run Claude in. Based on a couple of examples, I am now using this one.\nCopy this to an empty directory, inside that run git init for version control, and commit the first addition (the devcontainer). You may want to later publish this repository to e.g. GitHub.\nThe next step I did is to initialize Claude and Claude Flow, inside Visual Studio Code:\n#claude --dangerously-skip-permissions // #init.. (notes in bujo p 62) #Is this necessary? npm install -g better-sqlite3 npx claude-flow@2.7.1 init --force This sets up claude, and ends in a claude prompt. Just quit it.\nNow it is time to get specific.\nI collected about 45 lines of notes on what I wanted the tool to be. In my experience, the important elements of that description are:\nFunctionality and the intentions behind that, e.g. what bigger context is this going to be used in. Focus on MVP, don\u0026rsquo;t overdo the functionality. You will find that the coding assistants are eager enough to give you lots of suggestions. Tech stack, in particular the development environment. Deployment target, in this case just a local python program To use test driven design (TDD) I fed this into Claude asking for the open ends in this specification. It responded with a few questions for clarifications, such as level of sophistication in handling errors. I answered those, and had it update the specification.\nIn my review of it I simplified a few things even more. For example, it had added some additional input parameters that could be postponed to a later version.\nI stored the 437-line result as a specification (original version in git).\nThe next step then simply is to run:\nnpx claude-flow@alpha hive-mind spawn \u0026#34;design an application based on parallaxr-spec.md\u0026#34; --claude I told it to plan building the program, but it went ahead and delivered a working version in half an hour or so. It included a feature to run a demo, which worked immediately after I had configured an LLM key.\nThe command above runs its course, and then shows the claude code prompt. While I have used that situation to make minor changes, the hive-mind allows us to end that session, and start a new one with just enough context to proceed.\nOK, it works, now what? Once you have a piece of software working, a sign of success is that you want more features. The workflow I used for that runs through GitHub issues. The hive-mind we are using preserves a lot of information on the project across Claude sessions, though I am still trying to figure out what information exactly. We can therefore start each issue on a new session. The command line then simply becomes, for example:\nnpx claude-flow@alpha hive-mind spawn \u0026#34;implement git issue 21\u0026#34; --claude Git issues are not stored locally, but on GitHub, and Claude Flow accesses them by using the gh command. (A minor snag can be that this needs to be authorized before Claude Flow can use it.)\nI noticed some inconsistency in behavior when it comes to closing issues. Sometimes it would go all the way, and sometimes it would just commit and not even push to the registry. It also needed to be prodded to apply semantic versioning.\nThe root cause of this may be that I did not sufficiently specify the behavior I wanted. In such cases the coding assistant falls back to whatever seems to be the typical thing to do, according to its training. But there are diverging practices out there, which is reflected in the inconsistencies I observed.\nI\u0026rsquo;ll need to rethink the approach to acceptance testing and rollback procedures, and then spell it out. For example, where do we do various levels of testing? In this case, the program is planned to be used locally only, so there really is not much point in forcing the commit to a repository. If, however, the production and acceptance versions are publicly deployed through a CI/CD pipeline, we will need to include that in the testing loop, and feed the results back to the LLM.\nThe exact opinionated workflow could be specified in the Claude.md file, but it may be a good use case to introduce an additional, well-tooled, agent for that.\nI also, partly for the fun of it, asked for a refactoring plan. This plan also exceeded my expectations, it was detailed and relevant.\n","permalink":"/posts/claude-flow-parallamr/","title":"How Claude Flow helped me create my next tool"},{"content":"Whenever we need a new piece of software, big or small, there are a few alternative roads to follow. They include:\nBuy the software Use some SaaS, paid or freemium Use an open source solution Build it yourself This is true for individuals as well as large corporations, and for stuff that you spend less than 10 minutes thinking about up to projects that take hundreds of man-years to complete.\nSpoiler alert: none of these is guaranteed to be cheaper than any of the others.\nFor a small example, think of software to find duplicated files on your hard disk, which you need to get back some space.\nA large example would be a hospital information system. In this case, though I witnessed several variations of it, acquiring and implementing this software took many man-years. Every week for a few months, 50 people would come together for a full day to detail out how to work with the software. On the go-live day, just the company selling the software had about 100 staff on-site.\nEach of the alternative ways of acquiring software has its own costs and benefits. Briefly:\nBuying (or licensing) software costs money, but also time to select the right product. Once purchased, more money typically has to be paid to the vendor for keeping the software up to date. Using SaaS also requires a selection process, and while there is less capital involved in it, the total cost of ownership may be higher. Open source software does not have licensing cost, but maintaining it typically requires manpower, more manpower than buying or renting the software from others. Build it yourself requires deeper design than any of the other approaches, as well as a lot of manpower for building it. Another dynamic to consider is where the initiative to get the software comes from. On one end of the spectrum there is an individual who starts this for themselves, or together with a few direct colleagues. On the other end of the spectrum is a board level decision to roll out something across the entire organization. The hospital system I mentioned is an example of that, as are many other ERP systems.\nAcross the spectrum you see different technology approaches, pricing strategies, and vendor sales tactics.\nInnovation Many innovative projects start out as individual initiatives. Some of these are actively encouraged by leadership, others are tacitly allowed if leadership can plausibly deny they did so. Some companies have active search and destroy missions for these types of projects. I am not here to judge which of these strategies should be followed. Let\u0026rsquo;s just accept that this is typically called shadow IT, or shadow cloud.\nThese grassroots projects, as they are often called, don\u0026rsquo;t have a lot of options when it comes to acquiring software. They lack support and budget. But the people in these projects are close to where the real application and benefit is.\n","permalink":"/posts/selecting-software/","title":"Selecting Software"},{"content":"Agentic swarm coding feels like the next big thing.\nWhile I had success with claude-swarm in a small proof of concept (link), I struggled to understand in more detail how it work.\nQuick recall, here is what I did:\nnpx claude-flow@alpha init --force npx claude-flow@alpha hive-mind spawn \u0026#34;Create a simple single player web page where the user can play tic-tac-toe against the computer\u0026#34; --claude With this, Claude starts doing the work. Approximately 20 minutes later, it produced a solution that worked at the first attempt!\nBut, how does this scale?\nThere are quite a few design or process decisions that you need to make early on. As a beginner in claude-swarm I felt a bit lost.\nThis time around I took a more considered approach.\nAs suggested by some members of the claude-swarm community, I downloaded the whole package and asked Claude to explain it to me. For good measure I also ran it in a devcontainer (official one by Claude Code).\nReading through the CLAUDE.md that comes with claude-swarm, the first thing that I wanted to deeper understand is the SPARC methodology, or more specifically, why you want to select any of the SPARC modes.\nSo I asked claude code in the claude-swarm directory.\nThe SPARC commands are failing due to missing commander dependency in the CLI execution path.\nnpx claude-flow sparc modes\nif you run this inside the command line of claude code, with dangerous permissions, it will autofix this. SPARC configuration file (.roomodes) not found\nPlease ensure .roomodes file exists in: /workspace\nFixed.\nThe first answer Choose based on your current development phase:\n🎯 Choose by Development Stage:\n• spec - Starting a new feature/project, need to define requirements • architect - Have requirements, need to design system structure• tdd - Ready to implement with test-first approach • integration - Components built, need to connect them • refactor - Existing code needs improvement/optimization\n📋 Choose by Task Type:\n• Planning/Analysis → spec • System Design → architect • New Development → tdd • Connecting Parts → integration • Improving Code → refactor\n🔄 Typical Flow: spec → architect → tdd → integration → refactor\nQuick Decision:\nDon\u0026rsquo;t know what to build? → spec Know what, not how? → architect Ready to code? → tdd Code exists, needs connecting? → integration Code works, needs improvement? → refactor plan B, or put it to the test. https://claude-flow.ruv.io has a quickstart.\nnpx claude-flow@alpha init --force suggested. so let\u0026rsquo;s run that in the command line.\nNow what? It says something quite different:\nQuick Start:\nView available commands: ls .claude/commands/ Start a swarm: npx claude-flow@alpha swarm \u0026ldquo;your objective\u0026rdquo; \u0026ndash;claude Use hive-mind: npx claude-flow@alpha hive-mind spawn \u0026ldquo;command\u0026rdquo; \u0026ndash;claude Use MCP tools in Claude Code for enhanced coordination Initialize first swarm: npx claude-flow@alpha hive-mind init Do I run this in the shell or in claude code?\nAgain, I asked its code base about it.\nClaude: They Can Work Together:\n1. Use SPARC for planning npx claude-flow sparc spec \u0026ldquo;E-commerce platform\u0026rdquo;\n2. Use swarm for execution npx claude-flow@alpha swarm init hierarchical npx claude-flow@alpha swarm orchestrate \u0026ldquo;Build the spec\u0026rsquo;d platform\u0026rdquo;\nChoose Based On:\nSimple feature → SPARC Complex system → Swarm Learning/planning → SPARC first Production development → Swarm OK, but what is the difference between Swarm and hive?\nHive Mind = Advanced Multi-Agent Collective Intelligence\nComplexity Hierarchy: SPARC (Single) \u0026lt; Swarm (Multi) \u0026lt; Hive (Collective Intelligence)\n🐝 When Hive is Necessary:\nCross-session memory - Agents remember past decisions Collective learning - Patterns improve over time Autonomous coordination - Agents self-organize without central control Complex problem-solving - Emergent intelligence from agent interaction Long-term projects - Persistent knowledge across multiple sessions ⚡ When Hive is Overkill:\nSimple CRUD applications Single-feature development Short-term tasks (\u0026lt; 1 week) Personal projects Learning/prototyping 🎯 Decision Matrix:\nScenario Use \u0026ldquo;Build a login form\u0026rdquo; SPARC \u0026ldquo;Build an e-commerce site\u0026rdquo; Swarm \u0026ldquo;Build a distributed AI platform that learns and evolves\u0026rdquo; Hive \u0026ldquo;Debug this function\u0026rdquo; SPARC \u0026ldquo;Migrate entire codebase to new framework\u0026rdquo; Swarm \u0026ldquo;Create self-improving development workflow\u0026rdquo; Hive 🚀 Start Simple, Scale Up:\nTry SPARC first If too complex → Swarm If you need persistent intelligence → Hive Quick Test: Do you need agents to remember and learn from previous sessions? If no → Skip Hive.\nSo, when would that be? Here is what claude says about that.\nSession End Triggers:\nAutomatic Ends:\nClaude Code restart - You close/reopen the IDE Terminal session closes - SSH disconnect, laptop sleep, etc. Process termination - Ctrl+C, system shutdown Memory limits reached - Long conversations hit token limits Inactivity timeout - Extended periods without interaction Manual Ends:\nUser exits - /exit command or explicit termination Task completion - Agent finishes and saves state Context switch - Moving to different project/directory Deliberate reset - Starting fresh workflow Why Sessions Matter:\nWithout Persistent Memory: Session 1: \u0026ldquo;Use TypeScript strict mode\u0026rdquo; Session 2: Agent suggests JavaScript again 🤦‍♂️\nWith Persistent Memory: Session 1: \u0026ldquo;Use TypeScript strict mode\u0026rdquo; → saved Session 2: Agent remembers → \u0026ldquo;Continuing with TypeScript strict mode\u0026rdquo;\nSession Lifecycle:\nSession starts npx claude-flow start\nWork happens, memory accumulates Agent learns patterns, stores decisions\nSession ends (any reason above) npx claude-flow hooks session-end \u0026ndash;export-metrics\nNext session starts npx claude-flow hooks session-restore \u0026ndash;session-id \u0026ldquo;previous\u0026rdquo; Agent: \u0026ldquo;I remember we were using React hooks pattern\u0026hellip;\u0026rdquo;\nReal Example:\nMonday: Build auth system, decide on JWT approach Tuesday: Claude Code crashes/restarts Wednesday: Agent remembers JWT decision, doesn\u0026rsquo;t suggest sessions again The memory bridges the gaps between interruptions.\nthe set of agents.. claude flow, or the user, sets up a number of agents to run. Who decides on that, and why would you want more or less of them?\n● 🎛️ Agent Count Decision Makers:\nUser (Manual Control): You specify exact count npx claude-flow@alpha swarm init mesh \u0026ndash;max-agents 5 npx claude-flow@alpha swarm spawn researcher npx claude-flow@alpha swarm spawn coder\netc\u0026hellip; up to your limit System (Auto-scaling): System decides based on task complexity npx claude-flow@alpha swarm orchestrate \u0026ldquo;Build full-stack app\u0026rdquo;\nSystem: \u0026ldquo;This needs 6 agents: frontend, backend, database, testing, devops, security\u0026rdquo; Configuration Defaults: // In CLAUDE.md or .claude/config.json { \u0026ldquo;swarm\u0026rdquo;: { \u0026ldquo;defaultMaxAgents\u0026rdquo;: 8, \u0026ldquo;autoScale\u0026rdquo;: true, \u0026ldquo;topology\u0026rdquo;: \u0026ldquo;mesh\u0026rdquo; } } 🤖 Auto-Spawning Logic:\nTask Complexity Analysis:\nSimple task → 1-2 agents Medium task → 3-5 agents Complex task → 6-10+ agents Example Auto-Decisions: \u0026ldquo;Fix this bug\u0026rdquo; → 2 agents (coder + tester) \u0026ldquo;Build authentication\u0026rdquo; → 4 agents (coder, security, tester, docs) \u0026ldquo;Create microservices platform\u0026rdquo; → 8+ agents (architect, multiple coders, devops, security, etc.)\n🧠 Hive Intelligence:\nHive can spawn agents autonomously Hive: \u0026ldquo;I need a database specialist for this PostgreSQL optimization\u0026rdquo;\nAutomatically spawns database-specialist agent Resource Limits:\nCPU/Memory constraints Token usage limits Performance thresholds You control the ceiling, system optimizes within it.\nwhat is with the neural training and WASM? ● 🧠 Neural Training + WASM = Performance-Optimized AI Learning\nWhat It Does:\nNeural Training: Agents learn patterns from your codebase/workflow WASM: WebAssembly acceleration for faster neural computations SIMD: Single Instruction Multiple Data for parallel processing 🚀 Performance Stack: Neural Patterns (AI Learning) ↓ WASM Runtime (Fast Execution) ↓ SIMD Instructions (Parallel Math) ↓ 2.8-4.4x Speed Improvement\nWhen to Use:\nNeural Training:\nAgents learn your coding patterns npx claude-flow neural train \u0026ndash;pattern coordination npx claude-flow neural train \u0026ndash;pattern optimization\nExample learning: Agent notices: \u0026ldquo;User always uses async/await, never .then()\u0026rdquo; Agent adapts: Future code suggestions use async/await\nWASM Acceleration:\nEnable for computationally heavy tasks npx claude-flow wasm optimize \u0026ndash;operation \u0026ldquo;large-codebase-analysis\u0026rdquo; npx claude-flow wasm optimize \u0026ndash;operation \u0026ldquo;multi-file-refactoring\u0026rdquo;\n🎯 Use Cases:\nEnable Neural Training When:\nWorking on large codebases (\u0026gt;1000 files) Repetitive patterns in your code Long-term projects (\u0026gt;1 month) Team with consistent coding standards Enable WASM When:\nSlow performance with multiple agents Complex analysis tasks Large file processing Real-time coordination needed 🔧 Setup:\nCheck if WASM/SIMD available npx claude-flow features detect \u0026ndash;category wasm\nEnable neural training npx claude-flow neural status npx claude-flow neural train \u0026ndash;iterations 50\nMonitor performance npx claude-flow benchmark run \u0026ndash;type neural\n💡 Skip If:\nSmall projects (\u0026lt;100 files) Short-term tasks Simple CRUD operations Learning/experimentation TL;DR: Neural+WASM = Agents get smarter and faster over time. Use for production-scale development.\n\u0026ndash;claude ● 🎯 The \u0026ndash;claude flag in hive-mind commands:\nPurpose: Claude Code Integration Mode\nnpx claude-flow@alpha hive-mind spawn researcher \u0026ndash;claude\nWhat \u0026ndash;claude Does:\nSpawns agent INSIDE Claude Code environment (not external process) Uses Claude Code\u0026rsquo;s Task tool for actual execution Integrates with Claude Code\u0026rsquo;s file system and tools Leverages Claude Code\u0026rsquo;s permissions and security model Without \u0026ndash;claude: npx claude-flow@alpha hive-mind spawn researcher\nCreates external process agent Runs independently of Claude Code Limited file system access With \u0026ndash;claude: npx claude-flow@alpha hive-mind spawn researcher \u0026ndash;claude\nAgent runs via Claude Code\u0026rsquo;s Task tool Full integration with IDE Can use Read, Write, Edit, Bash tools Part of Claude Code\u0026rsquo;s orchestration Real Difference:\nExternal agent (no \u0026ndash;claude) Agent: \u0026ldquo;I can\u0026rsquo;t access your files directly\u0026rdquo;\nClaude Code integrated agent (\u0026ndash;claude) Agent: \u0026ldquo;I can read package.json, edit src/app.js, run npm test\u0026rdquo;\nWhen to Use \u0026ndash;claude:\nWorking inside Claude Code IDE Need file system access Want integrated development workflow Using Claude Code\u0026rsquo;s tools/permissions When to Skip \u0026ndash;claude:\nRunning in pure terminal Headless/server environments External automation scripts TL;DR: \u0026ndash;claude = \u0026ldquo;Run this agent inside Claude Code, not as external process\u0026rdquo;\ndon\u0026rsquo;t add \u0026ndash;claude to SPARC commands.\nthe current workflow - NOT clone a devcontainer environment (e.g. from vscode clone a template repo)\nremove redundant files\ngit init ; git remote remove\nnpx claude-flow@alpha init \u0026ndash;force\nnpx claude-flow@alpha sparc spec \u0026ldquo;read parallaxr.md for input\u0026rdquo;\nnpx claude-flow@latest init \u0026ndash;sparc npx claude-flow sparc spec \u0026ldquo;read parallaxr.md for input\u0026rdquo;\nNO:- you may want to add @alpha to claude-flow\nlets try npx claude-flow@latest init \u0026ndash;sparc \u0026ndash;force npx claude-flow sparc modes npx claude-flow sparc spec \u0026ldquo;read parallaxr.md for input\u0026rdquo;\nNO: still runs into .roomodes errors Nieuwste versie heeft geen .roomode meer, en geen SPEC meer?\nTry 2 hive mind - no SPEC For survival across session breaks, use Hive-Mind with persistent memory:\nSetup for Cross-Session Persistence:\n1. Initialize hive-mind (creates persistent database) npx claude-flow@alpha hive-mind init\n2. Spawn agents with persistence enabled npx claude-flow@alpha hive-mind spawn researcher \u0026ndash;claude \u0026ndash;enable-memory npx claude-flow@alpha hive-mind spawn architect \u0026ndash;claude \u0026ndash;enable-memory\n(hier ergens gaat het al met claude praten en bouwen) Gaat compleet over de top met de CICD strategy.\n3. Store your project context permanently npx claude-flow@alpha memory persist \u0026ndash;session-id \u0026ldquo;parallaxr-project\u0026rdquo; npx claude-flow@alpha memory store \u0026ldquo;project_files\u0026rdquo; \u0026ldquo;parallaxr.md\u0026rdquo; npx claude-flow@alpha memory store \u0026ldquo;project_goal\u0026rdquo; \u0026ldquo;create specification from parallaxr.md\u0026rdquo;\n4. Create persistent workflow npx claude-flow@alpha hive-mind workflow create \u0026ldquo;parallaxr-spec\u0026rdquo; \u0026ndash;name \u0026ldquo;ParallaxR Specification Analysis\u0026rdquo; \u0026ndash;persistence true\nstill a bit confused about this. ","permalink":"/posts/claude-swarm-deep/","title":"Claude Swarm Deep"},{"content":"How can you use cloud security lessons to better secure AI? This is what is keeping some of my clients busy recently.\nArguably the most important concept in cloud security is the allocation of responsibilities across the independent actors that contribute to any digital service. Often referred to as \u0026lsquo;shared responsibility\u0026rsquo;, this is about \u0026lsquo;who does what?\u0026rsquo;. For example, in an IaaS service model, the provider does the physical security of servers, offers a variety of network isolation options, and so forth. The IaaS consumer\u0026rsquo;s job is to use those features to, for example, organize logical server access, so only authorized access is permitted. In contrast, many mistakenly think it is the provider\u0026rsquo;s job to secure and update the operating system. It is not, in an IaaS model, it is the consumer\u0026rsquo;s job.\nMany security tasks can be delegated to trusted parties, provided you have proof or evidence of their proper execution.\nAs we move up the stack to PaaS and SaaS offerings, the responsibility matrix can become a bit more blurred, and more attention is required to the details.\nAI services are no different, they are typically cloud services, too. After all, AI is just somebody\u0026rsquo;s data on somebody\u0026rsquo;s computer.\nThe AI supply chain is a bit more complex than that of a simple web application. The Cloud Security Alliance recently developed an AI version of their Cloud Controls Matrix. It is called AICM (for AI Control Matrix), and one of its interesting features is a list of roles. The AICM distinguishes the AI consumer, Application Provider, Orchestrated Services Provider, Model Provider, and Cloud Service Provider. You\u0026rsquo;ll find my discussion of those roles elsewhere.\nWith that list of roles, as described in AICM, we can then allocate security responsibilities to specific actors. But first, we need a set of controls that we want actors to take responsibility for.\nThere is no lack of risk and control frameworks for AI. Right now I am experimenting with the OWASP Top 10 for Large Language Model Applications. Inside it, I identified 87 controls, which I mapped to the roles I described earlier.\nWhile this is preliminary research, and I am validating this with clients, you can already preview it. Navigate to my OLRA (OWASP LLM Risk Allocation) Navigator. It lets you interactively explore the mapped controls along various dimensions, and see how they relate to different roles. This offers insight into AI-specific risk management.\nLooking forward to your thoughts on this!\n","permalink":"/posts/cloud-sec-ai/","title":"Cloud Security and AI"},{"content":"Your IT security vendor wants you to be scared.\nThere.\nI said it.\nI scared you about being scared.\nBut that is not how I want to talk to you. I want to enable you to make better decisions faster, and I believe that better understanding of the essentials helps. This allows you to act from a position of autonomy, which is one of my values.\nIn the history of IT security, unfortunately, fear, uncertainty, and doubt (FUD) have always been effective sales tactics. And it is no different in the world of AI.\nThe reason is clear.\nIt is in how people think. Daniel Kahneman talks about two systems of thought: fast and slow. The fast one is more emotional, and quick to respond to fear. The slow one is more cognitive, and takes its time to think the situation through.\nThe first one helps you to survive, the second one helps you to develop and grow.\nBut, in IT security as in politics, if you do not make a conscious effort to deploy system two to a situation, the first system will win, even if it does not provide the best long term result. In many fields, professionals are trained, even drilled, to use the second system when a crisis arises. Think healthcare emergency responders, airline pilots, and combat soldiers.\nThat is my challenge in writing about IT and IT security: I am not very good at scaring you. Instead, I am doing my best to make your system two as effective as possible. That is why my book Digital Power is chock full of usable concepts.\nBut you need to turn your system two on to get results. So I am trying to scare your system one into doing that.\n","permalink":"/posts/scare-fud/","title":"Scare, FUD, and thought systems"},{"content":"Testing RSS\n","permalink":"/blog/newblog/","title":"Testing RSS updates"},{"content":"Applications based on LLMs (Large Language Models) have risks too. The OWASP Top 10 for LLM Applications risks are a good start for analyzing the risks of such a system.\nThese types of applications, like many others, are also cloud applications. This means that there is a variety of parties responsible for controlling those risks.\nBut, who is supposed to do each control? And which role do they have? For example, there are model providers, there is the AI consumer, and so on. For a deeper story on these roles look at AI roles.\nCombining those AI roles with the OWASP Top 10, gives us a list of more than 80 controls, by role.\nYou can review these controls with the OLRA Navigator.\nIt is about allocation of risks and their controls to roles, and that is why this tool is called the OLRA navigator. OLRA stands for OWASP LLM Risk Allocation. It allows you to select them by role and category.\n","permalink":"/projects/olra/olra/","title":"OWASP LLM Risk Allocation"},{"content":"My AI coding journey continues.\nMy first version of the Tic-Tac-Toe game took some time to get right even though I already applied some serious automated top-down design.\nAs explained, understanding feedback loops is crucial for correcting errors. Part of this is using explicit tests for desirable outcomes. A process for test-driven design would be even better.\nThe main question from that experience was: How can we let the AI check itself?\nThis is what agentic-coding, or swarm coding, is all about, and there are a couple of approaches to that.\nI found the most impressive system to be Claude-flow. The core idea is to have multiple dedicated agents work in parallel and check each other. For example, you want the tester to be a separate agent from the coder.\nClaude-flow has a lot of features and agents, which can feel a bit overwhelming. Despite its complexity, getting started was easy.\nHere is what I did:\nnpx claude-flow@alpha init --force npx claude-flow@alpha hive-mind spawn \u0026#34;Create a simple single player web page where the user can play tic-tac-toe against the computer\u0026#34; --claude With this, Claude starts doing the work. Approximately 20 minutes later, it produced a solution that worked at the first attempt!\nA couple of observations.\nIt created a single static HTML page solution, in contrast to the more complicated front-end back-end solution that the earlier approach resulted in. I did not look at a single line of code. It still over-engineered it a bit by including a human-to-human mode, which was not requested. I found it impressive that the solution worked immediately. While the absence of a back-end simplifies matters, the swarm\u0026rsquo;s ability to generate a test set likely drives this success.\nIt is clear to me that it no longer makes sense to try and write software at this level of complexity entirely by myself.\nI also did some experiments at a higher level of architectural complexity, and those did not all go very smoothly. AI coding assistants tend to be overly creative, leading to a codebase or deployment architecture that irrecoverably goes off the rails.\nMy expectation is that more agents are required, with more embedded specialized knowledge, to stay on track. That is the next step in the journey.\n","permalink":"/posts/claude-flow-ttt/","title":"Agentic coding, the next level"},{"content":"For the book, here is the link: https://digitalinfrastructures.nl.\nPDF: How to bluff your way into Zero Trust\nPDF: Using deployment diagrams to explain architecture and security to everybody.\nThe presentations are also online in the WHY2025 YouTube channel and at the CCC.\nMore on deployment diagrams in the book, in which you can search.\nFind me on LinkedIN or Mastodon @petersgriddle@fosstodon.org.\n","permalink":"/posts/why2025/","title":"Why 2025 resources"},{"content":"Taking it for a spin.\nAfter my playful tic-tac-toe app (blog post, the actual app) I moved on to create a real application.\nI restarted the experiments I did earlier (https://digitalinfrastructures.nl/posts/monkey-coding/) Real app now. track 1. claude-flow.\nbiggest lesson: understand nested feedback loops.\nmethod: learning from myself (DRY in prompting)\ndont hesitate to start all over.\nchallenge: explaining to claude code what a good result is, and the means to check that. gh will help\ntarget is to get to production MVP as fast as possible, prioritizing short feedback loops.\nquota problemen en compacting maakt nog al eens dat het geheugen kwijt raakt.\n│ \u0026gt; you should ALWAYS validate passing. If you can\u0026rsquo;t fix it yourself, escalate to user. Tips: the production server\u0026rsquo;s IP address is in git secret │ │ HETZNER_HOST. Deployment at the server should also include a git pull. And the deploy scripts seem to be hiding errors for you.\nPriority is end 2 end testing, then refactor and clean up. All before you run out of quota\u0026hellip;\n","permalink":"/posts/real-app-with-ai/","title":"Real App With Ai"},{"content":"Here is how I AI-coded a fully functional Tic-Tac-Toe web game without looking at a single line of code or manually identifying a GUI or logic error. I ran Claude Code (Pro) in VS Code without any other IDE/AI tooling.\nBut it takes some effort and discipline to get there. The core idea is to be very specific and use an opinionated environment that includes extensive automated testing.\nThe Agentic AI way Many people are researching this, all with slightly different approaches. There are a variety of ways to do more or less the same thing. Here are some of the interesting approaches I found. Interestingly, they all popped up in the first half of 2025.\nCole Medin Github IndyDevDan Home page Ryan Carson Github Sean Matthew YouTube The simplest is Sean Matthew\u0026rsquo;s, and while it works, you can add some precision and handy workflow items and shortcuts from the others. Again, there are often a variety of ways of doing more or less the same thing.\nI\u0026rsquo;d start like this.\ncreate a directory for your codebase run Claude in your editor (e.g. VS Code) inside Claude, run /init, this will also create a CLAUDE.md, which you probably want to adapt or override, see later. run git init, and publish the folder to your git account edit, establish or copy a CLAUDE.md, I have curated a 350 line opinionated version, which is adapted to this type of project You could now start with your feature, as I will describe in a moment. I chose to have it create the simplest application that would result in an actually running web page with all the test scaffolding that I requested in my CLAUDE.md, which is quite extensive and not application-specific.\nThis created 1180 lines of Python for what is effectively a \u0026lsquo;Hello world!\u0026rsquo; application.\nRequirements Now it\u0026rsquo;s time to get your Product Requirements Document (PRD). Starting from a small prompt you ask the AI to expand it to a PRD. I put the feature description in a file called tictactoe.md.\nCreate a simple single player web page where the user can play tic-tac-toe against the computer\nThe smallest prompt then is:\nHelp me create a PRD for the feature in tictactoe.md, respecting the standards in CLAUDE.md, store it in file PRD-tictactoe.md\nThe other approaches mentioned above have a more extensive prompt to create the PRD, which presumably gives a more structured specification document, but this one works surprisingly well. In this example, the PRD is over 300 lines long. It has a variety of components, such as a set of user stories, but it also repeats a lot of information from the CLAUDE.md file. Allegedly, it pays to review and repeat this process to make sure you are not wasting time later.\nPlanning The next steps are to translate this in a PLANNING and TASKS file. The latter one will be edited by the AI to record progress. Again, you can have a simple prompt to create these, or a more sophisticated one. For this experiment I took the shortest one. All these documents have some overlap.\nThen it is showtime!\nPlease read PLANNING.md, CLAUDE.md, and TASKS.md to understand the project. Then complete the first task on TASKS.md or pick up where we left.\nOff to the races\u0026hellip;\nClaude Code chugs along nicely for a while. Because we have instructed it to create test cases for each and everything, it will backtrack automatically and fix all errors until all tests pass. This resulted in one commit and a locally working application.\nWe are now outside of the feedback loop of fixing the misunderstandings, shortcomings, and hallucinations of Claude Code.\nIn the end, this resulted in 1900 lines of Python for the core application, and more than 3200 lines of code for testing. I touched none of them.\nWhile this line count sounds big, understand that this includes a lot of monitoring and security features. There is also extensive commenting in the code, and it would be interesting to see if we could refactor this to make it much shorter.\nNext level Next, the opinionated prompt calls for a CI/CD pipeline. While the AI created one, including a full test suite, it failed for a variety of reasons, though many had to do with a mismatch between the local environment and the environment that the pipeline runs in.\nIn the beginning, I was part of the feedback loop, so I screenshotted the Git Actions log and pasted these in Claude Code (really!). I later installed gh, allowing the AI to actually see the error messages. With this it could iterate until it was done. Again, we are now outside that feedback loop.\nThe final lesson The final lesson here is that as a developer / software engineer, you will mainly be involved in fixing things where you are part of the feedback loop. Your job should therefore be to engineer the AI into the loop, and yourself out of the loop.\nYou really don\u0026rsquo;t want to babysit the AI for each error that it is perfectly capable of fixing itself.\nThe main techniques for that are:\ngiving the AI clear objectives (e.g. 90% test coverage) giving the AI information to see if those objectives are met (e.g. proper error messages and log files). I am calling this method \u0026lsquo;Closed Loop Coding\u0026rsquo;, because we are closing the feedback loop inside the AI assistant itself.\nIn short, AI amplifies your capabilities, but if you don\u0026rsquo;t have the high-level objectives clear, it can backfire, and you will end up in a rabbit hole.\n","permalink":"/posts/ai-nocode/","title":"AI Coding: \"Look Ma, no hands!\""},{"content":"The approach People call LLMs statistical completion engines and that they therefore cannot write computer code. While the first may be true, the conclusion not necessarily follows.\nMy answer to this question: let\u0026rsquo;s try this out! Inspired by modern discoveries in, for example, context engineering and swarm coding (references to come) I decided to give AI assisted coding a shot.\nI had a little used SaaS application (an LMS) that was nevertheless costing serious money. Yet, completely killing it was not an option. It was relatively easy to extract the Gigabytes of content in there, also through a bit of AI assistance. So I decided to rebuild the app, or at least a minimal version of it. Of many options, I selected Claude as my coding assistant.\nI started out by adopting the prompt and repository structure by Cole Medin. I fed Claude with the first prompt of that approach, and a bit of the structure of the backup of the SaaS application, and asked it to create the initial feature request. With just a few lines of text, plus the data structures, Claude created a multi page feature list, sorted by priority. Quite nice. It even did an ASCII mockup of the GUI.\nFollowing the steps in Cole\u0026rsquo;s method, Claude Code started ticking off tasks and building code. At first, it moved nicely, regularly asking me for certain permissions or decisions. The interval between those was sometimes several minutes, so I quickly decided to introduce some audio feedback using the MacBook say text command, whenever the AI stopped for user interaction.\nIt ran into a couple of errors, but most were fixed immediately.\nThen it became time to look at the GUI to see if it actually worked. There were some errors and mistakes in them, so I reflected that back to Claud Code. It dutifully tried to fix them. Some of the fixes worked, some of them did not.\nThen it started to feel that for every fix, a new issue appeared in the user interface, and the coding assistant dutifully attempted fixes, with very limited results.\nWe were going down a rabbit hole.\nThe sting What is going on here?\nThe thing is, I had become part of a feedback loop involving the assistant and me on the implementation of small features. It gave me results, I commented on those results. While doing that, I am no longer a part of the solution, I have become part of the problem.\nAnd the problem is that I was interacting with the LLM on the wrong level.\nI was fixing code, I was not fixing the requirements and the methods. And while I am fixing the code, I am doing their job. Based on the error messages, the AI is typically quite capable of fixing the errors.\nI should be working on the requirements, such as clearly specifying required outcomes that can be independently verified by the coding assistant. I should be working on the methods, such as how the coding assistant can verify that those outcomes are achieved, instead of me verifying them. I should be thinking about the way this application we are building together is solving a business problem, or not, as the case may be.\nMaybe there is a better way to solve this problem than by writing code. In my case, the problem was already solved, I already has a SaaS solution, I just thought the price was too high. But the business case for that was deteriorating by the hour. Still, the experiment allows me to research this approach and write about it. So that is my current business case.\nMonkeys At this point in the story you might feel that indeed AI is a statistical completion machine. I was reminded of the meme \u0026ldquo;If you give enough monkeys enough typewriters, you will find a Shakespeare sooner or later\u0026rdquo;, and I felt like the poor guy who actually had to read through an ocean of words to find that piece of playwriting.\nThe trick is to have a structure that makes an AI look after that.\nThe peculiar thing is, if you ask the AI (Claude in this case) how we should simplify and strengthen the approach, so that there can be better end to end testability, it actually comes up with a very decent answer. That answer can even be translated into extensive project guidelines. This includes things such as modular application architecture, test-driven design, proper git version control hygiene, CI/CD pipelines, browser based testing, and more.\nThe coding assistant managed to apply these guidelines to a smaller project I gave it, and then made very few errors that required my attention.\nI had transcended the feedback loop.\nOne technique for that is making sure the assistant sees as much of the workings of the system, including its development and deployment process as possible, because you are the one who has to fill the gaps. For example, if the web app gives a server error (for example, code 500), the assistant should see it directly, instead of you manually relaying it to them.\nThe lessons The AI coding assistant will happily do what you ask it to do, and is not necessarily challenging you on best practices, or the lack of them.\nThe more we ask it to apply solid software engineering methods that work in teams of programmers, to better the AI will perform.\nThe assistant is capable of applying abstract rules to a specific situation (e.g. apply a modular structure, or introduce test-driven design). It is also capable of identifying relevant best practices and abstract rules based on quality criteria such as \u0026lsquo;modern tools\u0026rsquo;, and \u0026lsquo;better testability\u0026rsquo;. What does not happen automatically is identifying that the human has those demands to begin with. It seems to be trained on pleasing you with as little effort as possible, and without asking you questions that you may not like to hear. Maybe it should start there, with asking questions. Like: are you sure you want to apply a full ERP system to making an inventory of your home kitchen cupboard?\nCan an AI assistant code? I would rather ask the question: can it adequately simulate humans that code? What I have learned here is that this is quite dependent on making the best practices of human programmers explicit.\nVibe coding An afterthought: in his original tweet, Andrej Karpathy introduced \u0026lsquo;vibe coding\u0026rsquo; as the flow of being engaged with the AI coding assistant in a cycle of giving commands and fixing bugs. I understand that as not paying attention to any higher level guidance or method, which is not something to aspire to as a professional software engineer. Unfortunately, as it often goes, \u0026lsquo;vibe coding\u0026rsquo; is now often used as a term for all AI assisted coding.\n","permalink":"/posts/monkey-coding/","title":"AI coding rabbit holes"},{"content":"My AI-supported risk analysis assistant mirrors a common pitfall in risk management: focusing on irrelevant controls rather than genuine threats.\nI have created a risk analyst AI based on industry best practices, or so I assume. This is part of a quest toward more compliance automation, because as an industry we are falling behind in security.\nI am running through a simple example of a chatbot that answers questions over a nonsensitive dataset. The analyst dives deep into questions on all kinds of controls that, in my view, are quite irrelevant to the risk at the business level.\nLooking a little deeper it feels that it is overanalyzing the architecture, without filtering it by the actual harm that can be done.\nFor example, in the system under analysis, there is no sensitive data. That means there is no relevant data confidentiality risk, and encryption controls for data in motion are therefore irrelevant. Even discussing encryption is a waste of time.\nAt this moment, I feel the same frustration that pops up in a lot of IT risk decisions: people being bombarded with requirements for controls that do not affect the actual risk that the system owner and the system users have.\nI know the answer that I give in my teaching and consulting. If there is no realistic path from potential threat to actual pain of some stakeholder, don\u0026rsquo;t bother about the threat.\nBut maybe I can configure or train the analyst to pay more attention to this. What do you think?\n","permalink":"/posts/risk-value/","title":"Can AI automate compliance?"},{"content":"My first interest in networking came in the early 80s, as I was in the final years of my mathematics and computer science master\u0026rsquo;s program.\nAt the time, dial-up terminal networking was about the most advanced there was. And if you were lucky, you\u0026rsquo;d get 1200 baud (transmitting approximately 120 characters per second). My current fiber-optic home links are 1 Gigabit/sec, which is about 1 million times faster.\nBeyond this, computer-to-computer communication was mostly confined to the local data center. Transferring files from one computer to another typically involved physically moving storage media around. I have a great story about that, but that will be in another unit.\nEager to learn, we browsed the library to find a new book by Andrew Tanenbaum: Computer Networks. We already worked through most of his book \u0026ldquo;Structured Computer Organization\u0026rdquo; and we liked his approach and style. Many years later, I had the chance to meet and work with him a few times. He is both smart and personable.\nOur professors did not have time to set up a new course on computer networks, so we proposed teaming up with other students to each present a chapter to the group. That worked, but we could not do much practical work, as we lacked internet connectivity and even the hardware and software to run that on. I had to wait many years for that.\nAfter my Master\u0026rsquo;s, I got the chance to pursue a Ph.D. in a research group that was focussed on networking and computer communications. Even then, it took a few years before I moved from dial-up networking to planet scale internet.\nIt may seem archaic from today\u0026rsquo;s perspective, but that is how it was. You can\u0026rsquo;t expect to be using the network much when you are still in the process of building it out.\n","permalink":"/book/diginfra/first-network/","title":"How I Got Started in Computer Networks"},{"content":"What is the problem with the image that Zero Trust based information security brings along?\nOnce you understand the principles, and they are not really difficult, it is obvious that only ZT can lead us to a more secure cyber future.\nSo, what is holding us back?\nHere are some of the misconceptions:\n\u0026ldquo;It is a boatload of work, so let\u0026rsquo;s not start.\u0026rdquo; Truth: yes, fully securing your IT with all its technical debt is a boatload of work. That is exactly the reason why you need ZT, so that you know where you can get started quickly, and be more secure before the last hole is plugged.\n\u0026ldquo;Our board of directors does not understand this, so we don\u0026rsquo;t get funding.\u0026rdquo; Truth: ZT is easy to explain, once you find the right language to talk to them. ZT gives you technology neutral language.\n\u0026ldquo;Our security team does not trust ZT.\u0026rdquo; Truth: they may think it is overhyped, or another piece of technology that overpromises, and underdelivers. In reality, ZT is consolidating what they have always wanted to do, but did not know how to get funding for. And it is a great way to professionalize their career, if they so desire.\n\u0026ldquo;It forces us to do real work, instead of checking boxes.\u0026rdquo; Unfortunately, this is not a myth. But ticking boxes does not have a track record in making organizations secure. Nor has it been successful in creating meaningful work. ZT approaches are both more efficient and more rewarding.\n\u0026ldquo;Basic cybersecurity certifications are good enough.\u0026rdquo; Truth: if basic cyber certifications are going to improve your cyber security, you should definitely pursue those first. But they don\u0026rsquo;t help you prioritize and manage at scale.\n\u0026ldquo;Our partners are handling our security.\u0026rdquo; Truth: this is not true on the geopolitical scale, as some have found out. Nor is it true in cybersecurity. Companies remain accountable. And as ZT is also about prioritizing your investments, who would you prefer to have control over those investments? You or your partners?\n\u0026ldquo;We\u0026rsquo;ll just buy a box.\u0026rdquo; Truth: while there are great solutions out there that do a good job of implementing specific ZT use cases, and you will probably need some of them, if you don\u0026rsquo;t strategically know what you need, you will only procure shelfware. ZT addresses that.\n\u0026ldquo;Another course, another boring set of PowerPoints.\u0026rdquo; Truth: while the CSA CCZT courseware includes many PowerPoints, and I use some of that, my program is about much more than that. I flip the classroom, we spend most of the online time on a conversation to guide you through applying this stuff. My participants still find their jobs challenging, but not for lack of knowing how to approach it.\nThe next cohort of my Zero Trust program starts next week.\nThis week is the last chance to book a 1-on-1 call to discuss your participation in it, and the benefits that it will bring. Find the link in my profile.\n","permalink":"/posts/zt-myths/","title":"Zero Trust Myths"},{"content":"This is the dawn of a new age.\nI have been observing software development for more than fifty years, ever since I wrote my first computer program. In that entire time, I have never witnessed a development that has changed the profession deeper, faster, or more pervasively than now. AI-assisted coding has escaped from the lab, and is impacting the work of every software developer.\nIn the communities I track I hear stories of software engineers regret taking a single week of vacation because of the innovations that they now have to catch up to.\nI have lived through the revolutions of the Internet Dot-Com boom and cloud computing, but I feel this one is bigger and faster.\nOver the past weeks (May/June 2025) we have seen software development agents mature. AI models are now prompted to write prompts for other AI models. These are AI agents on the next level. We can now orchestrate long running flows of code generation and improvement without our direct oversight.\nSure, many people point out that AI typically does not behave more thoughtfully than an \u0026ldquo;overenthusiastic intern, who\u0026rsquo;d happily push buggy code to production.\u0026rdquo; Failure rates are high, but that is typical of any new technology. At the same time, there are already people pointing out that this coding workflow allows them to write software they wouldn\u0026rsquo;t otherwise be capable of. That is effectively an \u0026ldquo;infinite\u0026rdquo; speed-up.\nThis too is typical of a disruptive innovation: it gets used in situations for which the previous technology was too expensive.\nAs for quality: we know how to produce good quality software that is also secure. It involves using test driven design, continuous testing, adherence to patterns and standards, and feedback loops. All these can be codified into AI agents and agent workflows. Here is a simple example. Recently, I had Jules, the background coding agent from Google, update a Dockerfile so that it no longer required root permissions. It worked like a charm. Imagine having AI agents continuously reviewing code bases for these types of hygiene patterns.\nFew people currently have a complete understanding of where these developments are headed. Automatic coding agents have the potential to create or improve massive amounts of software. That software does not automatically have good quality, but, as sketched above, there are approaches to increase that quality.\nBut there is also a dark side. I shiver to think about the impact that this will have in the hands of malicious actors, from script kiddies to nation-states. The world of software engineering surely has changed.\n","permalink":"/posts/ai-coding-age/","title":"The AI Coding Age"},{"content":"If you build software for a living, generative AI may be a scary development, as it has the potential to take over a lot of software creation. But I think it depends on what you see as the job of creating software.\nA coder in the world of IT is somebody who writes code in some programming language. More typically they modify code instead of writing it from scratch. This is in response to bugs, feature requests, and so on. In the age of AI, a lot of coding can be automated. We have seen many examples of AI generating lots of code based on fairly compact specifications.\nA software engineer builds systems out of software. This may involve coding, but there are many other ways to create business value with software.\nLet\u0026rsquo;s drive this home through an example comparing the approaches that coders and software engineers would take.\nSuppose the objective is to create some kind of AI-powered analysis engine. You\u0026rsquo;d like to categorize a bunch of expenses coming from a variety of sources. A coder would select a few relevant libraries to start with, such as Langchain, get API access to a model or so, and start fleshing out the program code.\nA lot of this work can be generated by an AI. The tooling for that is at the moment one of the hottest areas of business development, so it is definitely a realistic approach.\nHowever, a software engineer might consider a few alternative options. Sure, they should be familiar with writing code, but there are a lot of other options.\nIt is very conceivable that there exists a SaaS solution (and probably more than one) that largely fulfills the needs of the business stakeholder. It could be a feature from one of the core systems that the data was coming from in the first place. Maybe most of the analysis could be done by an Excel or Google Sheets plugin. A complete open source package may already exist. These alternatives differ in many dimensions, and the optimal trade-off between advantages and disadvantages is, what I will maintain, an engineering decision.\nDimensions that matter include:\ncost, in particular total lifecycle cost speed, as in time to value flexibility, to what extent can the solution be customized, or included in a larger portfolio of applications the control that the stakeholders have over the solution the skills and competencies in and around the organization to keep this alive. Just collecting the background information to evaluate these dimensions is a significant task. I have heard estimates that more than 80% of knowledge in organizations is so-called \u0026rsquo;tribal\u0026rsquo; knowledge. That is the knowledge that is never written down, but is perpetuated in an organization through informal channels. This information is inherently difficult to input into AI applications.\nAnd then, think of this. The decision to use AI to develop and maintain significant parts of a code base is an important engineering decision in itself.\nI have yet to see evidence that an AI tool will bring significant benefit to this situation. For instance, when I asked a chat model for alternative software options for the analysis engine, it only provided lists of technical components and technologies suitable for a coder.\nIn conclusion, while AI continues to evolve and certainly has the potential to transform certain aspects of coding, and possibly parts of software engineering, I see no evidence that the discipline is in danger of being automated away.\n","permalink":"/posts/ai-code-software/","title":"AI will replace coders, not software engineers"},{"content":"Here is the story of how I started to use AI to help with running and securing my home network. I call it vibe ops, in analogy to vibe programming.\nThis post is going to be obsolete very soon, even though it is already the second version \u0026hellip;\nMy home network plays an additional role as a nice lab, and in the process of better securing it, preferably with Zero Trust Architectures, I am doing some experiments.\nThe home network is built around a Unifi Cloud Gateway, three Unifi WiFi access points, and a few switches. Currently it is flat and unsegmented. We need to do better security than that.\nHere is what I ran into.\nI started with a Unifi MCP server connected to my Claude Desktop, running Claude 3.7 Sonnet. This MCP server is cloned from github. This allows us to query, from Claude Desktop, the Unifi Cloud Gateway that controls my internet connection as well as the WiFi access points. It answers questions like:\nWhat are the connected clients? What are the active WiFi access points? Which clients are connected to the Attic access point?\nThis is interesting, but it gets more interesting if we combine this with other tools. So I tried nmap. The MCP server I used for that is cloned from https://github.com/himanshusanecha/mcp-osint-server.\nThis makes it possible to ask for:\nWhat are the open ports on all the Raspberry devices?\nWhich it does, except Claude hallucinated that a few machines with wlan0 interfaces are Raspberry Pis. In fact these are Tuya smart lights. A bit of prompt engineering solves that.\nHere is a fragment of claude_desktop_config.json.\n\u0026#34;osint\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;run\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;--rm\u0026#34;, \u0026#34;mcp-osint-server\u0026#34; ] }, \u0026#34;unifi-mcp-server\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;uv\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;--directory\u0026#34;, \u0026#34;/Users/peter/....../unifi-mcp-server\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;main.py\u0026#34; ], All good, but it does not work for local nodes, because of the way Docker Desktop implements isolation.\nAn example that works is:\nwhat are the open ports on domain digitalinfrastructures.nl?\nIt does the scan directly on the 2 IP addresses involved, and gives some more intelligence as well, involving tools from multiple MCP servers.\nNotes:\nThe MCP osint server does not advertise its capabilities very well, it seems. For example, Claude fails to understand that it cannot give nmap options, it only takes 1 argument. Seems easy to fix. Claude container invocations. Despite the --rm argument, some but not all of the containers started by Claude\u0026rsquo;s MCP activity seem to go away automatically. We could create a more remote server for the nmap scan of the network. This could have a better vantage point than my personal laptop. We\u0026rsquo;d have to install a remote MCP server on a Linux box in the local network, advertising its services. As is often said, a AI tool like this often acts like an overconfident intern. It happily applies tools, while not necessarily thinking which tool is the best. It gives analyses and recommendations that you did not ask for. Maybe we should apply some reasoning capabilities. It is interesting to watch Claude run with the tools. It makes you aware of the hidden knowledge and assumptions that go into a lot of this work. ","permalink":"/posts/vibe-opsing/","title":"Vibe OPSing with MCP: proof of concept"},{"content":"In order to illustrate the development of technology through tracking the development of LLM related tooling.\nIn December 2023 (check) ChatGPT came out. Within days people from around the world were using it.\nRAG - companies Langchain\nAgents\nMCP and A2A\nMCP spinoffs\n","permalink":"/book/cases/brief-llm-tool/","title":"A brief history of LLM tooling"},{"content":"You should not read this book because I tell you to. After all, you are an autonomous person, making your own decisions.\nYou should read this book because you are convinced that it is likely to give you significant insights into a world that matters to you.\nDigital infrastructures, and information technology at large, have moved from a fringe niche technology to becoming an essential part of modern life. Most companies would go belly up in weeks, if not days, if their digital infrastructures would fail.\nLet\u0026rsquo;s have a look at some examples. Maersk, the world\u0026rsquo;s largest shipping company, suffered a large cyberattack (known as NotPetya) in 2017 that disrupted global supply chains and cost over $300 million in damages. Colonial Pipeline, which supplies nearly half of the US East Coast\u0026rsquo;s fuel, was hit by a ransomware attack in 2021 that forced a shutdown of its 5,500-mile pipeline system, causing fuel shortages and panic buying across the southeastern United States.\nSociety is impacted in other ways too. Concerns were raised about Cambridge Analytica\u0026rsquo;s alleged use of harvested Facebook data to influence voter behavior in multiple elections worldwide. This shows how digital infrastructures can be used to distort democratic processes.\nAnd even though failures in shared services projects are less global headline making, they do impact lots of organizations and their clients.\nFor example, in my professional life, I have seen many projects aiming to improve collaboration unnecessarily delayed because of a mismatch between expectations and what the technology and power structure could afford. There will be examples of that throughout the book.\nWhat I write about in this book is shaped by the conversations I had with many people. I have worked with IT consultants, risk auditors, and their clients. I have worked with architects, CIOs, CISOs, and boards of large organizations. I have also worked with college students who were one third of my age, and whose parents weren\u0026rsquo;t even born when I wrote my first computer program.\nSo if you identify with any of these, or the topics I mentioned, this book is for you.\n","permalink":"/book/diginfra/why-you-should-read/","title":"Why You Should Read this Book"},{"content":"What is information really? If we know that, we can try to understand how we can judge its value, or even start to understand how we can create value with information.\nIn Claude Shannon\u0026rsquo;s theory of communication, information is about reducing uncertainty. Another way is to say that more information means less noise because if you add noise to information, that information will have more uncertainty and less value.\nTo visualize this, think of a picture that is obscured by a bit of fog or haze. You can still see some of the picture, but not very clearly. You will make more errors when trying to understand what the picture means.\nSimilarly, think of the difference between a grainy low resolution image, where you can see the individual pixels, versus a high resolution version of that image. More pixels, more bits, less uncertainty.\nIt is the same with sound. Being in the hall with musicians gives you much more opportunity to hear all instruments and singers compared to listening to it over the phone.\nFuture value Value can come from the reduction of uncertainty. If you know that a storm is coming, you can take protective measures and reduce damage. If you know a storm is not coming, you can enjoy a day outside. If you know neither, you cannot take advantage of the weather.\nIn business, the more you know about the potential customer, the more likely you can make them an offer that they will be interested in.\nIn information security, if you know about potential vulnerabilities, you can make it less likely to suffer damage from them.\nAn example from service management. Suppose your digital infrastructure is down a day a year, on the average. Your consumers will suffer from that, because it reduces their potential to benefit. How are you going to make it better, with less downtime? Now suppose you know that this happens on particular days, or hours, or with specific customers. With that information you can make more targeted investments in improving your digital infrastructure, which now are more likely to have a positive return on investment.\nThe pattern that we see here is that information on the current state of affairs allows us to influence the future outcome of a process, and with that, we can create value.\nOne of the most dramatic examples of that in the history of computing is the breaking of the Enigma code in World War II, by Alan Turing and his team members. This allowed the allies to reduce the loss that german U-boats were inflicting on transatlantic supply ships.\nInformation processing is information reduction Paradoxically, we never really seem to generate really new information, only more relevant information. We can call something information processing, but in reality we are only reducing information. If we compute the sum of two numbers, we are left with the sum, but that is not new information. It was, in a way, already there. And if we don\u0026rsquo;t show where the result came from (the two numbers) we are left with less information.\nIf in a table of inventory, we update the inventory with the result of many transactions, the resulting inventory table does not have more information than before. Of course, the information is more relevant to the current state.\nBut, what about generative AI, you may ask. Isn\u0026rsquo;t that generating information? With only a small prompt, we can have the AI generate a complete research report, or term paper, or nice new image. Yes, it looks like that, but the inference engine that takes your prompt, also takes in a huge model and combines the two into a new artefact, which is a lot smaller than your prompt and the model together. And in fact, the model itself is the result of processing huge amounts of training data.\nBut, the information that is the result of this reduction can be more valuable. Less is more. Paradoxical, isn\u0026rsquo;t it?\n","permalink":"/book/value/value-of-information/","title":"What is the value of information?"},{"content":"\u0026lsquo;But where do we start?\u0026rsquo;\nThe question hung in the air of my training session, asked by many of the attendants. Mind you, these are experienced people with many years of cyber security experience.\nBut turning Zero Trust from an abstract concept into concrete action? That\u0026rsquo;s where everyone gets stuck.\nI know that feeling well. Years ago, I joined my first Zero Trust working group, swimming in a sea of frameworks, agency guidelines, and vendor whitepapers. I even had the privilege of attending sessions with John Kindervag, the father of Zero Trust himself. Yet the gap between theory and implementation remained stubbornly wide.\nThat\u0026rsquo;s why I\u0026rsquo;ve spent months analyzing the growing mountain of Zero Trust literature, searching for resources that bridge this gap. Most of what I found was marketing fluff - vendors repackaging their existing products with a Zero Trust label. But three books emerged that, together, might finally answer that persistent question: \u0026lsquo;Where do we start?\u0026rsquo;\u0026quot; I owe it to my students to do this research.\nHere is my take on these three books that I feel complement each other nicely. I have interspersed that with some of my own perspectives and wrap it up with what I think could use additional elaboration. Read to the end for a final recommendation.\nThe Certificate of Competence in Zero Trust by the CSA (Cloud Security Alliance) The CCZT (Certificate of Competence in Zero Trust) is the first vendor neutral body of knowledge on ZT (Zero Trust).\nTechnically, it is not a book, but a set of study guides. As usual with CSA, the study guides are free downloads, and a large group of volunteers was involved in their making (including me).\nThe CCZT body of knowledge is a very comprehensive set of documents, and it aims to incorporate most industry knowledge, including those of US agencies such as CISA and NIST.\nCCZT takes a top-down and process-oriented approach, attempting to be rigorous and comprehensive. For me the best way to explain the usefulness of this approach is by pointing out that no organization wide approach is going to succeed without extensive stakeholder buy-in. CCZT addresses that.\nImplicit in the ZT approach is understanding an underlying trend. More and more companies are effectively a digital company, deploying more IT than ever, across a much wider and less controlled network, while external threats and compliance requirements are only increasing. Old-school blanket approaches to security are no longer sustainable. It is not your daddy’s datacenter anymore, and there is no firewall to rule them all.\nInstead, we need to prioritize, starting from the most valuable data assets to protect.\nIn my CCZT learning cohorts, we go through the chapters of CCZT and see how the concepts can be applied in the real world. The fit seems to be good, so far.\nWhat seems to work is that ZT has a language that is understood across an organization: from the board room to the shop floor.\nOf course, we’ll still run into that old problem that unless you know a bit about the technology and architecture, it is hard to understand the management and governance requirements, and vice versa. The limited coverage of technical examples in CCZT does not make that easier.\nThe CCZT chapter that feels a bit like the odd one out is the one on SDP (Software Defined Perimeter). It introduces different words for similar concepts, and it covers one specific set of use cases in quite a bit more detail than the rest of CCZT, down to introducing the Single Packet Authorization protocol.\nAs far as my memory of the working groups goes, this is the understandable result of wanting to incorporate the seminal earlier work that was done on SDP into later developments.\nIn summary, the biggest contribution of CCZT is that it comprehensively covers most organizational levels, but the objectives of timelessness and vendor neutrality make it hard on people who lack experience in organizational dynamics and technical architecture.\nThat is why the next books come in handy and complement CCZT nicely.\nProject Zero Trust “Project Zero Trust” is a business novel by George Finney. A business novel has fictional characters in it and elaborates on a management concept or business principle in a story. It bears a relationship with fictional case studies that are popular at certain MBA programs.\nWhat I like about the book is that it paints a reasonably realistic picture of a modern enterprise, including the information technology choices that it makes. This serves as a good backdrop to a variety of Zero Trust initiatives, which the book describes in a bit of detail.\nAs an instructor I find that most of the vendor neutral training material out there lacks specific examples (I mentioned CCZT as a specific example above). This makes it hard for students to anchor the abstract concepts that they are fed to a realistic environment with some resemblance to their job situation.\nThis book feels like it fills that need for a lot of my students, which is why I am recommending it to them. It combines a compelling story with enough examples that can be related to by anybody who has a basic understanding of information technology, while suggesting enough deeper dives for the so inclined (DNS, DHCP, anyone?).\n“Project Zero Trust” has most of the elements of the business novel genre, to the point that some feel like a cliché. There is the protagonist who has a new job, and runs into problems on day one, a real hero story. There is the CEO who steps down, the beers in a bar scene with insights from unexpected coworkers, and naturally the happy ending with the promotion. And there is appropriate ‘couleur locale’ from conference rooms to office dungeons.\nIt works most of the time.\nWhat I think the book could use some more off is a bit of drama. I mean that in the technical sense. The only serious conflict in this book is between the organization and one adversarial hacker. In contrast, the “Phoenix Project” and “Unicorn Project” (the archetypical IT business novels) show at length what internal conflicts in its protagonist organization can develop. To me this is relevant because no strategic IT innovation will be successful if it does not go through significant internal conflict and its resolution. More examples in spelling out the existing conflict and pathologies of an organization would therefore add significantly to the educational value for my students.\nI also liked the overt and covert movie references, and the shoutouts to a variety of industry organizations such as the Cloud Security Alliance and NIST.\nZero Trust Security “Zero Trust Security,” by Jason Garbis and Jerry W. Chapman, is presented as an enterprise guide.\nWhile “Project Zero Trust” narrates the ZT journey from the trenches that are under fire (please pardon the military metaphors), this book takes an architectural approach. Component by component is examined to see how they can play a role in applying Zero Trust principles. Example chapter titles: “Identity and Access Management”, “Virtual Private Networks”.\nWhat I like about the book is the systematic and consistent usage of deployment diagrams. In my opinion these are the first tool to use in analyzing an architecture for security.\nBut it does not stop there. The practical project experience of the authors shines through, for example in discussions on how to pragmatically approach the ideal of Zero Trust. The final part of the book summarizes their organizational and governance experiences. This covers similar ground as CCZT does, but in a much more pragmatic way.\nAs comprehensive as the book gets, it leaves me with the feeling that there is more to it and that we are still only scratching the surface. And the more this book elaborates on, the more I get the feeling that there is more to uncover.\nIn its pragmatism one insight stood out for me. Zero Trust can be presented as a radically new insight, which in a way it is, but almost all elements of it can be traced back to security concepts that are much older. The architectural examples in the book all seem to illustrate that Zero Trust is built with existing technology that only needs to be enhanced slightly.\nThat is not necessarily bad, in my opinion. On the contrary, it gives me the feeling that Zero Trust has the potential to be a unifying new language and conceptual framework for IT and cyber security. This alone can lead to more efficient and effective dialogue on cyber security, which is a good thing.\nBut a wide potential of applicability then still begs the question: where do I begin, and how do we know we are progressing? The maturity models give some insight but probably fall short for the technical professional who needs to map this to products and configurations.\nBut what do we need more? As an instructor, I have two thoughts for more instructional material.\nFirst: a set of labs. Even though all three books have some technology examples in them, nothing beats code that works, or actual design diagrams to tinker with. And once you have these labs, it will be easier to discuss how ‘Zero Trust’ can be added incrementally. It will also be easier to discuss the limitations of these solutions in fulfilling the Zero Trust promise.\nSecond: I am thinking of a game. The playground of the imagined game is an architectural solution to fulfill a specific ZT scenario. Players could use elements such as game cards on a board to rack up points and avoid penalties. The cards and the board would be aligned to the major ZT concepts. Maybe we could throw in random scenarios from bad actors, like the tabletop exercise elaborated in “Project Zero Trust”.\nSummary and conclusion All these books are relevant for the aspiring Zero Trust professional. The concepts and language overlap sufficiently, that is, any differences do not confuse. For somebody new in the field I would recommend starting with “Project Zero Trust”: it is a nice story, and a nice backdrop and source of examples for the other books. I believe the others can be read in either order. If you want to strengthen your architectural understanding of enterprise IT, read “Zero Trust Security” first. If you want a more comprehensive stakeholder and project perspective, and you can live with abstract architecture concepts, you might prefer the CCZT study guide first.\nThe books complement each other nicely, but even together still aren’t a roadmap to follow blindly. That is why I am looking forward to working with practitioners in my Zero Trust learning cohorts.\nFor more information on Zero Trust courses and programs, see https://cczt.clubcloudcomputing.com.\n","permalink":"/posts/three-books-zero-trust/","title":"Three books on Zero Trust, and when you should read them"},{"content":"The security of your SaaS cloud solutions starts with the review of three major areas. Practically all companies are using SaaS providers in one way or another. SaaS includes Services such as Trello for project management, Microsoft 365, and e.g. specialized solutions for marketing intelligence services. The sky is the limit. Most companies using are using hundreds of SaaS solutions.\nHere are 3 tips to start with.\nMaturity match The first thing to worry about is if the maturity of the provider matches your risk appetite. Are they good enough for your use case? If you are working with a mission-critical SaaS solution, you want to make sure that the provider is mature. You can start finding out if that is the case is by looking at their certifications. An example could be the ISO 27000 series certification for IT risk management, or similar. Most mature cloud providers have dozens of certifications. On the other end of the spectrum, you may want to work with a provider that is not so mature, but that is delivering a very innovative solution of great business benefit to your company. That benefit, that competitive edge, may warrant a greater risk appetite. So start with that maturity match first.\nSecurity features The next thing to look at is if the offering that you are considering has the right security features for you. The first set of security features to look at is identity and access management, and logging. Your first question here is: are the features we need a part of the offering? Office suites, such as Microsoft 365 and Google Workspace, have features such as data leakage prevention and real-time logging. The next question then becomes: are we procuring those features? The features that you require might be in a different package than you are considering. And enterprise features often have enterprise pricing.\nUsing security Finally, an important thing to look at in considering SaaS security is your usage of the security features. It does not make much sense to allow all users access to everything or to have log files that nobody is looking at. More specifically, a product such as Microsoft Teams has over 1000 settings that have an impact on the security of the solution (I had a bunch of students work through this). It is very easy to not use the right futures. Of course, there is much more to cloud and SaaS security than this. But the three main points to start with are the maturity of the provider, the set of security features they are offering, and your internal usage of those features.\nAnd then you can consider cloud security training.\n","permalink":"/posts/saas-security-simple-checklist/","title":"Saas Security: a Simple Checklist"},{"content":"“Project Zero Trust” is a business novel by George Finney. It talks about an emerging approach to IT and Cybersecurity that attempts to reduce cyberrisk in a more fundamental way. Zero Trust is a bit of a hype in IT these days, and both product companies and knowledge agencies are dropping lots of papers on this. But this book is in another game.\nWhat I like about it is that it paints a reasonably realistic picture of a modern enterprise, including the information technology choices that it makes. This serves as a good backdrop to a variety of Zero Trust initiatives, which are described in a bit of detail. As an instructor I find that most of the vendor neutral training material out there lacks specific examples. This makes it hard for students to anchor the abstract concepts that they are fed to a realistic environment with some resemblance to their job situation.\nFills a need This book feels like it will fill that need for a lot of my students, which is why I am recommending it to them. It combines a compelling story with enough examples that can be related by anybody who has a basic understanding of information technology, while suggesting enough deeper dives for the so inclined (DNS, DHCP, anyone?).\n“Project Zero Trust” has most of the elements of the business novel genre, to the point that some feel like a cliché. There is the protagonist who has a new job, and runs into problems on day one, a real hero story. There is the CEO who steps down, the bar scene with insights from unexpected coworkers, and naturally the happy ending with the promotion. And there is appropriate ‘couleur locale’ from conference rooms to office dungeons.\nIt works most of the time.\nWhat I think the book could use some more off is a bit of drama. I mean that in the technical sense. The only serious conflict in this book is between the organization and the hacker. In contrast, the “Phoenix Project” and “Unicorn Project” (the archetypical IT business novels) show at length what internal conflicts in its protagonist organization can develop. To me this is relevant because no strategic IT innovation will be successful if it does not go through significant internal conflict and its resolution. More examples in spelling out the existing conflict and pathologies of an organization would therefore add significantly to the educational value for my students.\nBy the way, I also liked the overt and covert movie references, and the shoutouts to a variety of industry organizations such as the Cloud Security Alliance and NIST.\nAnd if you are interested in applying Zero Trust principles, have a look at this page here: https://cczt.clubcloudcomputing.com.\n","permalink":"/posts/great-introduction-to-zero-trust/","title":"Great Introduction to Zero Trust"},{"content":"What are the real challenges in cloud security these days? In my recent conversations with industry practitioners, one came up consistently: the lack of knowledge and skills to adopt cloud securely. These gaps are slowing down how teams build, manage and secure their cloud environments, and they may be affecting your teams as well.\nProvider specific technical expertise Many IT professionals attempt to transfer their on-premises security knowledge directly to cloud. But this often leads to ineffective and hard to maintain solutions. A technical example is insisting on traditional firewall architectures. These are hard to implement right in the cloud and can lead to less secure deployments than are possible with cloud native architectures. One set of skills that is relevant to addressing this is understanding what features a specific cloud provider has for building a secure architecture. There are many courses available from the providers, even free ones, though it can sometimes be a bit challenging to select the correct ones. However, without understanding how abstraction and automation change the IT security game, these technical skills will not result in more efficiency. And without more efficiency security efforts will be outpaced by the speed of new developments.\nUnderstanding the big security picture While technical and cloud provider specific know-how is essential, it is just part of the skillset that is required. We also need a fresh perspective on security principles, if we don’t want to get bogged down in a quagmire of technology specific approaches. The concept of Zero Trust pulls together many earlier insights in the essence of proper IT security architecture, such as the demise of the traditional perimeter and the need for identity-centric security and unifies them. Zero Trust has the potential to serve as the ‘missing link’ between governance and technology implementation (a topic on which I hope to write another time). But for that to happen, teams need specific skills. They must extract the Zero Trust essence out of existing security solutions and translate them into actionable real-world practices that fit in modern cloud deployments.\nNow what? Do you recognize these challenges? If, like me, you believe that targeted skills training has the potential to have a high return on investment, then have a look at two of my certification-based programs.\nCCSK, the Certificate of Cloud Security Knowledge, is the ‘mother of cloud security certifications’, and an industry evergreen. I have delivered it more than 150 times over the past years. Recently, I have helped upgrade the Study Guide to version 5. While the study guide is technology neutral, there is an optional set of labs that guide you through major security controls for Amazon Web Services and Microsoft Azure. Through my blended teaching format, we emphasize your autonomy in preparing, and you’ll gain practical skills in dynamic discussions and exercises. But we don’t stop there. For more details on the format look here.\nCCZT, the Certificate of Zero Trust Knowledge, was launched in 2023, and is the first program to codify Zero Trust in a certification. I have contributed to this one too, and I have a program that combines teaching with coaching. This runs over a longer period so that you can directly implement your skills in your organization. More information on CCZT is here.\nCurious how these programs can empower your team? Let’s talk. Schedule a quick 15-minute call here.\n","permalink":"/posts/key-knowledge-gaps-in-cloud-security/","title":"Key Knowledge Gaps in Cloud Security and How to Address Them"},{"content":"Model Context Protocols (MCP, see my post on their security) are the new glue between humans, chatbots, and old school IT.\nHere is the step by step approach that I followed to \u0026lsquo;vibe code\u0026rsquo; a Model Context Protocol server for my CRM and mailing list manager.\nI journaled this description, so I have included most of the detours and false starts. For readability, I edited the description later, but the flow is as I went through it.\nThe CRM system is called Autorespond, and the description of the API is here. The API doc is not in any standard format, but I had Claude Pro convert it to Markdown using the fetch MCP. I also uploaded the doc to context7, an API documentation site for LLMs, but since Claude already had it in its context, I did not pursue that further, for the moment.\nWith that, I asked Claude:\nWhat do you need to know in order to write an pilot Model Context Protocol server in Python for retrieving the tags in an Autorespond administration?\nIt basically started reasoning and immediately writing code. However, it was clear that it did not really have a clue on MCP, not surprising, since MCP was introduced just a couple of months ago.\nI told it the doc could be found on github, which it downloaded partially (because of robots.txt limitation). It then basically parroted that documentation to create similar code for Autorespond.\nI manually put the resulting code in a new git repo, though I could probably ask some AI assistant to do that for me.\nIn my workflow I like to set up a virtual environment based off a requirements.txt file. I did not get that, so I wrote that myself. However, as we see later, there is a more modern approach.\nAfter fixing that, it runs, but throws an error\nMismatch between URI parameters set() and function parameters {\u0026#39;ctx\u0026#39;} Throwing the error message into Claude, and it changes two lines in the Python code to make this work. Of course, I did a git commit before replacing the Python code.\nThen I got a bit lost in the usage of uv in relation to registering this MCP at Claude desktop. This is the new Python package manager, and it seems to be the default for almost all MCP server installations. My Python instructor friend regards it very highly. It appears that I did not have that setup done well.\nThe main benefit of uv here seems to be that it isolates the execution of a specific version of Python and its libraries. You could use venv for that, but since the MCP runs from the context of Claude desktop, I am not sure if that would work well enough. No time to figure that out, just follow the herd. Another way of doing that is through the use of Docker, which isolates the code further. I do that for most external MCPs, but for a local development I consider this good enough.\nRebuilding the virtual environment with uv worked a bit better, though I still have limited understanding of it. Here is a snippet from the Claude config.\n\u0026#34;command\u0026#34;: \u0026#34;uv\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;--directory\u0026#34;, \u0026#34;/Users/peter/Documents/-----/AutorespondMCP/\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;autorespond-mcp-server.py\u0026#34; ], \u0026#34;env\u0026#34;: { \u0026#34;AUTORESPOND_ADMIN_ID\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;AUTORESPOND_API_KEY\u0026#34;: \u0026#34;***\u0026#34; The good news is: the generated code runs. The bad news is: setting up the package manager takes a bit more time. The ugly: I should have set up environment secrets first, instead of hard coding them in the code.\nWe can now start to use the MCP server in Claude, but it looks like it hallucinates a few of the search functions. It makes up function uses that are not in the Autorespond API, which therefore fail.\nSo I asked it to enumerate the read-only functions, which reduces the number of hallucinated functions. It then still does not quite understand parameters in the MCP context.\nValueError: Mismatch between URI parameters set() and function parameters {\u0026#39;email\u0026#39;} Sounds like it is time to tell Claude how MCP really works.\nOff to a fresh start, with a new git repo, and a new Claude context window. This time Context7 sounds like the proper way to ingest up to date libraries. I added the MCP server for Context7, and added it to the coding conversation.\nAutorespond was easy, I put it there myself. For the Python SDK it took a detour, but it managed to find the doc through /modelcontextprotocol/python-sdk.\nBack to uv. This time around, this seems to be the best workflow for starting a new repo, even with VScode.\nuv init uv add \u0026#34;mcp[cli]\u0026#34; httpx Claude gave the correct uv steps.\nHowever, this error comes back: ValueError: Mismatch between URI parameters set() and function parameters {'ctx'}\nClaude still does not get it. So I told it:\nthe problem is more generic. Here is the next message: ValueError: Mismatch between URI parameters set() and function parameters {\u0026lsquo;api_key\u0026rsquo;, \u0026lsquo;admin_id\u0026rsquo;} please check for all potential mismatches.\nClaude kind of fixed it, but it appeared it did not understand the fastmcp library, which is referred to in the Python MCP SDK. I had it include that from Context7.\nIt is tempting to try and fix the few lines of code that needed to be changed in my MCP server program. However, one of my software engineering rules is that you don\u0026rsquo;t manually fix automatically generated code.\nSo we git commit the Python code, and then replace it with a new version. From the git diffs we can see that the changes are indeed quite local. But I have seen sessions like these where instead of the local change that would be sufficient, large parts of the codebase are fully rewritten for no apparent reason.\nOK, now it runs in Python:\n% python autorespond-mcp-server.py [04/29/25 10:34:06] INFO Starting server \u0026#34;Autorespond API\u0026#34;... Let\u0026rsquo;s look at how it runs in Claude. It kind of works. But it did not understand that the authorization is in ENV variables. In the earlier version it did, by the way. Now it thinks the authorization is an additional API parameter, and it then starts to hallucinate the actual values there. It randomly generates API keys, quite amusing in fact.\nWe tell it to regenerate the code with the note:\nThe admin key and api key are environment variables. Rewrite the code.\nNow it works, as this Claude screenshot of a conversation shows:\nBut it has forgotten certain API calls (invoices, orders). And some of the calls don\u0026rsquo;t work, which seems related to the interpretation of the Autorespond API doc. I am not an API specialist, but I have been told that this doc is generated from code annotations https://apidocjs.com/. I believe these days you would do it the other way around, like what we did with Kimwitu a couple of decades ago.\nInterestingly, Claude (the coder) decides to label certain calls as MPC resources, rather than tools. An example would be getting all the tags or groups. While this sounds fair, in Claude (the desktop) these will not be used unless explicitly added by the user. This means they are excluded from the reasoning that Claude can do.\nSo far this took me a few hours, including the updates of my tooling, resulting in about 450 lines of code for the Autorespond MCP code.\nUp next. Giving better instructions on the coverage of the API. And, should we be writing some test cases? I have seen that explored in some of the meetups I visited recently. To do that well, we need a test instance of the Autorespond system.\nStay tuned for more \u0026hellip;\nGithub\n","permalink":"/posts/vibe-mcp/","title":"Vibe coding an MCP Server"},{"content":"If you are in security and not fully on top of AI risk, you want to look at MCP now, as this is going to be popular and risky. Reach out to your development teams and beyond to offer your help in using them wisely, even if you know nothing about them yet.\nMCP, Model Context Protocol, was introduced in November 2024 as a standardised way to feed AI chatbots with extra information. You can extend Claude or OpenAI desktop with MCP servers, which are basically small programs that run on the desktop and have access to all information and services that the user has.\nMCP servers are popping up like flowers in spring and range from fetching up to date weather information to orchestrating your entire customer onboarding workflow.\nAs said, they have access to everything that the user has access to: the local machine, attached network files, the internet, you name it. Effectively, they are an insider threat on steroids. For example, an MCP could access sensitive corporate documents on the local network, and send them to an AI model, even if that is running on another continent.\nMost MCP servers I have seen are written in node.js, which requires npm to be installed, which is not exactly known for its great security track record, see here and here.\nFor a nice little example of MCP servers and clients, and their vulnerabilities, have a look at this github repository.\nMCP has tremendous potential in quickly creating useful workflows. As a security professional it is your choice if you want to stand in the way of that, or if you are going to help move it along a safe pathway.\nFor more background on the technology, its applications, and risks, I strongly recommend listening to this podcast with Caleb Sima and Ashish Rajan.\n","permalink":"/posts/mcp-risk/","title":"Look at MCP now to be ahead of AI risk"},{"content":"architecture-beta group frontend(cloud)[Frontend] service telco(cloud)[Telco] in frontend service sips(internet)[Sips] in frontend group backend(cloud)[Backend] service app_server(server)[Azure voice bot] in backend service twilio(internet)[Twilio] in backend service database(database)[Database] in backend service llm(server)[LLM] in backend group configuration(cloud)[Configuration] service faq(database)[FAQ mgt] in configuration telco:R -- L:sips sips:R -- L:twilio twilio:R -- L:app_server app_server:B -- T:database llm:B -- T:app_server faq:R -- L:database ","permalink":"/posts/ai-voice/","title":"AI Voice"},{"content":"I have found that no discussion on risk is going to lead anywhere if it does not make clear who suffers from it. Make clear who has the pain. For my phone and laptop it is easy: if I lose them, I suffer. In a larger organization it is less clear. Suppose a server dies. Whose application then no longer runs? Who has to pay for a new server? This gets increasingly harder if we are talking about shared services, because the owner and the consumer are now decoupled.\nA related complication pops up when a failing component or service is remote from the organizations main purpose, or mission. We see this a lot around software vulnerabilities. A software vulnerability can allow a malicious actor to fully take over a service. But unless you demonstrate that:\nthis vulnerability can actually be exploited, and this exploit can cause damage to the mission it would be a waste of time to address it individually.\nIf you are involved in risk analysis, make sure to complete the reasoning up to the point where the stakeholder with the budget feels the pain. To do less is a waste of resources.\nExternal victims It gets a little more complicated if those who suffer are not part of the organization that controls that risk. Example: as a merchant accepting credit card payments of your customers, the customers credit card number helps you get paid. But if you accidentally disclose it, and it falls in the hands of a bad actor, you don\u0026rsquo;t suffer. The customer does, or their bank.\nFrom the perspective of the customer, your activity impacts something that is of value to them. Economists call this an externality, and we see various examples of that in the world of risk, and in digital infrastructures at large.\nAs the example customer, there is little that you can do about it. Why the credit card system still works is that banks and credit card issuers have an interest in the system working, and they don\u0026rsquo;t want to saddle either the card holder or themselves with these losses.\nThey have the pain, and their response has been to create a mandatory certification scheme for everybody who touches a credit card number. You cannot process a credit card, and definitely not at scale, without being PCI/DSS certified. This is enforced by contract. If you can\u0026rsquo;t abide, you can\u0026rsquo;t process credit cards, which may be important to you. This is how they make the credit cards processors suffer. It is an industry regulation.\nSimilarly, personal data loss is a risk to the person, not to the organization that collects your personal data. That is why there are privacy regulations, of which the EU GDPR (General Data Protection Regulation) is the most well-known.\nThese aren\u0026rsquo;t industry regulations, they are the law. And if you don\u0026rsquo;t follow the law, countries can fine you. Unfortunately, as I mention elsewhere, money is a blunt instrument. So while privacy laws work, they are not a perfect solution.\nSumming up, this leads to a new category of risk: compliance risk. If you do not comply with regulations, whether they are industry or government, you will suffer the pain.\n","permalink":"/book/risk/who-suffers/","title":"Who Suffers?"},{"content":"How does vibe coding work in the real? Vibe coding is having AI write your software. Coined by Andrej Karpathy, the hype is all over the map, with companies that are rethinking their hiring strategies for programmers. Sounds like disaster for software engineers and programmers.\nNot so fast.\nCurious to learn more about it, I reached out to an old friend who is an experienced software engineer. He was a co-founder in a SaaS company in the monitoring space. After a successful exit he now has a bit more time to pursue hobbies. But he is still professionally busy.\nHere is his workflow for using AI for creating software. Understand that this is quite opinionated, but it does match my own experiences.\nFirst of all, don\u0026rsquo;t rely on Co-pilot and other assistants. Before you know it, you have lost control over your codebase, and you will find it really hard to debug it, if not impossible.\nDon\u0026rsquo;t start to code immediately. A lot of AI assisted code editors start off by immediately generating code. Not with this guy.\nHe starts with an analysis in Anthropic\u0026rsquo;s chatbot, Claude 3.7 Sonnet, Pro account. Important settings are\u0026rsquo;extended thinking\u0026rsquo;, \u0026lsquo;style explanatory\u0026rsquo;, and allow it to create artefacts.\nHe first discusses the architecture of the solutions, and asks the bot to generate a few alternatives with pros and cons. If relevant, he asks for more explanation of alternatives. Claude still has a tendency to generate code, but you should include \u0026rsquo;no code\u0026rsquo; in the prompt a few times. Apparently it can take a while for Claude to get that message.\nOnce you have some overview of the software you want to create, you can start asking for code. Ask it for 10 lines max at a time, to implement specific parts and functions. My friend just copy/pastes this into a code editor, and then syncs it to github.\nClaude Pro has a feature called Projects, in which you put the project knowledge, and a link to your github repository.\nWhile I did not discuss this with him, I think it is a great idea to also use Claude to generate unit tests.\nOne of the complications of vibe coding in general is that the model can have trouble staying on track with libraries. For a variety of reasons, you want to pin libraries to a specific version. If not, the model can hallucinate its own version. Especially with more recent versions of libraries and frameworks, the models aren\u0026rsquo;t always up to date, and they don\u0026rsquo;t like to admit that.\nOften there is a set of markdown text files with an SDK or library that has all the documentation. If not, his approach is to use OpenAI Deep Research to create a markdown file with all the relevant documentation on the specific library he is using. The idea is to not pollute the Claude history with irrelevant information on the libraries. This then goes into the Claude Project. One of the nice things is that you can then also \u0026lsquo;chat\u0026rsquo; with the documentation.\nSometimes the chat with Claude becomes too long, and a warning is issued. The approach then is to ask Claude for a summary of the chat, and use that as the beginning of a new chat.\nFor debugging there is the Claude Code command line, which can look directly at files in the code directory. This has faster feedback than going back to the github repository.\nIn summary, if you know what you are doing and apply some structure, using AI to support you in software construction has a lot of potential to increase productivity.\n","permalink":"/posts/vibe-coding-real/","title":"Vibe Coding in Reality"},{"content":"Change is quite inherent in technology, and in particular in information technology. At the same time we want technology to provide a reliable service, and that requires a degree of control. In this chapter we\u0026rsquo;ll explore some fundamentals of change, in particular how this works with groups of people.\nChange and control mindsets complement each other. We need both, even if they conflict at times.\nFor example, in a typical IT environment, you have developers and system administrators. The output of the developers is a stream of changes: new features, improvements, bug fixes, and so on. Adminstrators are in the business of keeping everything stable, the same. They see no fundamental difference between a new feature and an incident. Both are disrupting the normal flow of business. Consequently, they are seen as a threat, and that is why it often feels that developers and system administrators are from different planets.\nPart of running a smooth IT function is juggling the balance between change and control.\n","permalink":"/book/change/intro-to-change-control/","title":"Introduction to Change and Control"},{"content":"Power is a concept that is widely used and ill defined. Many philosophers have discussed it, but not one definition really stands out. Before we attempt to define power formally, let\u0026rsquo;s see how the word in used in everyday IT situations.\nUnderstanding power in IT is not just academic. As the examples show it is crucial in understanding how IT works, and creates value and risk.\nThe cloud architect held significant power in deciding which platforms the organization would adopt for its digital transformation. Automated deployment pipelines gave development teams the power to release software faster and with fewer errors. Legacy systems often retain unexpected power in large organizations, simply because so many critical processes still depend on them. Regulators have the power to halt digital initiatives if data protection requirements are not met. By owning the central identity management service, the security team had the power to control access across the entire infrastructure. Outages at major cloud providers show how concentrated power in digital infrastructures can lead to systemic risk. The CIO used the power of budget approval to steer the enterprise toward adopting more secure infrastructure patterns. Power struggles between central IT and business units can delay the rollout of shared infrastructure services. With real-time observability tools, operations teams gained the power to detect and respond to incidents before users were affected. An open-source community can collectively wield more power than a single vendor when shaping the direction of a software tool. From these examples, we can see certain recurring features of power in the context of IT and digital infrastructures.\nPower can be attributed to people, technical artifacts, teams, organizations as a whole, roles, and institutions, to name a few. These same types of actors can also be the subjects of power. Power is exercised through a variety of means and mechanisms. In these examples, mechanisms include:\nDecision-making authority – The ability to choose platforms, policies, or directions. Technical capability and automation – Tools that enable or restrict what actions are possible. Dependency and path-dependence – Power held by systems or practices others rely on. Legal and regulatory enforcement – Influence through rules, compliance, and consequences. Control over chokepoints – Gatekeeping access to critical systems or resources. Centralization and concentration of infrastructure – Power from aggregated control or single points of failure. Resource and budget control – Steering outcomes through funding and prioritization. Organizational politics and influence – Competing agendas, alliances, and negotiation. Information asymmetry – Advantage through greater visibility or data access. Collective governance and community action – Shared power through participation and collaboration. These are the building blocks of effective IT. The way these mechanisms are organized plays a critical role in shaping both the value and the risk of digital infrastructures.\nA common thread is that power influences the future, and influences the outcomes of activities. The simplified definition of power, inspired by Oxford Languages, that I use here is:\nPower is the ability of an actor to direct or influence the behavior of others or the course of events.\nAs our examples show, these actors are not just people - they can include technical artifacts and teams.\nPower isn’t just philosophical—it’s operational. It determines what can be built, who gets to decide, and how resilient or risky systems become. To work effectively with digital infrastructure, we need to see power not as abstract, but as architecture.\n","permalink":"/book/power/intro-power/","title":"Introduction to Power"},{"content":"Most digital infrastructures are meant to communicate or coordinate, or are in support of other digital infrastructures that communicate or coordinate. That is where their prime value is.\nThe internet is a great example. It is designed to enable computers to communicate by moving data packets between them.\nSocial media is another example, used by people to communicate with each other. Its success is a testament to the fact that communication is a fundamental human need.\nFor an example of a supporting digital infrastructure you can look at an IaaS provider, which enables data processing and storage for other applications and infrastructures.\nFrom a business perspective this communication and coordination can lead to value in the form of, amongst others:\nbetter resource utilization and less waste, better process efficiency, better quality of services and products, reduction of risks. These are just the major, broad categories of delivering value, and there is considerable overlap between them. For example an organization\u0026rsquo;s website helps communicate to its customers. But you can also look at it as a more efficient way to organise the coordination on the delivery of products and services to the customer.\nAs you dive deeper into business processes, you will find that there is a wide range of processes and ways that lead to business value, each of which has its own peculiar ways of communicating and coordinating. In the early days of networking, I was sometimes asked what the value of a network is. That is a hard questions. Equally unanswerable is the question what the value of a message is. It just depends on the role that such a message plays in a process. For example, if your house is on fire, you only need a small message to reach the fire department, but if it does not get there, you\u0026rsquo;ll lose a house.\nStrategy consulting firms, like the one I worked at, do a lot of work in process reengineering to create value for their clients. The larger firms have serious collections of proces improvements. Over the past decades, significant reengineering of supply chains has taken place. The core idea of that is typically that better coordination reduces risk and inefficiencies.\nI think that just about any process can be improved with more information and communication. The questions remain: at what cost, which stakeholders will benefit, and which stakeholders will experience negative results.\n","permalink":"/book/value/value-in-process-improvement/","title":"Value in Process Improvement"},{"content":"Digital infrastructures focus on services rather than products, making it elusive to capture the essence of these services, especially in defining the fluid interactions between service providers and consumers.\nPromise theory is a little-known approach to interaction, though it has quite a few great thinkers behind it. Introduced by Mark Burgess and others, it is about how autonomous agents work together. It helped me a lot in getting a handle on various distributed systems. There was this project where we designed a scalable travel information system with what we now call microservices. We needed to describe how these parts work together. And there was a project that required lots of independent and autonomous social security agencies to work together on providing a service. In getting this from the drawing board to actual production, promise theory turned out to be a great tool.\nLet\u0026rsquo;s start with the basics, and we\u0026rsquo;ll cover some of the background details later.\nImagine you are in a café or restaurant, and you wish to avail yourself of the service to order a beverage. You have the attention of the waiter, and you politely ask them for a coffee. The waiter responds with a \u0026ldquo;yes, by all means\u0026rdquo; statement. After a while, the waiter returns with the coffee and says \u0026ldquo;there you go\u0026rdquo;, to which you reply \u0026ldquo;thank you!\u0026rdquo;\nThis is a transaction between two autonomous agents. Both have the option to not participate.\nNow what is really going on here?\nOur question to the waiter is really a request for a commitment. We want the waiter to commit to delivering us the coffee. The \u0026ldquo;yes, by all means\u0026rdquo; statement amounts to an acceptance of this commitment. Once the coffee is there, the statement \u0026ldquo;there you go\u0026rdquo; in fact signifies a request to be acquitted of the earlier commitment, that is to say: a declaration that the commitment is fulfilled. And once we say \u0026ldquo;thank you\u0026rdquo;, we have answered to that acquittal request, and stated that there are no more open commitments.\nThis basic interaction is an enormously universal pattern as we will see, and it can be used to describe interactions on many levels. I have examples ranging from technical internet protocols to the organization of service management and legal contracts.\nBut before we move on, I\u0026rsquo;ll have to discuss some variations that allow you to see how universal the pattern is.\nSome of the steps can be combined, or are implicit. The two steps by the provider can be combined if there is little time delay between them. The final acquittal can be implicit. What we have described is the \u0026ldquo;happy path\u0026rdquo;. Alternative messages are also possible. The waiter can refuse the request: \u0026ldquo;we ran out of coffee unfortunately\u0026rdquo;. We may not accept the drink: \u0026ldquo;could you make that an iced latte, please\u0026rdquo;. Another point to make is that these transactions are often part of a bigger picture. For example, once we accept the coffee, we are making an implicit promise to pay for it, at some later stage. Though you can also envision scenarios where putting your money on the counter of the barista is an implicit acquittal.\nMany, if not most, business transactions can be modelled with this, as we will see. The key is to understand what the promises are that are being made and acquitted.\nIT support is also a service Let\u0026rsquo;s turn our attention to an example in digital infrastructures: we want a new laptop. Again, this proceeds by making a request, in this case typically to a service desk. It is the exact same flow of messages, although there may be more detail involved and a paper or web form needs to be filled in.\nIn our example, we have humans trading with humans. But the same principles hold between humans and machines, machines and other machines, as well as between organizations and machines. The core idea is that we are describing how agents transact.\nOnce we understand and describe the essence of such a transaction, we can automate it without changing the meaning. That is a very powerful insight in a cyber world. As an organization, we want to have machines service our customers. And as customers, we don\u0026rsquo;t seem to mind talking to a website as a substitute to talking to an organization.\nIn the course of the 20th century, most countries completed the automation of their telephone systems. Requesting a call through an operator was replaced by \u0026ldquo;direct dialling\u0026rdquo;, or self-service as we would call it in other situations. As late as the 1970s there were destinations you could not directly dial, even in developed countries.\nBut the principle of setting up a call is the same, whether you ask a human or a machine. It starts with \u0026ldquo;please connect me with this number\u0026rdquo;. And the general promise, the commitment, of the telecommunications company remains to do that, irrespective of the technology.\nWhat is a promise? According to Jeff Sussna, a promise is\n\u0026ldquo;\u0026hellip; a strongly stated intention to provide a service, which may or may not be kept\u0026rdquo;.\nThis makes it clear that there ultimately is a possibility for it to not be fulfilled. Jeff Sussna compares this to a teenager\u0026rsquo;s promise to clean their room. It may happen, but there is a chance it does not.\nAutonomous agents can only make promises to each other, they cannot force each other to do things. However, we can ask other agents to make a promise to us. In our example, we ask the waiter to bring us a coffee. The waiter may chose to respond by making the actual promise.\nThe next important construct is the conditional promise. An example would be: \u0026ldquo;If you bring me a coffee, I will promise to pay you for it\u0026rdquo;.\nWith these basic primitives, we can model a lot of conversations.\nOur example coffee conversation now becomes:\nQuery: Please promise me to bring a drink Ack: I promise to bring you a drink in a short while Reply: Please promise me that you are satisfied and will pay Ack: I promise to pay you for the drink sequenceDiagram actor Client actor Provider Client-\u0026gt;\u0026gt;Provider: Query Note right of Provider: Please promise me to bring a drink Provider-\u0026gt;\u0026gt;Client: Ack Note right of Provider: I promise to bring you a drink in a short while Provider-\u0026gt;\u0026gt;Client: Reply Note right of Provider: Please promise me that you are satisfied and will pay Client-\u0026gt;\u0026gt;Provider: Ack Note right of Provider: I promise to pay you for the drink Semantics We can dive a little deeper into what such a promise means. In all our examples, messages were exchanged between agents. These messages control a process of interaction, and in that interaction, a shared reality is created. This sounds abstract, I know, so let\u0026rsquo;s have an example. At a marriage, the magic sentence is:\n“I now pronounce you husband and wife”.\nWhat changed after that sentence is said? Legally, these people are now married, which creates a whole new world of possibilities and obligations. Before that sentence was spoken, they were not married.\nThat is why this is also called \u0026ldquo;speech act theory\u0026rdquo;: the statement acts upon our reality. In the theory this example is a \u0026ldquo;performative\u0026rdquo; or \u0026ldquo;declarative\u0026rdquo; statement.\nThis view of messages helps us see how our interaction is a shared reality between the agents, and can actually control that shared reality. That reality can be about the physical world, as in our coffee example, or it can be about the legal world that we use to control the physical world, as in our matrimonial example. It can also be about the information world, such as access rights to data, or control over a virtual server.\nThe beauty of this is that we have a lean and unifying framework that ties together services, contracts, resources, control, human and machine communication.\nTool in automation Because we have this common language, we can now use this to describe an interaction process between humans, and then talk about how to automate that interaction. The agents can change from man to machine without the promises changing. We\u0026rsquo;ll have some examples of that elsewhere.\nContracting In the above we have assumed that the promises just exist, fixed and immutable. But we can also apply the theory and language to the creation and modification of these sets of promises.\nHow does the customer know that they can ask for coffee, not to mention being confident that they will not be charged outrageously?\nThat is because the café has a large blackboard on the wall that effectively says:\nWe promise that, if you ask us to promise to bring you coffee, we will do so, under a set of conditions.\nAnd there are a lot of conditions. The price is just one of them. The conditions aren\u0026rsquo;t all set by the café. They can also originate from civil law, for example, or local municipality regulations.\nBy the way, in promise theory you can never ask an agent to do something. You can only ask them to promise to do something.\nIn this scenario, you enter into a contract implicitly the moment that you place your order. If you only order a single coffee, there is not much distinction between the contract and the order. But if you are in a multicourse meal in a restaurant, it is different. You have a contract when you accept the table. Then there will typically be a sequence of food and beverage orders that will be rolled up into a single payment. Typically.\n","permalink":"/book/diginfra/promise-theory/","title":"Promise Theory"},{"content":"For many people, the word power has a negative connotation. They\u0026rsquo;d rather avoid using power altogether. I can feel that, and I can definitely feel that about the abuse of power.\nBut does that make it unethical to talk about power? Power is everywhere, and conflict too. There is no society without a power structure. There are always differences of opinions in any group, if only to decide when to have lunch.\nWithout exercising power, no group will survive, likely to the detriment of its members. A former colleague of mine, who served as a lieutenant of an armored infantry platoon, shared many leadership lessons with me. One crucial lesson was that as a combat vehicle leader, your job is to use your power to choose and enforce a direction in which the group moves as it exits the vehicle in a battle. It does not matter which direction, as long as everybody moves in the same direction. To do otherwise endangers the group. Following the direction of the leader, and their power, is not a concession or a compromise in this case, but a survival tactic.\nAnd when it comes to power abuse, we still need to understand the power in order to understand the abuse, and our possible response to it. As the famous general Sun Tzu allegedly wrote more than 2000 years ago: \u0026ldquo;If you know the enemy and know yourself, you need not fear the result of a hundred battles.\u0026rdquo;\nThis understanding of power structures extends to our modern contexts as well. For example, creating digital infrastructures at scale requires agreements on technical standards. organizations like the Internet Engineering Task Force and the World Wide Web Consortium (W3C) create standards that are subsequently used to enforce collaboration on interoperability. This resolves conflicts between individual companies and benefits all of them. Successful Open Source projects have clear governance structures which balance power and interests of individuals with that of the community as a whole. Linux, Apache and Mozilla are great examples here.\nThere is therefore no shame in studying power. On the contrary, it is morally necessary to reach common objectives and avoid abuse. Let\u0026rsquo;s continue by diving into some specific power roles.\n","permalink":"/book/power/ethics-of-power/","title":"The moral necessity of talking about power"},{"content":"Automation is a big part of IT, but not all automation brings value. Automation takes time and effort, upfront, and any benefits come later.\nThink of the IT projects you were involved in, most of those aimed at providing a measurable benefit somewhere.\nThis diagram (from xkcd, a series of webcomics) illustrates when automating repetitive tasks, or even just parts of them, brings benefit. In other words, is there a business case for such an intervention?\nThe objective of this diagram is to show how much time you can invest in automating tasks. You can think of tasks such as:\nreducing 3 clicks off a digital workflow converting a spreadsheet to another data format scheduling an appointment looking up some research running a test installing a new version of a piece of software saving a piece of evidence for an audit setting up an auto reply rule in a mailbox Such manual tasks can be shortened or eliminated with a bit more automation. The top row of the diagram indicates how often that task is done. The left column shows how much time the automation would save, per individual execution of the task.\nEach cell in the table then shows the amount of effort that you can spend on that automation and still have a net positive outcome over five years. The table contains a number of black (empty) cells. My understanding is that these are \u0026lsquo;impossible\u0026rsquo; situations. For example, you cannot execute a one-hour task fifty times a day, according to this table. This is only true, in my opinion, if you assume a single person is doing that task. If a whole team can benefit from the automation, there would be useful numbers in those cells as well.\nEach cell shows what investment would have a five-year break-even point, as it is called, that is: if you spend this amount of time on it, the break-even point will be five years. If only half the investment is necessary, the break-even point will be two-and-a-half years. If only a tenth of the investment is necessary, the break-even point will be six months.\nFor example, if I can reduce the time it takes to do a daily task by one minute, two hours of investment in that will be paid back in about six months.\nOf course this is a simple way of looking at those business cases. This does not take into account other costs or benefits. A couple of examples of that:\ncomputer usage is not included as a cost maintenance over the five year period is not included the use case you are automating could change drastically in five years, making your automation obsolete automation often leads to more consistent quality, especially as you use it more often, a great example of that is in automated testing All of this uncertainty favors focusing on automating tasks where the benefit substantially outweighs the cost.\n","permalink":"/book/value/automation-business-case/","title":"The Automation Business Case"},{"content":"There are many ways to influence and control a system, but one of the most controlled (pun intended) ways is to use feedback loops.\nLet\u0026rsquo;s start with an analogy first: driving a car.\nIf you want the car to stop as fast as possible, it suffices to push the brakes as hard as you can. But that does not give you much control. For example, your passengers might not like it, and it leads to wear on the tires. If you want the car to stop at an intended location, for example just in front of a traffic light, you apply a feedback loop.\nAnother example is keeping the car in the proper lane on the road. Such a loop starts by observing the state, asking: where are we driving? Then we figure out how that differs from the middle of the lane, which is presumably where we want to be driving. Based on that difference (the error) we turn the steering wheel. That is the control we apply. The car will respond, after which we can observe a new state. This closes the loop. We feed back information from observing the car into the control.\nCars are full of feedback loops. Some are mechanical, some automatic, some have a human in the loop. And some exist outside the car, such as traffic control systems.\nWe typically want the feedback loops to keep (or bring) the system in a specific state. In our car example: we want the car to be driving nicely along the highway.\nFor the feedback loop to lead to this result the feedback should be negative, meaning that deviations from the desired state are counteracted, instead of amplified.\nThere is a lot of theory on these types of control systems, for example to figure out if they work fast enough at an acceptable cost.\nLet\u0026rsquo;s look at some examples of feedback loops in digital infrastructures.\nLarge websites have so-called autoscalers. If the load on the website increases, for instance because the website is suddenly in the news, or it is Black Friday on a shopping site, the autoscaler can spin up more webservers to handle that load. It acts by observing the web traffic and the delays in handling that, and controls the amount of servers that are active.\nIn the early days of the internet, I advised a retail internet service provider. At the time, those were independent companies, not part of the telecommunication companies. They were growing very rapidly, and as a result they experienced quality issues. Consumers found that web downloads were too slow, and threatened to leave. The cause of this was that the company was not adapting its connection to the internet fast enough. That connection was a large part of the cost of running the provider, so they did not want to buy too much too early. To fix this, I created a control rule through which they could better balance between spending too much on bandwidth and disappointing consumers.\nFeedback also makes AI deep learning systems work. The neural network is given a series of training data. The output is checked for correctness, and on the basis of the errors, the weights in the network are adjusted. Repeat this long enough on enough processors, and the errors will drop. The network has then learned.\nFeedback loops are everywhere.\nWhen you download a large file from a server, the server will adjust its sending rate to whatever the network and the receiver can handle. When a cloud provider gets more customers, it will adjust the server capacity it has, and it will also adapt the staffing of its support center. In cybersecurity, we observe the patching level of software components against known vulnerabilities, and update the software as needed. Understanding feedback loops helps you understand how control can be applied.\n","permalink":"/book/change/control-feedback/","title":"Control Through Feedback Loops"},{"content":"Once we understand promises, contracts between agents now become really simple to express. They are a set of complementary conditional promises: \u0026ldquo;If you do this, I will promise that\u0026rdquo;. In our example this looks like the following.\n\u0026ldquo;If you promise to pay me, I will promise to bring you coffee.\u0026rdquo; \u0026ldquo;If you promise to bring me coffee, I will promise to pay you.\u0026rdquo; If one party does not keep its end of the bargain, the other party is free to withdraw from their part of the deal. Of course there is the complication that somebody has to deliver first: do you get coffee first, or do you have to pay first? This requires trust. As you are probably aware, both types of contract exist in real life. In fact you can find more complicated versions as well.\nIt is typical to have additional promises for any deviations from the happy path. An example would be: \u0026ldquo;If you do not pay for your coffee, I promise to call the police\u0026rdquo;. This is a simple approach. We will discuss later how we can model trust and trust violations.\nOne way to sum it up is by this question:\nWhat do I do, what do you do, what do I do if you don’t?\nThis was the longest English sentence I made that only has monosyllabic words. I had a rap song produced from it.\n","permalink":"/book/diginfra/promise-contract/","title":"Contracts are complementary promises"},{"content":"Digital infrastructures serve, nearly always, multiple customers. These customers therefore share the resources provided by these digital infrastructures. With that sharing comes the potential for conflicts over those resources.\nWhen I talk to my friend over the phone, we share a connection, and that is exactly when sharing is part of the value of that infrastructure. But when multiple users draw computer capacity from the same pool, there is a risk that the pool is too small, and some users will not get the capacity that they require.\nThat is a conflict of interests, and it can play out in a variety of places.\nWhen the service is offered on a market (as is the case with a public cloud provider), the conflict is between the provider and the consumer, who are not getting what they think they have contracted. Secondly, there is a conflict between the delivery team, who are not getting the resources that they need to realize the service level objectives, and the sales teams who have sold more than can be delivered.\nIn an in-company situation (for example, a private cloud), the conflict is more likely to occur out between various internal consumers. I have seen more than one example where a department with a lot of ego and budget manages to get their way at the expense of less politically savvy departments. Bullying your way into monopolizing resources may be effective for the bully, but it is not necessarily the best outcome for the organization as a whole.\nThat is a governance issue, and there should be leadership supervising these conflicts and setting policies for their resolution. Failure to do so is a failure of governance and leadership. We\u0026rsquo;ll talk more about that in another unit.\nFor the moment we\u0026rsquo;ll end here with the observation that in digital infrastructures it can involve technical and architectural insight to understand these resource conflicts and the means through which they can be resolved. I have seen governance fail in these situations because the leadership is not properly educated on these finesses.\nFor example, capacity in an infrastructure setting could refer to storage, bandwidth, or processing power. These differ seriously in how their capacity can be managed.\nWhere understanding is missing, politics, power, and ego, fill the void.\n","permalink":"/book/diginfra/shared-service-conflict/","title":"Shared Services Lead to Conflicts"},{"content":"Controls Microsoft: Countermeasure (or control). A safeguard that addresses a threat and mitigates risk.\nTo be continued.\nwhat other assets?\nWhere did that file go? Where did you leave that address? Who changed your password?\nOnce we have assets and risks identified, we think of ways to minimize these risks. Those ways are called controls or measures. If you have read through an IT risk management book, many of these should be familiar. For the rest of you, here is a brief outline of some control examples for data.\nClassification: organizing data in various categories. This could from public to top secret, with a few in between. This is not really a technical control, but rather a means to apply specific controls on that data. Labelling: similar to classification. Data labels can relate data to specific use cases, such as development versus production, specific applications or owners. One neat way to organize risks is according to a data lifecycle model.\nCreate: classify, label Store: encryption Use: logical controls Share: DLP, encryption Archive: asset management Destroy: crypto shredding (encrypting and deleting the key) ","permalink":"/book/risk/controls/","title":"Controls"},{"content":"walk in with well spelled out risks, a clear connection to business impact, data, a mitigation plan, and measurable targets.\nProviding third-party assurance enables the board to deliver on its risk management responsibilities.\n","permalink":"/book/risk/mitigation/","title":"Mitigation"},{"content":"Computers are terribly reliable, in general. Today\u0026rsquo;s computer systems execute millions, even trillions, of instructions each second, with an error rate that is inconceivable in other technologies. Yet, if you have hundreds of thousands of machines, you do need to take care of failures.\nIn the early days of Google growth I read an article about their error numbers (a Google cluster has several thousands of machines):\nIn each cluster\u0026rsquo;s first year, it\u0026rsquo;s typical that 1,000 individual machine failures will occur; thousands of hard drive failures will occur; one power distribution unit will fail, bringing down 500 to 1,000 machines for about 6 hours; 20 racks will fail, each time causing 40 to 80 machines to vanish from the network; 5 racks will \u0026ldquo;go wonky,\u0026rdquo; with half their network packets missing in action; and the cluster will have to be rewired once, affecting 5 percent of the machines at any given moment over a 2-day span, Dean said. And there\u0026rsquo;s about a 50 percent chance that the cluster will overheat, taking down most of the servers in less than 5 minutes and taking 1 to 2 days to recover.\nA 2024 report puts storage drive failure rates at about 1.35% per year. With thousands of drives, failure is not an option, but a certainty.\nThese look like interesting considerations for both hardware and software planners.\nAdrian Cockcroft, while he was CTO of Netflix around 2010, summed it up as:\nSize breaks hardware\nNo matter how good your hardware is, if it becomes big enough, it breaks. In his view you therefore need to solve reliability problems in software, not in building better hardware.\nAs Google say:\n\u0026ldquo;Our view is it\u0026rsquo;s better to have twice as much hardware that\u0026rsquo;s not as reliable than half as much that\u0026rsquo;s more reliable,\u0026rdquo; Dean said. \u0026ldquo;You have to provide reliability on a software level. If you\u0026rsquo;re running 10,000 machines, something is going to die every day.\u0026rdquo;\nThe business case for this is that you will have to invest in software for reliability. Once you have done that, the hardware reliability no longer matter, within certain bounds, and you are financially better off with cheaper hardware.\nThe next thread of thought then becomes on which software level you can best provide that reliability. At Google a core technology for that was Map/Reduce, which is a \u0026lsquo;middleware\u0026rsquo; software layer on which resilient applications can be build. We\u0026rsquo;ll cover that in another unit.\nFinally, scale does not only break hardware, but also organizations. For example, a task that takes half a day every week can be done by a single person. When the volume increases tenfold, this becomes a fulltime job. When the volume increases a hundredfold, you need a small department to do it, and with that comes a whole range of coordination and management tasks. That introduces a lot of communication overhead. Without being compensated with economies of scale, this can make the task too expensive to do.\n","permalink":"/book/diginfra/things-break-at-scale/","title":"Things Break at Scale"},{"content":"What do roads, airports, the internet, the electricity network, and a search engine have in common? They are all services that are independent of a specific user or usage. They are provisioned on a longer timescale than that of an individual usage. And they are typically not owned by their users, or at least, not directly.\nIn this book I am mostly concerned with digital infrastructures. Their services are digitally accessible. Of the above examples, the internet and the search engine are the best examples of that. Interestingly, the other services increasingly rely on digital infrastructures themselves, or even incorporate specific digital infrastructures. Trading platforms, for example, enable the planning of electricity supply and demand. In many countries, electricity is a market, not a monopoly, which requires coordination between the various players.\nYou\u0026rsquo;ll also see that I talk about digital infrastructures as a service, not a product. It is not sufficient to buy a road, for example. For it to be truly useful to its users, it needs maintenance, repairs, incident management, and more. Any abandoned road will soon deteriorate without maintenance, and become useless.\nDigital infrastructures are sometimes called platforms. In the 1990s Windows was an example of a platform. A few decades later the concept of platform engineering started to be used for services that helped developers develop and deliver code faster.\nDefining it with scientific rigor is difficult, much like unambiguously defining what a car is. There will always be edge cases.\nWhat sets digital infrastructures apart, in my opinion, is that, thanks to automation, their scale, geographical reach, and deployment speed, can be orders of magnitude greater than that of other infrastructures. That has a lot in interesting effects, which we\u0026rsquo;ll explore in this book.\nIn summary, digital infrastructures are about services that organizations deliver to independent consumers, while at the same time these services are subject to automation. That gives a tremendous dynamic in that relationship, and leads to new value, new power, and new risk.\n","permalink":"/book/diginfra/essence-digital-infrastructures/","title":"The Essence of Digital Infrastructures"},{"content":"While Artificial Intelligence, especially the generative type, is a highly disruptive form of IT innovation, its risk management still follows the same basic principles. We just need to extend those principles to new forms of data and software.\nWhat are the assets? What are the vulnerabilities and threats to it? What is the damage that this can bring, realistically? So let\u0026rsquo;s see how what the AI specifics are.\nAI Assets Let\u0026rsquo;s focus on the AI assets that are the product of deep learning. Deep learning neural networks have represented a shift in AI technology. Before that, symbolic AI was more common.\nThe reason to elaborate on this is that there is a fundamental difference between symbolic AI and neural network AI. Symbolic AI works by following programmatic rules, and is fairly deterministic. Neural networks are the result of training with large datasets. They have enabled generative AI which is much less deterministic.\nFurthermore, and this is really significant from a security perspective, in its operation, GenAI mixes data and instruction to operate on that data deeply.\nFor example, anything an external user inputs to the system as data, might also be interpreted as an instruction. This represents a huge vulnerability for hackers to exploit.\nThe trained models represent a lot of information, and that information is often hard to identify, and therefore to see the classic information risks of.\nModels are effectively software: you stick data in them, and data comes out. But because they also embody a lot of data (we are talking Gigabytes, Terabytes and beyond of training data) they combine the risks of software with the risks of data.\nAn AI system has a few more traditional and less traditional data assets associated with it. Base models, or foundational models, such as Llama, often get additional training or finetuning. The data used for that may well include proprietary or sensitive data.\nThen there are system prompts and additional data sources that are fed into those models, together with user input.\nAI Vulnerabilities Damage ","permalink":"/book/risk/querying-ai-risk/","title":"What about AI Risks?"},{"content":"How to fix the WiFi? How to find a new phone for grandma?\nApplying technology follows certain rules. However, many people only have an intuitive understanding of these rules. As a result, technology is not optimally applied. By understanding how applying technology really works, you can be more effective, more efficient, reduce waste, and overall do a better job. It takes just a few simple steps to improve any attempt at applying technology. We\u0026rsquo;ll focus on information technology here, though most principles have wider applicability.\nLet\u0026rsquo;s start by looking at a few examples that I have used in teaching IT students. The first example is fixing the WiFi at home, and the second one is selecting a new mobile phone for grandma. Think for a moment how you would approach these two cases. If you want a more corporate example you can think of replacing a content management system, or introducing a new security capability.\nThe core idea of technology is that by doing an intervention in the real world, you achieve certain desirable outcomes. This is in contrast to the core idea of science, which is that by doing observations on the real world, we can derive certain conclusions that allow us to predict what might happen under similar conditions in the future. Science seeks to understand and explain the underlying principles governing phenomena, while technology applies that understanding to create tools, systems, or processes that achieve specific goals.\nOf course, science and technology are intertwined: technology relies on scientific insights to be more effective, while science often needs technology in order to do experiments and observations.\nAs our ambition is to apply technology in a bit more systematic way, let us begin to ask ourselves what it is that we try to achieve.\nBy the way: technology literally means the science of technics. In English there is not much of a distinction between techniques and technology.\nA technique aims to achieve a certain desirable outcome. Interestingly enough, the attention is often on the technique, and a little less on the outcome. I find that focussing on the outcome first is a productive and relevant thought exercise.\nLet\u0026rsquo;s review our examples. What does fixing the WiFi mean? What result does it achieve? This could be many things. Maybe we want a better internet experience in the back of our garden or on the top floor? Maybe we want to have higher internet speeds inside the house. Maybe we want less packet loss. Maybe we want to play our games with less ping delay, so we can win more often. Maybe we want to allow our friends easier access, or more security.\nThe essence of the result is that some measurement of quality improves for some stakeholder.\nTurning our attention to grandma\u0026rsquo;s new phone, what do we want to be improved? Maybe her current phone is too hard to navigate because the buttons are too small, or it does not run an app that allows her to see the pictures of her grandchildren. Or maybe it breaks down all the time, and your tech savvy nephew has to come over to fix it, and he does not want to do that as often anymore.\nNow we can turn our attention to the intervention. In our WiFi case, are we buying more access points, and if so, where should they go, and how should they be connected? Maybe we want to change the frequency allocations, or allow use of the 5GHz frequency bands. With grandma\u0026rsquo;s phone, do we install new apps, buy a different size phone, or what?\nHow does the intervention lead to the desired result? In other words: how does one lead to the other? Maybe you have a (scientific) theory about that. Maybe you\u0026rsquo;ll just need to figure it out. In both cases, you start with a hypothesis that explains how the intervention leads to a result.\nFor example: because WiFi signal strength (and therefore quality) decreases with distance between device and base station, we install more base stations in order to have better quality around the house. Another example would be: because there is limited frequency spectrum, we reconfigure our existing base stations to use different frequencies in order for them to interfere less, and have better network quality within their range.\nAs you can see from this example, your assumptions, your hypotheses, matter.\nWe can morph these statements in a variety of useful ways. This is what makes for professional application of technology. Here are some variations.\nBy theory Z, we do intervention X to achieve result Y.\nWe hypothesize that intervention X will lead to result Y, in which case we can start to form a theory.\nHow does intervention X lead to desirable outcomes?\nWe are looking to achieve result Y, and we have theory Z. What does that tell us about possible interventions?\nOnce we grasp this, we can move on to more complicated scenarios. We can flesh out what a better outcome is. We can use this to do design in more complicated situations such as with more stakeholders. We can also use this to do more systematic troubleshooting.\nMore about that later.\n","permalink":"/book/change/technical-meta-model/","title":"Systematically applying technology"},{"content":"Consumers of digital infrastructures benefit from not running them themselves, but having a provider who serves more consumers do it for them.\nImagine stringing a wire to connect your PC to your neighbor\u0026rsquo;s PC in order to play a game together. People have been doing these things. How long does it take to string the wires and connect them? What is the cost? Where do you buy the cable? How are you going to run that cable? It is a lot faster to just use the internet for that.\nThe introduction of a separate provider changes the provisioning process. For one thing, the provisioning can go much faster. The provider has capacity (stock so to say) that can just be used. Related to that is that the service is already defined by the provider. Instead of designing it from scratch, you just pick one of the options offered. Presumably, that option has had a lot of design and thinking behind it already. It is likely to be a better option than anything that you can think of yourself.\nSo, that brings value: it can be faster and better than your homegrown alternatives.\nBecause the provider has multiple consumers, there are economies of scale that play out. Whole books have been written on this, and we will be looking into that in more detail. Think of sharing of unused capacity. Not everybody is using their internet link to the max all the time.\nBut \u0026lsquo;digital\u0026rsquo; brings more specific benefits. It is the opportunity to automate service delivery that has immense effects on economies of scale. Think about it: if a piece of software does its work, replicating that piece of software across a lot of servers is a negligible amount of effort in comparison to creating that software, typically. In contrast, baking 1000 pizzas is a lot more work than just baking one or two.\nFinally, consumers can find value in being connected with other consumers. There is transactional value in that, to arrange or discuss matters, but for most people there is emotional value in being connected to other people. The value of a phone or social network to the individual users, not just the network owner, increases with the number of other users connected to it. As a result the value of the network increases quadratically with the number of users. This has implications for the power balance, as we will discuss later.\nIn a later unit we\u0026rsquo;ll discuss some of the words that economists use for these phenomena, such as investment externalities and network externalities.\n","permalink":"/book/value/intro-to-value/","title":"Provider Value"},{"content":"Shared resources can lead to conflicts. If the capacity runs out, somebody will feel the pain at the expense of somebody else. This conflict will be resolved in one way or another. Without other arrangements, the stakeholder with the most power wins. This is not necessarily the best outcome for the organization as a whole.\nTo illustrate this, I gave ChatGPT the following prompt:\nWrite a business case story about the conflict over shared computing resources.\nAnd here is what it answered. Admittedly, the situation of a single server is a bit old-fashioned. Nevertheless, the principles hold. Identify some governance concepts in this story.\nOnce upon a time, there was a small startup company called TechPro. They were a team of software developers who needed to use shared computing resources to complete their work. Initially, they all worked on their personal laptops, but as their team grew and their projects became more complex, they needed to access more powerful computing resources.\nAt first, they decided to use a shared server hosted on-site, but soon they started to experience conflicts over access to the server. Some developers needed to use the server for extended periods of time, while others only needed it for short bursts. Additionally, some developers needed more computing power than others, which led to contention over who had priority access.\nAs the company continued to grow, these conflicts started to have a significant impact on their productivity. The developers spent a lot of time coordinating access to the server, which led to delays in completing their projects. Some developers even started to look for alternative computing resources outside of the company, which led to security concerns.\nThe CEO of TechPro recognized the severity of the problem and decided to take action. She tasked the IT department with finding a solution that would allow for fair and efficient sharing of computing resources. The IT department evaluated various options, including adding more servers, using cloud-based resources, and implementing a queueing system for access to the server.\nAfter careful consideration, they decided to implement a queueing system that would prioritize access based on the urgency and computing needs of the tasks. This solution would allow for fair access to the server, as well as efficient use of the resources. The IT department also provided training to the developers on how to use the new system and established clear guidelines for resource usage.\nThe implementation of the new system was not without challenges, as some developers were resistant to change and preferred the old way of accessing the server. However, with clear communication and support from management, the developers quickly adapted to the new system.\nAs a result of the solution, TechPro\u0026rsquo;s productivity increased significantly, and the conflict over shared computing resources was resolved. The developers were able to complete their work without delays, and the company was able to retain control over their computing resources. The CEO was pleased with the outcome and praised the IT department for their innovative solution.\nAs an exercise, see which stakeholders you can identify in this example. You can also think of residual risks of this solution, and other approaches.\n","permalink":"/book/power/governance-example/","title":"Governance over IT, an example"},{"content":"An important part of managing digital infrastructures is updating various software components. It does not matter if we are talking about operating systems, applications, AI models, configurations, software libraries, and so on.\nWhat matters is: who is going to do that?\nUpdates happen for many reasons, but the major ones are:\nnew functionality better security. As you can imagine, there are different stakeholders for these changes, and different skill sets required.\nIn today\u0026rsquo;s environment, whether we are using cloud or not, there is a division of labor and expertise. This can be within a company, or across many service providers. Figuring this out is an example of applying shared responsibility models. Ideally, a cloud service comes with a clear shared responsibility model that explains who is supposed to do what. What is it the cloud provider does, what is an external service provider doing, and what should cloud consumers do themselves?\nA great way to then detail out the responsibilities is by using the terminology of promise theory, which is discussed elsewhere in this book. In brief, it breaks down interactions into promises that are made and fulfilled.\nHere are some examples from service providers:\nWe promise to prevent unauthorized access to these systems. We promise to maintain a particular system according to vendor best practices. We promise to make sure that there is a spare copy of your data off site. We promise to apply updates and improvements. We promise to answer your call to the service desk. It is not just about doing tasks, it is also about specifying what the conditions and outcomes are. You don\u0026rsquo;t just want updates done, you want them done within a certain period of time. In that way, others can depend on that, with less coordination and overhead.\nA SaaS provider promises to update its operating systems, libraries, configurations, for example. An IaaS provider does not promise to update the operating system on your virtual machine. In fact, they might even promise that they will not have access to it.\nMost people are familiar with calling a service desk (or customer support in general) for help.\nHistorically, this has often been a frustrating experience. That is why it is important to have quality attributes with them, such as \u0026rsquo;time to respond\u0026rsquo; (which typically means, the time it takes for somebody to start working on it), and escalation paths.\nFor software updates, you can think of quality attributes such as time to update after a new version has been tested.\nIn a complex multi-provider environment, one of the most important things about promises is, who is making them. Many security issues have been the result of a responsibility falling in the cracks between two parties, where both think the other is taking care of it.\nDigital infrastructure management requires clearly defined responsibilities and quality promises from all parties to ensure timely and secure updates, preventing security gaps due to ambiguous responsibilities.\nYes, the real world can be a bit messy. But I have found promise theory a great tool to help clean some of it up.\n","permalink":"/book/change/promise-to-update/","title":"Promise to Update"},{"content":"The US president Harry S. Truman famously had a sign on his desk that said:\nThe buck stops here.\nThis refers to the process of \u0026ldquo;passing up the buck\u0026rdquo;, meaning to escalate decisions to the next higher level in the organization.\nTruman implied that he took responsibility but also that this is where power comes from.\nThis is an essential part of governance, and this vertical line of responsibility represents one way of looking at it. We can trace how this works in the following risk management example.\nSuppose one risk control is to stop a certain data flow at some point. For example, not allowing USB storage keys in laptops, or reducing the permissions of some people, or reducing network access for guests.\nThis is a security intervention at the lowest, technical, layer.\nBut who has the responsibility to review whether that is actually done? That is a different layer of technology, or maybe of human oversight. If you do not have that, the control may not be very effective.\nNext up, you might ask who created the policy that these data flows need to be restricted? Again, this is a next higher level of responsibility.\nContinuing, who checks that this policy is set, who decides that this type of policy is set, and for which types of data?\nAs we progressively get higher and higher, these policies (controls) will be more and more abstract. They will be controls on controls.\nNow, if you are in a role in the organization where you find no higher-level control, you are the highest level control.\nThe thing is, the person with the highest level control, should also have the mandate and the budget to enforce it. Ideally, this is the most senior management in the organization. And with today\u0026rsquo;s regulatory environment, they are.\nI find this way of looking at governance more insightful than a top down approach. The risk of a top down approach is that a general control just gets translated into more controls with more text that are still not technical enough to be implemented or enforced.\nYou should be able to go up, down, and back to make sure that the technology controls match the objectives of the organization as a whole. This also helps to understand which controls are superfluous or redundant.\n","permalink":"/book/power/buck-stops/","title":"Where the buck stops"},{"content":"Trust is an essential element in any collaboration. We want to trust things, people, and organizations to do the right thing, to keep their promises. Without trust, we will not be able to have confidence in the contribution of others, and that is a risk.\nAnything we don\u0026rsquo;t trust is a risk. Anytime we assume trust that is not warranted is also a risk. That is one of the core concepts of Zero Trust Security Architecture.\nTrust can also be something that is fairly technical, as in: can I trust the webserver to be up all the time?\nTrust is an elusive concept, but I do have a couple of ways of looking at it that I have found very useful, because they work in the real world. One is from \u0026ldquo;the Prisoner\u0026rsquo;s Dilemma,\u0026rdquo; which is a story from game theory. Another is \u0026ldquo;authority,\u0026rdquo; which is basically \u0026ldquo;I trust somebody, because somebody tells me so\u0026rdquo;.\n","permalink":"/book/risk/what-is-trust/","title":"What Is Trust"},{"content":"In 2005 I visited my father in France. It turned out to be convenient to pick me up from the Gerona airport in Spain. And as we had enough time, we had lunch in La Jonquera.\nAt the restaurant\u0026rsquo;s checkout I noticed a peculiar array of devices: there were four payment terminals.\nI\u0026rsquo;d never seen that. From what I know, a merchant works with a bank which handles all their payments. Apparently not over here.\nA closer inspection revealed that each was associated with a different bank. So apparently, depending on the bank that a customer of the restaurant works with, the restaurant needed to have a payment terminal associated with that.\nTo me, this does not sound optimal for the merchant. It takes money and on the desk to accommodate all those different payment networks. And if you have only one terminal many customers can\u0026rsquo;t pay by card. That won\u0026rsquo;t make them happy, and the last thing you want as a merchant is to have unhappy customers.\nAn online payment system, in this case with cards and terminals, is an infrastructure. and arguably a digital infrastructure. It serves many users: customers, merchants, and in this case the bank. One infrastructure for each bank.\nIt sounds obvious that there is a benefit in having a digital infrastructure like this that serves most banks, instead of just one. For example, you would not have to replicate installation and maintenance of those payment terminals. And indeed, in the current day and age, it seems to be the normal thing to do.\nBut apparently, it was hard to get to such a common system. So hard in fact, that it made sense for the banks and the merchants to waste all that money on replicating an infrastructure and foregoing all the benefits of a shared system.\nThere are a few hypotheses on why this is so.\nLet\u0026rsquo;s analyse this and see what causes this situation.\nFor one, services like these don\u0026rsquo;t appear out of thin air. They evolve. They don\u0026rsquo;t come into existence and remain stationary forever. There are actors and stakeholders that make them change.We\u0026rsquo;ll have to look at the actors involved and their objectives and possible actions if we want to understand how such systems look like at any given moment.\nThe main actors involved here are the bank(s), the merchants and the customers. When it comes to actual payments, these are the most important ones.\nThe banks probably expected to reduce costs and have more happy merchants and customers. And having this benefit earlier rather than later probably compensated for the higher cost of building out your own digital infrastructure for your merchants.\nWhile it would be cheaper overall to have a digital infrastructure that is shared across all banks, there seems to be a valid reason to not have that, at least not to begin with.\nMy hypotheses are: it takes time to agree on standards for interoperability and for actually setting up the service that is shared across banks. Not the least of your problems is who is going to own that infrastructure. It is likely to be a new legal entity. And that introduces a new stakeholder.\nNow back to the power dynamics that created the situation in the picture. Who benefits, who does not?\nThe banks are faced with a choice between the short term gain of realizing a payment infrastructure, and the long term gain of reducing its cost. And as they are investing, they have some power.\nThe merchant can chose between having multiple terminals, or sticking to just one, which amounts to a choice between spending money (and desk space) versus making customers unhappy.\nFinally, the choice for the customer is to pay cash or by card. The customer (and the other stakeholders) probably think that cards are a safer, and possibly cheaper alternative. The customer might therefore be led to feel that they prefer a merchant who accepts cards.\nThe banks and the merchant apparently prefer short term revenue increase over long term cost savings.\nAnd as a result the power dynamics play out so that it is the customer who benefits, the banks that invest and reap more benefits, and the merchant has to pay for a lot of that. Maybe the merchant will see some cost reduction in their payments handling.\n","permalink":"/book/diginfra/lunch-spain/","title":"What a lunch in Spain taught me about digital infrastructures"},{"content":"One of the key aspirations of Digital Infrastructures at Scale is to equip you with the tools to shape and drive change in your professional environment—especially when your goal is to lead a transformation.\nEvery stakeholder has power. Here I want to highlight two important positions of influence in IT where technology meets power are architects and auditors/assessors.\nIT architects are builders. They design new applications, platforms, and infrastructures that enable businesses to operate more effectively. A CRM system, for example, is not just a technical solution—it transforms workflows, communication, and decision-making. Similarly, infrastructure architects create digital foundations that accelerate the deployment of such applications.\nAuditors and risk assessors, on the other hand, focus on preventing failure. Every technology introduces risks, and without proper attention, these risks can derail progress—whether through security breaches, compliance fines, or operational breakdowns.\nBoth roles involve power. Without power, things will not move in the way you want, and every initiative encounters resistance. Understanding the sources of power—and the forces that push back—is essential for you to achieve meaningful outcomes.\nMoney is a form of power, but it is often a blunt instrument. In organizations, other forces—such as survival and strategic priorities—can be even more influential. The key to driving transformation is linking these forces together with precision.\nThis book provides you with the frameworks, insights, and real-world examples to navigate these challenges and drive successful change.\n","permalink":"/book/power/positions-of-power-it/","title":"Positions of Power in IT"},{"content":"Infrastructures are nice, but the applications that they enable are where the value of information technology is. Applications store and process data, so an application is roughly a data model plus a certain number of functions operating on that.\nA word processor is an application. Its data model is formatted text, and the functionality allows you to manipulate that text. Another example would be gmail, whose data model is a set of messages, and the functionality allows you to manipulate the messages and their flow.\nThat is a simplistic view, but a good start from the perspective of understanding who is doing what.\nNetworked applications typically live on servers, but will have a client component.\nDigital infrastructures are made up of processors, storage and networking. The costs of these change rapidly, but at different rates. Memory is becoming cheaper a lot faster than processing, and network bandwidth prices are dropping slower than that. The cost of humans to manage this technology is dropping slowest, if at all. What this means is that there will be continuing shifts in what the optimal design is for networked computing.\nNow for the research questions. How fast is it actually changing? How do we organize this, technically and people wise, in order to control the cost, improve the quality, and speed up the change and development process?\nFor example, technology development in this area is very much structured by standards. This allows people to collaborate on the design of system components so that those components then later work together. These standards can be set by a vendor for example, or agreed in a standardization committee. What is the dynamics of that?\nIn which way can we best organize the development and in particular the management of large digital infrastructures?\n","permalink":"/book/diginfra/applications/","title":"Applications and Infrastructures"},{"content":"Power does not automatically flow from those that have it to those that are influenced by it.\nAs they say in dutch, quoting the poet Willem Elsschot: \u0026ldquo;tussen droom en daad staan wetten in de weg, en praktische bezwaren\u0026rdquo;. (\u0026ldquo;between dream and deed stand laws in the way, and practical objections\u0026rdquo;).\nWe want to understand this. If we want to exercise power, we need to understand the intermediaries. If we want to subvert power, the intermediaries are one of our disruptive points.\nThe power intermediary aids in applying power. They are like the forward observer in an artillery unit. They don\u0026rsquo;t have the artillery power themselves, but they definitely influence how it is applied. Knowledge is power, as they say.\nAnd there are many more examples of power intermediaries, and many more words that are used to describe that function. You can think of: power broker, facilitator, mediator, intermediary, but in our digital infrastructures world, we can be more specific.\nLet\u0026rsquo;s take an example situation. Suppose the board of a company wants to set a digital strategy for the company, who is in the end implementing and realizing that strategy? Or, the board wants to demonstrate control over the resilience of the organization to cyber risks. In the end, that requires a lot of people and roles, for example in building systems, or doing incident response. Many of these roles are, in fact, power intermediaries, because they facilitate the flow of the board\u0026rsquo;s power to the places in the organization that matter.\nAs we discuss elsewhere, this involves people, process and technology. I also elaborate on two specific positions of power elsewhere: the architect, and the assessor, although they are by no means the only ones.\n","permalink":"/book/power/power-mediation/","title":"Power Flows"},{"content":"What do a laptop, a smartphone, and a smart thermostat have in common with a browser, a database, and a data center?\nThey are all execution environments that contain software and data, and that makes them building blocks for deploying digital infrastructures. In a diagram we often depict them as a box, or an oval. Inside the box, software gets executed, instructions get interpreted, actions are done. Software without execution is just dead data.\nWhy does it matter? Well, the more we know about those building blocks, the more efficient we can think about all the various manifestations of execution environments. For example, these things, or more accurately: their boundaries, are prime locations for implementing security controls.\nWhenever I look at how a digital infrastructure is implemented, I start by looking at the execution environments, and ask four questions: what, where, how, and who.\nWhat? What is the data that is inside it, what is the software, the code, that is inside that environment? And in an AI world: which model is there inside?\nWhere? Where is that execution environment located? In our current virtualized and cloud world, that environment is typically inside another environment. Ultimately, of course, there is a physical machine in which it sits.\nHow? How does the software get deployed inside that environment? There will be a manual process, or a continuous delivery pipeline, or something similar.\nWho? Who is responsible for managing the environment and its access controls. In a cloud world, this is an important question. What does the provider do, what does the consumer do?\nThen it is time to look at the control boundary that this environment creates. The control boundary creates an outside and an inside. How is data from the outside allowed to go inside? What is the mechanism or protocol? How is that controlled? The same holds for the reverse. How is software inside that boundary allowed to access the outside?\nLet\u0026rsquo;s take an example: your browser is talking to a webserver, which could be a computer that runs Linux and an Nginx instance. The Linux machine implements an access control on the network level: it only allows traffic on the https port to go to the Nginx webserver process. The Nginx webserver then guards its data, and only allows read only access.\nIf you want more examples of execution environments, consider containers, functions as a service such as AWS Lambda, AWS S3 storage buckets, SaaS/PaaS providers, Antivirus agents, firewalls. Each of these has processing inside, and each of these hold data. But the type of software, data, and configuration they have differs, as does the mechanisms they offer for access control.\nDeeper in the networking space you can see that a router is also an execution environment, though it does not have a lot of data, mainly the routing tables.\nWe will return to discussing how useful this is elsewhere.\n","permalink":"/book/diginfra/execution-environments/","title":"Execution Environments"},{"content":"Getting to value quickly has value in itself. The faster you get to value, the better it is, generally. We\u0026rsquo;ll discuss some of the reasons for that elsewhere.\nAgile development is all the fashion nowadays for getting to digital value quickly. Why is that and what kind of digital infrastructures does that require? Back in the old days, business software was primarily written to automate existing business processes. Those processes might change somewhat as a result, but in the core processes were no different. Think accounting systems, scheduling, \u0026ldquo;customer relationship management\u0026rdquo; and so on.\nToday we see that software not only automates these business processes, but becomes part of the product, or even becomes the product itself. And on top of that, this software is often an on-line service. Think of the smart room thermostat. Or financial services, where software increasingly is the main part of the product: think online banking. And in social media from Facebook to Tindr, software really is the product.\nThe development dance Every product changes the world that uses it. Think how cars have changed the way people commute, or even choose where they live. Software is no different. But a changing world also changes the products we can use or want to use. There is a kind of dance between supply and demand. Do we have breakfast out of our house more often because there are more opportunities for this or does the supply of breakfast places increase as a result of us going out more? Just as in a dance, it is not always easy to tell who is leading who.\nBecause software now has become the product it will also participate in the dance, and then it becomes more important to quickly adapt to the dance partner. As a developer, you change the world that uses your software in ways you cannot always predict, so in reaction you have to adapt to that world.\nThe faster the better.\nThis explains the need for agile development. Between idea and realization (time to market) there should not be two years, but only two weeks, and preferably less.\nWhat kind of digital infrastructures does that require? The prime objective of digital infrastructures is to enable the deployment of application functionality. The quality of digital infrastructures used to be measured in the number of users it could support well. I.e. we used to talk about a system supporting 10.000 concurrent users with less than 4 seconds response time.\nBut agile development comes with a new goal: \u0026lsquo;feature velocity’. That is the speed with which new features can be deployed. The time between inception of a feature and its deployment to a large user base has to be shorter than the time it takes for the environment to change. In a dance you want to anticipate your partner, not stand on their toes.\nYour digital infrastructure should not be a bottleneck. This requires features such as automated testing, quick scaling up and down of resources, and as little manual intervention as possible. This is the only way to shorten the lead time for a change.\nCloud computing In summary: agile development requires cloud computing. Remember: the essential characteristics of cloud computing include fast, elastic and self-service provisioning of resources. That is what is required for agile development.\nAnd then the dance continues. Because if we can do that, we can do other new things. Like better security. If you can respond quicker to new functional requirements, you can also respond quicker to security issues.\n","permalink":"/book/value/agile-requires-cloud/","title":"Agile Requires Cloud"},{"content":"From the moment a security vulnerability is discovered, it represents a negative value to its potential victims. When it gets exploited, it can lead to loss of data or loss of integrity of the data. This in turn impacts the victim\u0026rsquo;s business processes.\nFor example, if personal data is leaked, reputations will be damaged, financial losses and fines can be expected. Credit card abuse forms another example of loss.\nThis \u0026ldquo;damage potential\u0026rdquo; increases as the vulnerability becomes well-known, progressing from nation state actors, to organized crime, to script kiddies, just to name one example pathway. At first, few people know about it, but gradually more people will be able to inflict damage with it. Over time, each step adds to the likelihood of that vulnerability being exploited and causing real damage. The likelihood starts at near zero, and ends at close to 100% as the vulnerability is completely public. This only stops when an investment is made to mitigate the vulnerability, for example by updating the software. And hopefully, that investment is less costly than the damage potential.\nThis damage potential resembles the concept of \u0026ldquo;work in progress\u0026rdquo; from lean production. Originally developed as the \u0026ldquo;Toyota Production System\u0026rdquo;, it is also applied to software development.\nFor example, if your team spends three months with five staff members on building a feature, the work in progress is now valued at fifteen man-months. That is an investment, which you will only recover once the feature is delivered and accepted. Only then will you be paid for it, hopefully reflecting more value than you put in as an investment. The mantra of lean production is to reduce work in progress. Work in progress represents a liability: it is capital tied up, and maybe it won\u0026rsquo;t bear fruit. For example, your new piece of software may solve the wrong problem. This is why entrepreneurs love the idea of a minimum viable product, it reduces work in progress. You want to drop bad ideas as fast as possible.\nBack to vulnerabilities:\nThe longer you wait with mitigating a vulnerability, the more negative value it accrues. Fixing it represents an investment, which hopefully has a positive return.\nThere is a parallel with software development. In software development, the net value drops as more money is poured into development, which then returns to positive as the feature is delivered and paid for (figuratively speaking). In cyber security, the net value drops as the vulnerability is accessible to more threat actors, which then returns to zero after an investment is made into its mitigation. Hopefully the cost of mitigation is less than the net value (i.e. damage potential) at that time.\nThis may sound pretty abstract, but I think I will be able to show the usefulness of this approach. It helps us identify where and how investments are most productive in cyber security.\nAt any given moment in time, a stream of new vulnerabilities is thrown at cyber defenders around the world. For example, in 2024 around 40.000 vulnerabilities were published in the CVE database (source). Without additional information, all of these carry a negative value to an organization, as all of them have damage potential.\nWhat investments can reduce the damage potential, and more importantly, which of these have the best return on investment?\nLet\u0026rsquo;s start at the beginning. If you can match vulnerabilities to the software you have, you\u0026rsquo;ll find a lot of them are not relevant as they relate to software you don\u0026rsquo;t have. A proper and accessible software inventory therefore represents an investment that can reduce the total negative value of vulnerabilities.\nCase in point: log4j affected a quarter of the world\u0026rsquo;s organizations. So, without more information, your organization had a 25% chance of being pretty vulnerable. But, if you knew that this software was not in use anywhere, your vulnerability dropped to zero.\nThen, fast forward through the value chain. How can we reduce the negative value of a vulnerability? One way is to reduce the damage potential through segmentation and similar Zero Trust techniques.\nIn a future extension of this unit, we can discuss:\nactor analysis: we have two types of actors here: malicious actors and potential victims, but there are more actors self inflicted vulnerabilities such as misconfigurations the value streams for malicious actors the value stream for security researchers the value streams for security service providers why Zero Trust reduces the negative value of a vulnerability. ","permalink":"/book/risk/lean-risk/","title":"Lean Risk and Economics"},{"content":"Intermediaries, brokers. 3 actortypes (or more)\nAn intermediary adds value between client/server, source/sink I.e. index, filter, conversion, (de)couple (e.g. Relate to ’broker’) Indexen Gebruikersadministratie, ten behoeve van autorisatie en TTP diensten Abonnementadministratie, welke afnemers of belangstellenden zijn er? Bronindex, welke bronnen hebben informatie over een bepaald sofinummer (search engine)? Functionaliteit formaat conversie, filtering vraag/aanbod matching Performance verdelen en routeren van berichten, multicasting aggregatie caching bundeling van afspraken (bijv. SLA)\ndistributor/directory authorization choice / arbitration / load balancer service integration pubsub. Intermediary holds source and subscriber directories. Notice the various commitments that can be made. Examples: newsletter, podcast subscription multicast subscription toepassing: chatbots streaming?\nPattern composition: Tell me the current state, subject to authorization intermediary, then subscribe me to changes\nindexesEen bronindex houdt bij waar welke informatie beschikbaar is Een abonnementindex houdt bij waar afnemers van informatie zijn\nChain gang: CEO Aaron to CEO Betty: please promise to me that Alice can talk to Bob when I have a service request\nCEO Betty to Bob: please promise to me that you promise to Alice to pick up the phone when she calls\nComposition and supply chain. (restaurant waiter, chef) Dynamics of supply chain, jeff sussna.\nService management is organising the keeping of promises. What is the role? Which promise does it keep? What are its clients and providers?\nI.e. Change management (ITIL) Promise to keep an asset inventory Promise to process change requests on the basis of a change policy\nChange management (ITIL) Promise to process change requests on the basis of a change policy ”I promise to allow changes that meet change policy requirements to promote to production” Can be manual or automatic or automatic with exceptions\n","permalink":"/book/power/promise-multiparty/","title":"Promise Multiparty"},{"content":"As we mature processes, they come within reach of actual automation. Especially IT management processes. To paraphrase General Carl von Clausewitz, who said \u0026ldquo;War is the continuation of diplomacy with different means\u0026rdquo;, we can say that automation is the progression of process maturity with different means - replacing human effort with software and systems.\nMy favorite historical example is IP address allocation. In the past, whenever there was a new computer, you would walk up to the head of the lab or data center and ask for a new IP address for that machine. You may remember that.\nYou\u0026rsquo;d go to the person in charge for an IP address, they\u0026rsquo;d pull out their notebook, sharpen their pencil, and note it down. Simple, manual, and not built for scale.\nIn 1994 I went to a Unix systems administration conference and they had Mike O\u0026rsquo;Dell over from the USA. He had a presentation about the internet where he talked about many layers of technology to just push IP packets around. I was impressed by the number of layers back then, but I think what he was trying to say was how wasteful it really was, and that many of these things had to be re-engineered to allow the internet to grow.\nAs a side note, it grew by a factor of 500-1000 in number of users in the thirty years since. At the time of the conference there were about a 1000 websites worldwide, and this conference is the first one listed on the NLUUG website.\nWe talked with him in the bar afterwards, where he said: \u0026ldquo;You know, next year Microsoft\u0026rsquo;s going to come out with a new version of Windows (editor note: Windows 95) and that will have an internet protocol stack built in to the operating system. They\u0026rsquo;re planning to sell 150,000 of those every month\u0026rdquo;. That sounded like a staggering amount. Can you imagine how many IP addresses that will be right? How are we going to manage these? We need more pencils!\nThen he mentioned that Microsoft collaborated with the IETF to define an automated system for IP address allocation. That standard we now know as DHCP, and it is also in every PC and practically every network. It very likely has reduced many errors that happened in the traditional process, such as duplicate IP addresses being handed out.\nWhat we see here is that a process (address allocation) matured enough for it to be automated. Consequently, it can scale up, and it can be of higher quality.\nAnother perspective on this is that this activity largely fades into the background of the system administration domain, and becomes part of the technical digital infrastructure. This is a very common pattern in IT, systems administration, and in digital infrastructures in particular.\nCompare how assemblers and compilers were heralded in the early days of writing software as making programmers redundant. Well, automation did not make them redundant, it just made them write software on a much higher level of abstraction, leading to more productivity and more quality. The same thing happens in systems administration: as parts get automated, admins operate at a higher level.\nIn the late eighties, a university colleague of mine, now a retired professor, was doing his PhD on network management architectures—a concept that was quite elusive at the time. What did network management entail? How would it be standardized? Back then, the idea of computer networks was still new, and automating their management seemed unnecessary because there were so few computers. However, once networks started to scale, network management became much more critical.\nHis research focused on SNMP and similar technologies. Just as DHCP automated address allocation, SNMP helped manage network measurements and settings. Ultimately though, he concluded that network management encompasses everything not yet automated into a protocol. Again, this represents a maturity story: human management handles what we cannot automate (yet).\nThat is the cycle of digital development: from manual effort to mature processes to automation—and then on to the next layer of complexity.\n","permalink":"/book/change/dhcp-automation/","title":"Network Management Automation - the DHCP case"},{"content":"Business Model Canvas The Business Model Canvas is a strategic management tool that serves as a visual framework for developing and discussing business models. For additional information, see http://en.wikipedia.org/wiki/Business_Model_Canvas.\nThe business model canvas has nine basic building blocks. These define the interconnections and relationships within a business model.\nThe example used in this section is Amazon Web Services (AWS), particularly EC2 (virtual machines on demand). This is an Infrastructure as a Service offering. The power of the business model canvas approach becomes clear when we see how it can distinguish between various cloud service offerings. Customer Segments (CS) Customer segments are the groups of customers that the company ultimately serves, i.e., the ones that consume and pay for the services.\nIn the AWS case, although practically anybody with a credit card can spin up a virtual machine, in 2015, Amazon primarily targeted software developers and (startup) SaaS providers as the main customers. Historically, the Amazon development teams were the first customers, and external customers were initially added as an afterthought.\nValue Propositions (VP) Value propositions reflect customer problems and needs. This central element describes why the customer would ultimately pay for the product or service.\nThe value proposition of a cloud computing service is driven by its five essential characteristics. For example, in the AWS EC2 case, the core component of the value proposition is rapid self-service provisioning of virtual machines with pay-per-use billing. For each individual customer, these translate into different business advantages, like fast provisioning, reduced capital expenditure, and minimized risk of over-investing.\nChannels (CH) Value propositions are delivered to customers through communication, distribution, and sales channels.\nIt is often assumed that cloud computing relies solely on self-service direct sales, but the reality is much more diverse. SaaS providers, in particular, are developing extensive partner programs. AWS primarily employed a self-service direct model, where delivery is through APIs. The model is enhanced by premium support.\nCustomer Relationships (CR) Customer relations are established and maintained with each specific customer segment.\nOne way AWS maintains relationships with its customer segments is through conferences. The 2013 re:Invent developer conference attracted 9,000 visitors. In 2024, the conference, no longer solely focused on developers, drew around 60,000 visitors. Additionally, there are vibrant online communities. AWS has shifted its customer relationships significantly since 2013, targeting new customer segments, and consequently, new relationship channels.\nRevenue Streams (RS) Revenue streams result from value propositions that are successfully offered to customers.\nThe structure of revenue streams is where cloud computing differs from earlier IT service models, as they are usage-based rather than asset-based. AWS charges hourly fees per virtual machine; the bigger the virtual machine, the higher the hourly rate.\nKey Resources (KR) Key resources are the assets required to offer and deliver the previously mentioned elements (e.g., value proposition, customer relationships).\nAWS owns massive amounts of hardware, estimated at 1 million servers or more in 2015, housed in dozens of data centers worldwide. But there is more. The service can only be delivered through advanced and unique fulfillment software and processes.\nKey Activities (KA) At AWS the key activity, delivery, is highly automated. But at the AWS scale, oversight and resource planning is still a significant effort. Optimizing assets versus utilization is very essential in the IaaS business model. Through economies of scale, AWS is able to spend a lot of effort on these activities.\nKey Partnerships (KP) Some activities are outsourced, and some resources are acquired outside the enterprise.\nAWS buys immense amounts of hardware, and uses a lot of (open source) software. Building out data centers is also likely to be outsourced.\nCost Structure (CS) All business model elements discussed above impact the cost structure.\nIn more traditional IT service models the revenue streams are tightly coupled to the cost structure. The cloud computing innovation is also about decoupling these. At AWS, the main cost elements are in assets such as servers and data centers, in services such as electrical power and telecommunications, and in people for managing the systems.\nSummary The business model canvas is a useful tool to map out the particulars of cloud provider business models. In this section, we have only looked at the basics of a particular infrastructure provider. It is also useful for software-as-a-service providers as we will see in the next unit. It can also be used to expand on the business model of internal/private cloud providers.\n","permalink":"/book/value/business-model-canvas-iaas/","title":"Business Model Canvas for IaaS Providers"},{"content":"Understanding the technical architecture of digital infrastructures is critically important, in particular for non-technical professionals.\nI have spent more than a decade educating people on cloud security, for example through certifications such as the Certificate of Cloud Security Knowledge (CCSK), organized by the Cloud Security Alliance (CSA), and the Certified Cloud Security Professional (CCSP), as organized by (ISC)2. These bodies of knowledge cover a lot of ground, and most of it is related to digital infrastructures at scale.\nMy students come from many different backgrounds, each bringing with them a unique set of experiences that color their understanding of the way the cloud is managed and controlled. This is the reality in practice, because secure cloud adoption is a team sport where diverse backgrounds count in order to reduce the risk to organizations.\nWhat is technology architecture? Architecture is often used to mean the overall structure of something, and technology architecture then describes how various technology components fit together.\nCloud computing, in my opinion, does not have that much new technology. Most of the technology we have today was already in existence before the advent of cloud computing. Today, a common characteristic of the technologies that are relevant for cloud computing is the fact that they facilitate resource pooling and interconnection of systems. Resource pooling is an essential characteristic of cloud computing, and a technology such as server virtualization helps implement that sharing. But server virtualization should also guarantee proper separation between otherwise independent cloud tenants.\nTechnologies such as APIs and federated identity management allow the cloud to be made up of a lot of collaborating independent companies. This helps create an IT supply chain. Your average company has hundreds of SaaS suppliers who in turn use hundreds of other cloud companies to help them deliver their services. APIs also enable the essential cloud characteristic of automatic self-service provisioning. For example, through APIs we can set up auto-scaling services. Again, this is a tool in building the IT supply chain.\nBeyond the company boundary The new thing that cloud computing brings is sharing between independent companies, interconnecting different, independent providers and automating that. The whole technology architecture now spans the IT supply chain. This has big governance and security implications. For example, when that collaboration or isolation fails, we cannot escalate these problems to our own CTO or CIO to resolve them. These problems are not confined to a single company anymore. They have to be resolved between companies.\nThe technical collaboration between companies will only work with proper contracts and management processes. This has to be set up in advance, instead of figuring out how it works later, as is so common inside an enterprise. And the people whose competence is to review these contracts and set up the service management processes therefore must understand how the technology enables that collaboration. That is why technology architecture is so important for less technical people. And that is also why it can be hard. The CCSK body of knowledge focuses specifically on how cloud technology architecture has an impact on cloud management, in particular on cloud risk management, and that makes it a great tool for building effective cloud adoption teams.\nEven those who are not involved in day to day technology decisions should still have an understanding of it, because in today\u0026rsquo;s world, it does matter to them. This always reminds me of a World War 1 quote from the french Prime Minister Georges Clemenceau.\nWar is too important a matter to be left to the military.\n(La guerre! C’est une chose trop grave pour la confier à des militaires.)\n","permalink":"/book/change/new-skills-needed/","title":"Technology architecture for non-techies"},{"content":"Deployment is everything that happens between writing software and actually using that software by its intended users. And as we get more software and more users, deployment becomes more complex.\nWhy deployment diagrams? Deployment diagrams are a great technique for communicating about important decisions in deploying software. Decisions such as who is going to do what, how are things connected, and so on.\nThere are many ways to draw deployment diagrams and many standards to choose from. UML and Archimate are just a few of them. To me, there is no single right way to create deployment diagrams. In that sense, these diagrams are more like maps. And the usefulness of a map depends on the journey that you are going to make. A map for a mountain walk is pretty useless if you want to make a railroad journey and vice versa.\nIn this section, I’m setting out to define the principles that these maps should adhere to. The reason for that is that there is a lot of intuition on these types of diagram and their visualization.\nIt turns out that the actual symbols to use are not so relevant. It is more important to understand what we mean by those symbols, and how these diagrams are useful.\nWhat do we want to model? Modern IT systems are made up of many components, but all of them handle data in one way or another. Some of the important principles are that we want to understand where data is stored (at rest), where it is being processed, and how it moves from one place to another.\nWhat you want to explore is how data is connected because that tells us something about who can access which data. The converse of that is that we can also then see how things are isolated from one another. And this is a really important thing for security. If we know who is responsible for which component we can also understand who is responsible for capacity, for security, and for making it into production bringing it into production.\nWe used to think that we are connecting computers. But these days we are really connecting execution environments. An execution environment can be a computer, but it could also be a virtual machine or a container. Or it could be a Lambda function. The essence of an execution environment is that it runs code and that it is somewhat isolated from its environment. It also implies that we can then look at how these execution environments are connected.\nTake the following simple example. On the left we have a user working on the web browser, on the right-hand side, we see the web server. They are connected through the Internet. The web server is an execution environment that serves up webpages. The user’s browser is an execution environment that renders these webpages to the user. And we annotate the connection link with the protocol that is being used.\nSo we see two important concepts illustrated in this diagram: execution environments and connectivity.\nNow in a more formal notation such as UML or Archimate, this would look a bit different. Many would be able to argue about the specific symbols to use, but when I am pragmatic I am only concerned with how well the diagram communicates.\nHow detailed should your model be? A diagram is meant to communicate. It should communicate the most essential thing that you want to bring across to the people who are looking at your diagram. In this diagram, we are focusing on how the WebServer and the DNS service are probably different services. As a result, this diagram emphasizes the protocols that are being used, and the separate execution environments that are involved.\nAlternatively, we could introduce the Internet as an actor. In reality, by the way, the Internet is actually a set of actors, but we don’t show that here. What this diagram also shows, in comparison to the previous picture, is that there are multiple levels of detail on which you can draw these diagrams. Again, it all depends on what you want to illustrate.\nArchitectural decisions One of the purposes of deployment diagrams is to document and demonstrate architectural decisions. These decisions could, for example, be on the flow of data, the location of data, and where data is actually being processed. In the next example, we show how this works in a music distribution service, such as Spotify or Apple Music.\nIn your typical setup, there are three major components: the cloud-based music storage, the speaker or sound system to play the music on, and a mobile device to control it all from. This potentially gives us three connections. The first one is from the mobile device to the cloud-based music service to select the music that you want to play.\nBut how does the music get to the speaker?\nThere are two options. The first option is that the music goes from the cloud to the mobile, and then to the speaker. The other option is that the music goes straight from the cloud to the speaker. In fact, both options happen in reality. The first one describes a Bluetooth connection between the mobile and speaker, and the second one can be seen with Spotify connected speakers.\nIt is an interesting exercise to discuss the benefits and disadvantages of both options. You might also want to dive deeper into the actual protocols being used to make this work. Especially the protocols between the speakers and the rest are not so trivial.\nCloud-Native How is deployment different in a cloud-native age? To begin with, there is virtualization, there is containerization, we have functions as a service (such as AWS Lambda), we have DevOps, we have infrastructure as code, we have external services, APIs, and so on.\nAnd then we have also flexible infrastructure that can rapidly scale up and scaled-down. All of this brings complications to drawing deployment diagrams. Let’s see how we can accommodate each of these cloud-native concepts in our diagrams.\nVirtualization A virtual machine is an execution environment that lives within another execution environment, probably a physical host. Remember that an execution environment is isolated from other execution environments. A virtual machine is in complete control of the entire memory address space in the machine that it runs on. It only shares the hypervisor on that machine. That is quite powerful isolation. In fact, it also has network interfaces that are completely indistinguishable in capabilities from the network interfaces on a physical machine.\nSimilarly, a container (such as a Docker container) is an execution environment that lives within another environment. Each container is pretty isolated from the other containers that run on the same host, although not so isolated as a virtual machine is from another virtual machine. For example, containers share network port address space. This means that two containers on the same post cannot use the same IP address port number.\nIn the diagram below we have chosen not to show how the network is organized.\nNote that we have combined containers and VMs in one picture. This architecture actually happens in reality, it has its advantages. We’ve also chosen not to show any details of the underlying operating systems, hypervisors or Docker runtimes in this picture. Again, depending on what you want to communicate with the diagram, you might want to include those networking and other details.\nAutomated deployment Let’s move into slightly more advanced cases of deployment. It is pretty common these days to automate the deployment of software on any given machine. That has many advantages in terms of reproducibility, maintainability, and ease of upgrade. And that also comes with security benefits. However, it does require additional software and deployment components to get this going. That is because there are many more moving parts in this type of IT architecture.\nFor example, you need some kind of machine to deploy from, and a machine or environment to deploy to. You also need some technology to remotely deploy and configure the software. A popular tool for that these days is Ansible. Instead of typing commands on the command line, or clicking in a user interface, the configuration of the target machine is the result of a script that is executed. We say that this script is then ‘manifested’ into the target environment. As a side note, the word manifest originates from shipping, where it describes a document that lists the cargo items that are to be on the ship.\nIn automated deployment, it is very important to understand what type of infrastructure and software is created by whom or what. For that reason, we introduce a special type of relation, the manifestation relation. We signify this relation by a dashed line. Of course, there is still an underlying communication protocol that is necessary for this to work.\nIn the next diagram, the target machine is remotely configured from an Ansible playbook. On the target machine, we indicate the components and software that are to be installed there, and those should be described in the Ansible playbook. To make this a completely reproducible architecture, we also need to describe what the software components are that should be on the deployment machine to begin with. The old-fashioned flowchart symbol with the folded corner resembling a document is used to indicate where data is being stored. In this case, that is the Ansible playbook.\nCloud deployments In the previous diagram, we have simply installed the software onto an existing virtual machine. In a cloud world, however, we can go much beyond that. We can deploy what is called “infrastructure as code”, where complete architectures can be provisioned automatically. In the example below, we are using a deployment machine to run a Terraform script that automatically deploys 2 virtual machines and an internal network on the cloud provider. With the big oval, we indicate that there is some kind of ownership by the cloud provider of that part of the architecture, which also implies some isolation and control separation.\nThis diagram also shows how the Terraform script results in (is manifested to) actual deployment at the club provider. That is done through the cloud API.\nContinuous integration and delivery Next up in our journey towards ever deeper automation of software deployment, we have the continuous integration and delivery pipelines. As you might know, a continuous delivery pipeline takes software and other digital assets from a source code repository and builds it into something that can be deployed in an appropriate environment such as a cloud provider.\nThere are many examples of deployable artifacts. They could be AWS machine images, Docker images, or whatever you can think of. The artifacts are often stored in separate systems, across control boundaries. This is one of the reasons to put them outside of the pipeline.\nThe diagram shows the three major components, each of which could be under the control of a separate department or even organization. Note also how the diagram poses the question of how the build server (tagged ‘CI CD Pipeline’ in the picture) communicates with the software repository. In practice, there is some kind of trust relationship, where the build server is triggered whenever there is a commit to the repository.\nFrom the perspective of control, we see that this diagram identifies two pieces of data. On the right-hand side, we see the deployable artifact, and on the left-hand side, we see the source code repository. Different groups of people may have responsibility for these. We have taken the liberty to draw the deployable artifact as a kind of document, whereas the source code repository is depicted with the old-fashioned flowchart database symbol: the cylinder or disk. (As a completely irrelevant side note, this symbol might actually have been derived from magnetic drum memory, which ceased to be relevant in the 1960s).\nAt this point, we may feel the opportunity to combine these diagrams into one huge big diagram that allows us to see each and every detail of our full-blown architecture. It can be done of course. But often it is better to illustrate the architecture with a sequence of simple diagrams.\n","permalink":"/book/diginfra/deployment-diagrams/","title":"Deployment Diagrams"},{"content":"Here is a high-level overview of the SaaS provider business model and some of the strategic options that are in there.\nBusiness Model Canvas In this unit, we\u0026rsquo;ll explore examples using two hypothetical SaaS providers: one offering bookkeeping software and the other a project collaboration platform.\nCustomer segments (CS) In the Business Model Canvas, “Customer Segments” are the groups of customers that the company ultimately serves, I.e. the ones that consume and pay for the services.\nIt is characteristic of the SaaS model that this could basically be anybody, not just IT people. Let us just remind ourselves that customers here are the ones that use the service to get their business done, or get their personal lives in order. In a business context we often also have to distinguish between the user and the organization that purchases the solution. This is very likely true in the case of our bookkeeping software company.\nValue Propositions (VP) Value propositions reflect the customer problems and needs. This is the central element that describes why the customer would ultimately pay for the product or service.\nThe essential characteristics of cloud computing may or may not relate directly to the core value proposition of the software application. In our first example, the core value proposition —automated bookkeeping— is unrelated to cloud computing. Of course, cloud computing’s characteristics give the SaaS proposition an edge above its direct on-premises alternatives even if the functionality would be the same. Self-service provisioning leads to quicker time to deploy, more scalability in usage (whether accounts or transactions), lower investments or commitments, and potentially lower cost. The value proposition is fundamentally different in the second example, the project collaboration support site. In this example, the cloud\u0026rsquo;s characteristic of broad network accessibility directly enhances the software\u0026rsquo;s usefulness for users spanning company boundaries. Interestingly, the first provider could use this insight to extend its functionality beyond what would be possible in an on-premises solution. Think collaboration with accountants, suppliers and possibly customers, or channel partners.\nChannels (CH) Value propositions are delivered to customers through communications, distribution and sales channels.\nIt is often assumed that cloud computing relies solely on self-service direct sales, but the reality is much more diverse. SaaS providers in particular are developing extensive partner programs. The typical enterprise software solution is not implemented overnight. It takes attention to change management and alignment on master data for example. That is why system integrators often experience the move from on-premises to SaaS as relatively painless. They are doing the same job on a different environment. Less invasive SaaS offerings are frequently aggregated in broker portals, commonly referred to as \u0026rsquo;enterprise app stores.\u0026rsquo; These portals add value through consolidated billing, self-service provisioning, identity management, and potentially some data integration. But that is one to paint on another business model canvas.\nAnother natural extension of the SaaS model is exposing the core functionality through an API. While not often directly accessed by the consumer, this does allow integration with other SaaS providers. Our project collaboration software could integrate with an existing cloud storage provider. The main SaaS channels therefore are direct self-service sales, value added re-sellers, system integrators, and enterprise app-stores. The notion of cloud broker fits in here as well, but dissecting its many shapes and forms is a topic beyond the scope of this section.\nCustomer Relationships (CR) Customer relations are established and maintained with each specific customer segment.\nThe lure of cloud computing is that the provider can have a much more direct relation with the customer than is possible with an on-premises solution. Technically, the provider can potentially see each and every move from the users. Which software builder would not like to be able to see the popularity of every feature in real-time? This allows for much more rapid innovation cycles.\nIt is not impossible for the loop from idea to wide customer feedback to be closed in a couple of hours. However, this power can bring the provider in conflict with the consumer who might object to its data being used. As an example that is close to the limit of what might be considered acceptable consider the following case. An on-line bookkeeping service for individuals allows them to categorize payments to merchants. Once enough individuals categorized Danny’s steakhouse as a restaurant, this can then also be suggested to other clients of Danny’s. Is it legal to use data from one cloud consumer to deliver value to another? Generally speaking, the answer is no, but it may be acceptable if only aggregate data is used. Support is often easier on-line, and on-line communities often add considerable value for the consumer.\nRevenue Streams (RS) Revenue streams are the result of value propositions that are successfully offered to customers.\nThe structure of revenue streams is where cloud computing differs from earlier IT service models. Software firms traditionally relied on licensing arrangements that were somewhat usage based, and could be hard to enforce technically as well as legally.\nCloud computing service models by definition are usage based, and have the potential to be much more closely related to the value that is experienced by the customers. Both our examples enhance the productivity of users, and it is natural to charge per user who has access to the functionality on daily basis. Transactional services such as event management or email delivery are more naturally charged by the transaction, potentially on a bulk basis.\nKey Resources (KR) Key resources are the assets required to offer and deliver the previously mentioned elements (e.g. value proposition, customer relationships).\nThe core asset of a software company is likely to be its code base, its understanding of consumer requirements and processes, and the staff that does this. For a SaaS provider, this is augmented with actual technical service delivery and understanding of consumer behavior.\nIt may seem a small matter to go from knowing your software and the way it runs at your customer’s sites to running the software yourself. Yet, the competencies involved are fairly different. The most obvious differences between cloud providers and software delivery companies are in multi-tenancy and feature velocity. Every SaaS provider has to think about how multi-tenant his software needs to be to realize the right scalability model for its customers. Feature velocity, the time between inception and go-live is a great competitive differentiator. To achieve this, the provider requires an integrated \u0026lsquo;DevOps\u0026rsquo; organization, demanding significant input from people, processes, and technology. Then, on the physical asset side, an important question is how much delivery assets the company decided to have. Does it need to own hardware assets or are they sourced from an upstream cloud provider? On the canvas, this represents a trade-off between resource and partnerships.\nKey Activities (KA) The key resources perform key activities.\nThe obvious key activity at a software company is: develop software. In the long run, these should increase the value of the code base. For a SaaS cloud provider, actually delivering the software as a service is an extension to that. The virtuous circle in a SaaS provider is understanding customer behavior and requirements, translating these into new functionality and delivering this to customers. For this to be successful on the SaaS scale, it has to be executed as an integrated pipeline. The most advanced organizations get the operational activities out of the way. Developers and product managers are empowered to push features to production. Tests are all automated and the focus of operational staff is not so much into bringing features in production, but to maintain the assets and operational fabric that allow the developers to do that themselves.\nKey Partnerships (KP) Some activities are outsourced, and some resources are acquired outside the enterprise.\nA fundamental choice for every software company is ownership of development tools, as the dependence on these is of strategic importance. That is why large software companies used to have their own homegrown development environments. It turns out that the development tools are a source of strategic risk, but not of strategic advantage. As the industry has matured, it turns out that significant portions of these are best moved to an open source model. An additional fundamental choice for a SaaS provider is: who runs and owns the delivery infrastructure? Again, that infrastructure represents a risk more than a source of competitive advantage. As Netflix puts it: “we are not in the business of building data centers”. That is why it makes sense to work with IaaS or PaaS providers rather than owning the infrastructure. This will obviously also impact the cost structure as we will see.\nCost Structure (CS) All business model elements discussed above impact the cost structure.\nIn more traditional IT service models the revenue streams are tightly coupled to the cost structure. The cloud computing innovation is also about decoupling these. In software, revenue streams are pretty disconnected from the cost structure. After all, when the software is written, shipping it to customers has very low incremental cost, even though servicing customers has not. For software as a service this is a little less so, as there is actual infrastructure necessary to support the service. The cost of that infrastructure is related to the usage volume.\nThe most significant cost elements related to software development are in creating and maintaining functionality, and in maintaining the development and delivery infrastructure. For the software delivery side there will be costs related to in company server infrastructure or incurred from key partners such as IaaS providers. Interestingly, for a lot of SaaS companies, most of the development cost is about supporting future customer needs, not current customer needs. An exception could be the bookkeeping firm, which might be tracking tax regulations as they tend to change regularly.\nSummary Again we see the business model canvas as a good tool to map out the particularities of cloud provider business models. It points us to provider particularities and indicates some important strategic choices.\nSee also on YouTube: ","permalink":"/book/value/business-model-canvas-saas/","title":"Business Model Canvas for SaaS Providers"},{"content":"Podcasting has its own digital infrastructures, for example in hosting them. Let\u0026rsquo;s look at how podcasting has grown, and what made it take off anyway? Many actors influence each other here, and the state of the art of the technology also has an impact on growth rates.\nSuppose a hundred people get told by an enthusiastic friend to try podcasting. Of these, ten don’t have any hardware on which they can play the podcasts. So the rest goes online, and tries to find interesting content, but only 50 people can find a directory in which they can even start to look for podcasts that they like. Only 40 people then find content that they sufficiently like. Ten people drop out because they find loading the content too complicated. Of these, another ten find out that the files are too big for the hardware they have (for example in 2005, they just had a simple MP3 player, no iPod or similar). Of the ones left, another five don’t have the patience for the downloads (we are talking dial-up internet access for a lot of people here, still). If you have been keeping tabs: we are down to 25 people who are capable and willing to regularly listen to podcasts. Now suppose each of these tells four friends, on the average. That means we are back to a hundred.\nNow suppose that all those numbers are a little worse than I have guessed. In that case, any enthusiasm will soon sizzle out. Now suppose that the numbers are just a little better, so that at the end of the week we have 110 people that are going to try subscribing to podcasting. The week after, it will be 121 people trying, and so on. This represents a growth rate of 10% per week, which amounts to more than a hundred fold increase in a year (12,913 people to be exact).\nIn fact, all these numbers have been getting better gradually over many several years. Both the technology and the content were existing as early as 1997. Yet, the gradual increase took until about 2005 to reach what Malcolm Gladwell calls: “The tipping point”. This is when a development, epidemic, or trend just seems to explode. Obviously, technology has improved, in particular once the iPod was launched, which could store 1000 songs. But something more was going on.\nI checked these numbers with Adam Curry, who is regarded by many as the father of podcasting, or \u0026lsquo;podfather\u0026rsquo;. I found out that he has made a conscious effort to improve the numbers. For example, he developed \u0026lsquo;ipodder\u0026rsquo;, which started as a piece of software to make the mechanics of subscribing to podcasts and getting them on your player easier. Ipodder was a directory to help people find content that is interesting for them. Curry also ran “The Daily Source Code”, a regular podcast, as a tool for podcast software developers to test their software.\nThere is also a tipping point for creators of podcasts, which works in tandem with the tipping point for listeners. But I will leave you to figure out the details of that yourself.\nWe can\u0026rsquo;t really say that one person had the power to force podcasting upon the world, but there was definitely somebody with the insight and the opportunity.\n","permalink":"/book/power/the-tipping-point-for-podcasting/","title":"Who made podcasting big?"},{"content":"Cloud Computing is an important and big set of digital infrastructures.\nBetween 2000 and 2010, as the internet was growing in reach, it also became a vehicle for the delivery of compute services. Back in the day, Application Services Providers, as they were known, offered software remotely, so it was no longer necessary to install it in a company\u0026rsquo;s datacenter. I could tell horror stories about how early client server application installations went, so not needing that was a key selling point.\nA little later, Amazon was one of the pioneers of offering storage and servers over the internet. In addition, there were a bunch of other providers offering a variety of platforms on which you could develop and deploy software. These offerings were often \u0026lsquo;opinionated\u0026rsquo;, which means they made a lot of technology choices for you.\nThese seemingly disparate developments were brought under a single umbrella term: cloud computing. The history of that term is not easy to trace. It is one of those concepts that seem to have been discovered independently in multiple ways. As early as 2001 we talked about putting servers \u0026lsquo;in the cloud\u0026rsquo;, meaning we did not care much where they actually were.\nNIST, the US National Institute of Standards and Technology, solidified the concept in 2011. They lumped together all kinds of online services and access to resources in a single definition, by identifying five essential characteristics of such services.\nI have spent many hours explaining these, and answering questions about them. Technical people used to be confused about the vagueness of these characteristics, but once we start looking at them as drivers of value and risk, it becomes a bit more applicable.\nWe\u0026rsquo;ll get to those characteristics in a moment, but first I want to point out that there is a more fundamental characteristic than the five of NIST.\nThe service Cloud computing is a service, rather than a product.\nIt is not a unit that you buy, like a laptop, but a service that you rent. The consumer and the provider are in a continuous relationship. If one of them goes away, the relationship ends. This is different from owning something. There are many computers still in operation of which the manufacturers have long gone out of business. The sections on promise theory explain how you can describe and even quantify such services and their quality.\nThe NIST essential characteristics fit into that framework. Let\u0026rsquo;s go over them.\nOn-demand self-service A consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with each service provider.\nThe value that this brings is in the speed at which it can happen. As a general rule, delay brings cost, or at least missed opportunities. Not having a human in the loop at a provider can speed up things. Not having a human in the loop at the consumer can speed up things even more. This is why cloud providers generally offer APIs and web interfaces to provision their services.\nSelf-service also brings risk. In order to reap the benefits, organizations must delegate their control over this provisioning to where it is needed, which is often at a much more operational level. This can lead to uncontrolled consumption, unless technical and governance measures are put in place to mitigate these risks.\nBroad network access Capabilities are available over the network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, tablets, laptops, and workstations).\nThere are a couple of things in this NIST definition that are obvious to some, and confusing to others. It depends on your background, so be aware of that.\nBroad means ubiquitous here, distinct from broadband networks. It assumes the network is available to everybody. Broadband refers to the speed of networks, such as Gigabit fiber and 5G mobile. The network does not come included as a part of the service. Consumers are supposed to already have some network access. That is part of the value: no need to have separate networks for separate services. The network is a shared service between the consumer and the provider. However, that does not mean that the network has a single owner. The NIST definition tries to avoid mentioning the internet, or internet protocols. While the public internet is a major delivery infrastructure for delivering cloud services, major cloud providers also offer dedicated communication services where capacity and isolation can be agreed upon bilaterally. Those services still run internet protocols, typically. The network is viewed here from the perspective of the service: what does it take to get to the users? It includes connectivity but also the user devices. In contrast, a typical network engineer excludes both the clients and the server from their definition of the network, whereas the average user sees all services as part of the network. Confusing, isn\u0026rsquo;t it? In the old days (1960-1990), services such as airline reservations, Compuserve, the French Minitel, and financial market information (Bloomberg terminals) were provisioned as end-to-end services and the fee included data communications as well as the end user device. The risk associated with this characteristic is lack of isolation between clients and between services. When a cloud service is on the internet, your accounts on that service are on the internet too, and therefore potentially accessible by bad actors. This cloud characteristic compares to what economists call \u0026lsquo;unbundling\u0026rsquo; of services.\nResource pooling The provider’s computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to consumer demand. There is a sense of location independence in that the customer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction (e.g., country, state, or datacenter). Examples of resources include storage, processing, memory, and network bandwidth.\nThis one is a mouthful, probably because the concept of resource here is pretty broad. It tries to cover all bases.\nCloud providers are shared services, as I have explained elsewhere. What makes that work economically is a combination of factors. There are economies of scale at work that individual consumers can\u0026rsquo;t reach. But in combination with the characteristic of rapid elasticity, consumers can provision just enough capacity for their needs without paying for excess or unused capacity. The slack is taken up by the provider, who can average out the consumption over multiple consumers, in the same way that the average electricity user is only occasionally using ten times their average consumption.\nThat is a clear business benefit, but the risk of it is that the resources may not be available when the consumer needs them. And of course, the provider bears the risk of unused spare capacity that cost them money and does not bring immediate revenue. As an internal IT department is typically a cost center, accounting rules in an organization won\u0026rsquo;t allow them to take on this risk.\nRapid elasticity Capabilities can be elastically provisioned and released, in some cases automatically, to scale rapidly outward and inward commensurate with demand. To the consumer, the capabilities available for provisioning often appear to be unlimited and can be appropriated in any quantity at any time.\nWe discussed on-demand self service, but that did not state how fast the capabilities were scaled. It also did not discuss de-provisioning. To the consumer, the speed of provisioning matters. And in order to control costs, release must also be fast.\nHow fast? That depends on the business process that it needs to support. An incoming storm of new shoppers should probably be handled in minutes. In contrast, a flood of new employees would still be well served in hours, or even days.\nRapid elasticity also has risks, in particular uncontrolled spending. If spend can grow faster than the review cycles can keep up with, there is a monetary risk.\nThe provider also faces risks. It is hard to predict how much capacity is required to serve the customers. And the demand can change much faster than a provider can build the resources.\nThis is probably one of the reasons that infrastructure providers have reserved instances and spot instances, on top of the regular server instances. The reserved instances do not run the risk of a sudden scale down. The spot instances can typically be pre-empted by the provider, so when they are running low on capacity for better paying consumers, they can just terminate the spot instances, and reallocate the capacity.\nMeasured service Cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported, providing transparency for both the provider and consumer of the utilized service.\nIf nobody pays for what they are using, they will hoard everything they can lay their hands on. Before cloud computing existed, IT resources went to the departments that were most savvy in budget discussions, not necessarily the departments and applications that needed it most or had the best use for it. I discuss these governance issues in more detail elsewhere.\nThe promise of measure service is that you pay for what you use, or more specifically, you pay for what is valuable to you. That is why some services are priced by the account: the more users you have, the more valuable the service becomes. Think of email as an example.\nMore simply, an infrastructure service does not charge you for the storage box, but only for the part that you are using.\nThis is different from the cost structure of the provider. For the provider, the number of email accounts is not a cost driver. Instead the storage of mailboxes is, as well as the number of messages processed. Again, the difference between cost and value is taken up by the provider as profit or loss (as the case may be).\nSetting prices like these can be complicated. One approach that works quite often is to consider pricing and consumption as a game. The moves of the providers are not just setting the prices, they also set the dimensions, e.g. charge per user or charge for consumption. The consumer can primarily accept or reject the pricing, based on the payoffs they are getting. In a business context the payoff is closely tied to the business benefit.\nThe NIST definition tries to not talk about money, but instead talks of control. Money is a form of control, but inside an organization there are other forms of control, such as quota.\nWrap up Cloud computing brings power to at least two types of actors. The consumers get to ship new features, and deploy new software faster. The providers are building a scalable business for themselves.\nSo everybody wins, right? Maybe, maybe not. Maybe there is a party that is not getting benefits. It is up to you to figure that out in your situation, because those are the ones that may sabotage any cloud migration project. For example, if adoption of new technology reduces opportunities for professionals whose careers are based on mastering the old technology, those professionals are likely to strongly oppose the adoption.\nEvery change in technology changes power structures.\n","permalink":"/book/diginfra/cloudcomputing/","title":"Cloud Computing"},{"content":"The AI landscape has many digital infrastructures.\nLet\u0026rsquo;s explain this step by step and focus on which data is stored where and how it is processed.\nA core element of AI systems is a trained model. This is especially true for the dominant form of AI these days: deep learning neural networks.\nA trained model is the result of processing a lot of training data by a specific neural network. These models are fixed in size, but typically very big. The smallest useful models are close to a gigabyte, while recent public chat models run into multiple terabytes. LLM training costs hundreds, thousands, or more hours of compute time on specialized hardware.\nblock-beta space in space llm:2 space out space in[\u0026#34;Lots of\\ntraining\\ndata\u0026#34;] --\u0026gt; llm[\u0026#34;Training\\nEngine\u0026#34;] llm--\u0026gt; out[\u0026#34;Large\\nLanguage\\nModel\u0026#34;] style in fill:#fff,color:#000,line:#000;stroke-width:0px,color:#000,stroke-dasharray: 5 5 style out fill:#fff,color:#000,line:#000;stroke-width:0px,color:#000,stroke-dasharray: 5 5 A trained language model is effectively a piece of software. You feed it text, and text comes out. This is called inferencing, and it requires that the entire model fit into RAM memory. Only for the simplest cases is this possible on a high-end laptop. For more interesting use cases, you\u0026rsquo;ll need a lot more hardware. Therefore there is a good business case for sharing this across many users.\nblock-beta space in space llm:2 space out space in[\u0026#34;Prompt\u0026#34;] --\u0026gt; llm[\u0026#34;Large\\nLanguage\\nModel\u0026#34;] llm--\u0026gt; out[\u0026#34;Completion\u0026#34;] style in fill:#fff,color:#000,line:#000;stroke-width:0px,color:#000,stroke-dasharray: 5 5 style out fill:#fff,color:#000,line:#000;stroke-width:0px,color:#000,stroke-dasharray: 5 5 In cloud computing, we would call this Inference as a Service. In the NIST cloud model, we\u0026rsquo;d call this SaaS or PaaS, depending on whether is it consumed directly or as part of a larger application.\nThis gives us the option to look for this on the market, or create a shared service inside an organization or group of organizations (e.g. private or community cloud). It also implies that we need to have a clear definition of the service and related service level objectives. This includes any allocation of security responsibilities.\nMore at https://www.cloudsecuritynewsletter.com/p/securing-ai-applications-in-cloud-what-are-we-really-securing\n","permalink":"/book/diginfra/digital-inf-ai/","title":"What are AI Digital Infrastructures?"},{"content":"Zero Trust Architecture is an approach to better cybersecurity. To many, it seems daunting to implement. But it does not have to be hard to start.\nConsider this hypothetical situation.\nYou have an application with hundreds of thousands of sensitive records, let’s say client records. We assume that in this example it seems hard to implement MFA (Multi Factor Authentication) on it. What other controls can you implement to reduce the assumed trust? We can use the Kipling method, which is at the core of Zero Trust architectures, to engineer better controls. In short, the Kipling method is about the \u0026lsquo;who\u0026rsquo;, \u0026lsquo;what\u0026rsquo;, \u0026lsquo;when\u0026rsquo;, etcetera of allowed communication.\nflowchart TD subgraph exec[\u0026#34;Execution Environment\u0026#34;] app[(App)] end users[Cloud Users] fw[Firewall] users --\u0026gt; fw fw --\u0026gt; app We want to allow specific access for specific use cases and be explicit about it. However, to focus our efforts, it makes sense to also identify that our biggest risk is the exfiltration of a lot of those sensitive records: a data breach.\nThe allow rules Let’s begin with the ‘who.’ Who is accessing the information? The application in our example probably does authentication and authorization of users. Where do these come from, and how accurate is that information? Ideally, this comes from an up-to-date corporate directory, but even if it’s not, you can, for example, ask how quickly a departing user has their access revoked.\nThen the ‘what’. Which application and resources are we accessing? What are specific users allowed to do? As part of operational risk management, we have probably already identified who, based on their role, can modify records or do other critical actions. But think one step further. As our main fear is exfiltration of large amounts of data, we can look at where we can control that. Maybe we can disallow large downloads, for example, except when a timely ‘four eyes’ approval is in place.\n(By the way, I think it makes sense to look at large downloads as a risk separate from small data leaks. After all, many employees have access to small amounts of information, and that risk is typically already accepted).\nMoving on to the ‘when’. It can reduce risk to limit access to specific times of the day for most users. There is not necessarily a reason to allow more.\nNext is the ‘where’. Where are the users and the application located? Our case description does not give us a lot of information here. The application could be a server, which then has an IP address. And through a firewall combined with a geographical information feed, we may be able to restrict access to users based on their location.\nThe ‘why’ stands for the business reason. In this case, our data is sensitive, and we don’t want it to be exfiltrated. And in our analysis, we have identified several possible controls.\nHow: One layer of enforcement of this would be in the application itself. In the Zero Trust jargon, we are putting a Policy Enforcement Point in the application logic.\nThe mirror allow rule However, there is also another set of ‘allow rules’ that is often overlooked. I am tempted to call these the ‘mirror’ rules, but it is not a standard Zero Trust term.\nThe data and the application reside in a compute environment, for example a server. There may be malware running in that server. After all, one of the tenets of Zero Trust is ‘assume breach’. If the server has permission to access anything on the internet, that malware might easily exfiltrate large amounts of data.\nIn addition to looking at the user accessing the data, we are looking at the place where the data resides and see if its compute environment can access the world, and thus exfiltrate data. This is the mirror image of the first rule: you could say that subject and target are switched around.\nWe can apply the same Kipling method from the perspective of that server (or any compute environment that has the data in it). What is it allowed to do?\nThe ‘who’ then is the server, and there are various ways to identify it, depending on how it is set up and how we want to control what it can do. It can be an IP address or domain name, for example.\nWhat can the server access? The more limited that is, the better. It should probably be capable of logging somewhere, but it needs only limited DNS and internet access. There are likely to be integrations with other systems, but these should be enumerated and controlled.\nWhen can the server initiate contact? This seems less relevant to restrict, because logging and many integrations can be operational at any time.\nWhy is this access needed? As said earlier, any compute environment must be able to connect to certain other services for its functional operation. Yet that does not imply that it needs broad uncontrolled network access. And there are known cases of abusing overly permissive egress.\nHow can this rule be enforced? One way would be at the outer perimeter of the network, although it is also conceivable to do it through a dedicated firewall or a (network) security group in a cloud environment.\nWhat is the benefit here? In this example we have looked at a specific case of data that we want to protect. The Zero Trust approach and the Kipling method led us to various options that we have. These options allow us to hammer out implicit trust in an existing application.\nThe nice thing is that we can rate and rank these options based on their effectiveness, cost, and feasibility, all while focusing on one specific strategic asset that we want to protect. This is in stark contrast to a traditional approach where you start with strengthening the perimeter and just hope that this will have an impact on the one application that you want to protect first.\nAnd we all know: hope is not a strategy.\nImplication for maturity What we can also illustrate with this story is that, even though we can start with an individual application, many of these controls will become better and cheaper if there is some maturity and shared services in the organization. Reliable user identities are helped by proper federated identity management. Fine grained network access rules are easier to do if there is more software defined networking.\nMaturity is an investment, and it pays off in cheaper, faster and better security. That is another tradeoff that this example illustrates.\nFor more information on Zero Trust, visit https://cczt.clubcloudcomputing.com\nAlso published at https://www.linkedin.com/pulse/retrofitting-zero-trust-existing-application-peter-hj-van-eijk-zjpte\n","permalink":"/book/risk/retrofitting-zero-trust-existing-application/","title":"Retrofitting Zero Trust on an existing application: an illustration"},{"content":"Public cloud migrations come in different shapes and sizes, but I see three major approaches. Each of these brings value in its own way, and they all have very different technical and governance implications.\nThree approaches Companies dying to get rid of their data centers often get started on a ‘lift and shift’ approach, where applications are moved from existing servers to equivalent servers in the cloud. The cloud service model consumed here is mainly IaaS (infrastructure as a service). Not much is outsourced to cloud providers here. Contrast that with SaaS.\nThe other side of the spectrum is adopting SaaS solutions. More often than not, these trickle in from the business side, not from IT. These could range from small meeting planners to full blown sales support systems.\nMore recently, developers have started to embrace cloud native architectures. Ultimately, both the target environment as well as the development environment can be cloud based. The cloud service model consumed here is typically PaaS.\nI am not here to advocate the benefits of one over the other, I think there can be business case for each of these.\nThe categories also have some overlap. Lift and shift can require some refactoring of code, to have it better fit cloud native deployments. And hardly any SaaS application is stand alone, so some (cloud native) integration with other software is often required.\nProfound differences The big point I want to make here is that there are profound differences in the issues that each of these categories faces, and the hard decisions that have to be made. Most of these decisions are about governance and risk management.\nWith lift and shift, the application functionality is pretty clear, but bringing that out to the cloud introduces data risks and technical risks. Data controls may be insufficient, and the application’s architecture may not be a good match for cloud, leading to poor performance and high cost.\nOne group of SaaS applications stems from ‘shadow IT’. The people that adopt them typically pay little attention to existing risk management policies. These can also add useless complexity to the application landscape. The governance challenges for these are obvious: consolidate and make them more compliant with company policies.\nAnother group of SaaS applications is the reincarnation of the ‘enterprise software package’. Think ERP, CRM or HR applications. These are typically run as a corporate project, with all its change management issues, except that you don’t have to run it yourself.\nThe positive side of SaaS solutions, in general, is that they are likely to be cloud native, which could greatly reduce their risk profile. Of course, this has to be validated, and a minimum risk control is to have a good exit strategy.\nFinally, cloud native development is the most exciting, rewarding and risky approach. This is because it explores and creates new possibilities that can truly transform an organization.\nOne of the most obvious balances to strike here is between speed of innovation and independence of platform providers. The more you are willing to commit yourself to an innovative platform, the faster you may be able to move. The two big examples I see of that are big data and internet of things. The major cloud providers have very interesting offerings there, but moving a fully developed application from one provider to another is going to be a really painful proposition. And of course, the next important thing is for developers to truly understand the risks and benefits of cloud native development.\nAgain, big governance and risk management issues to address.\n","permalink":"/book/value/three-ways-to-go-cloud/","title":"Multiple Ways to Go Cloud"},{"content":"Cloud is too important to leave to technical people.\nCloud distributes responsibility for IT services across an IT supply chain. This supply chain is composed of independent providers. This implies that there are these companies have technical boundaries that are matched by organizational and contractual boundaries. This is new, we did not have that before the digital revolution. Amazon calls this the shared responsibility model for cloud security. I would simplify that as: what do I do, and what do you do? For example, who is responsible for patching the Operating System in an IaaS service model?\nContracts need to fix this allocation of responsibilities, otherwise it is not enforceable. But, who is going to check those contracts? Who needs to make sure that the contracts actually specify those tasks, specify who needs to do them, and specifies how to monitor and enforce that. That is a job for procurement and legal, typically. Because of that, these people (in this case: procurement and legal) need to understand what the service is. And they need to understand which (technical) tasks are not part of that service.\nThis is important. Insufficient understanding delays the whole assessment process, and reduces its quality. As one of my course participants, a legal person, once said:\n“When I go into a conversation with a cloud provider I have time for let’s say 10 questions. If all these questions go to understanding basic cloud terminology and technology, I have missed the opportunity to talk about the real risk and opportunity for our company”.\nThe conclusion must be obvious. Educate your lawyers, procurement and so on. Help them understand the cloud well enough. Help them know where technical boundaries need to be translated into legal controls.\n","permalink":"/book/change/lawyers-need-understand-tech/","title":"Why lawyers need to understand cloud"},{"content":"(First public draft)\nImagine that you are part of the government of an average nation, and you have just realized that IT has become a substantial factor in your operation. Or you have a similar position in a manufacturing industry, or in the financial sector. As IT increased in volume, you have tried to keep its costs down, it was just a facility. Outsourcing to more experienced partners was an option, and so was the use of cloud computing, for example for your Office applications.\nNow you realize that IT is not just a cost, but that it is also existentially important to your business.\nNo IT means no business.\nThis is no longer about cost. It is about survival.\nThe geopolitical situation and the oligopolistic dominance of big tech are creating a massive challenge. In the west, we are talking about the US government and the three big hyperscalers. In the east, it is China and their big companies. All these actors have demonstrated that they can and will exert their influence in a way that can be counter to the interest of IT consumers.\nCloud computing has aggravated the situation. Where vendor lock-in was already an issue in the early days of computing, most companies could operate independently from their vendors for a while. In a cloud world, service can stop from one minute to another.\nHence the call for more sovereignty and autonomy.\nSovereignty and autonomy sound nice, and appeal to core human values. But they are problematic: they are ill-defined, and unattainable in the absolute sense. On a global level, there are very few countries, if any, that have no dependence on any other country. So no country is fully sovereign and autonomous. In my opinion, the most important objective is to reduce the negative effects of that dependence.\nIn this unit I want to develop a framework for structuring the conversation around business resilience, which I think is the umbrella concept here.\nI propose to start with a risk based approach, focussing on the supply chain. We start by identifying the threats that the call for sovereignty and autonomy is supposed to address.\nFor example, a nation state order might force a cloud provider to cease operations for a specific customer in a different country. This leads to an availability risk for that customer. In this case, they cannot access their email anymore.\nThe next questions are: what is the bad consequence of that, what are the chances that it happens, and how quick can we reduce the impact of that?\nAll this is fairly standard risk management procedure. But for this conversation I suggest to specifically look at the following.\nWhat do people mean when they talk about the need for more sovereignty and autonomy? What are the risks that derive from having a geographically distributed IT supply chain? What are, in detail, the components of that supply chain? For example, there is a difference between the location of a datacenter, the software that runs in it, and control over the operations of that hardware and software. How can nation state actors and corporations exert power that is counter to sovereignty and autonomy? What are the mitigations that cloud providers propose? How tenable are they? What are mitigations, technical and political, that are applicable for cloud consumers and regulators? In particular, what alternative sources for IT assets and services exist? What residual risks do these have? For example, building a large single service provider company has the risk that it will be acquired by a multinational under foreign control. This has happened. I suspect we will also find out that many of the risks and mitigations are not technical, not even legal, but (geo)political. To fully analyze those, we will need people with these skills. Understanding the essentials of this technology can be challenging for experts in politics or law. And, by the way, that is one of the reasons why I have taken up writing Digital Infrastructures at Scale.\n","permalink":"/book/risk/guide-autonomy-resilience/","title":"A guide to digital sovereignty, autonomy, and business resilience"},{"content":"Where do you start your IT security journey? It is important, but it can be confusing.\nFor many organizations, the trigger is a compliance obligation to show that confidential information remains confidential. Maybe their customers are asking for an ISO/IEC 27001 certification, demonstrating that an IT risk management system is in place. Maybe they are handling credit cards and therefore need to worry about compliance to PCI DSS.\nControls The common theme in these is that they are control based. The process is that you realize compliance by implementing a set of controls, such as defining a password policy, or implementing a type of firewall.\nThere are many positive elements to this approach, especially if it promotes a structured management approach.\nThe downside of this approach is that not all controls are equally relevant in a given situation. It also lends itself to a \u0026lsquo;box-ticking\u0026rsquo; approach, where controls are implemented only in a superficial way, and their actual effectiveness remains unclear.\nThreats In the security community, the topic of the day is what the most current threat is. Money and effort are spent on investigating the latest threats, and discussing how they can be averted. Every day a seemingly endless stream of new vulnerabilities is discovered, each and every one having the potential to endanger all sensitive data that an organization has.\nThis can be a relevant approach. After all, many vulnerabilities have actual exploits associated with them. Yet, exploitable does not imply that actual damage is imminent. A server that is hacked but has no valuable data or relevant connectivity does not result in any significant actual damage to the organization.\nData A third approach is more strategic, and focuses on the value at risk: the data. This is the core of the Zero Trust approach: start with one important data set at a time. That set is isolated, and by tracing where that data is allowed to flow, access to that data can be controlled by a variety of techniques. While there are a number of described approaches to Zero Trust, including the CCZT (Certificate of Competence in Zero Trust) by the Cloud Security Alliance, there is little guidance on how to implement it within specific technologies.\nHow good are these? The control based approach is top-down, starting with policies, working your way down. From a management perspective, setting up a system for overseeing IT risk management promises that eventually all risks will be treated.\nHowever, control frameworks can be big. The CSA Cloud Controls Matrix contains more than 100 controls. These controls are also quite high-level, and translating them into more system and technology specific language is hard. The result is risk management progress that is forever \u0026lsquo;half\u0026rsquo; finished, with unknown gaps. Or worse, continued effort is spent on rewording the policies to make them more detailed, but never getting specific. Nevertheless, regulators love this approach, because it speaks to the senior management and board members who need to take responsibility.\nThe threat based approach is more bottom-up. Starting with the technologies in place, relevant threats are identified and prioritized. Often, these are very technical, and need technology specific expertise to be evaluated. Overlooking just one threat can be disastrous. As is often said: defenders have to defend everything, attackers need only one path in.\nThis approach is the one practitioners take, if they have no other way to prioritize their efforts. Though it sounds cynical, security vendors love this approach because it is an easier sell: the dangers are clear to explain.\nThe data based approach is inside-out, so to say. Identifying the most important data deep inside allows to build out layered defenses. Zero Trust calls this the \u0026lsquo;protect surface\u0026rsquo; as opposed to the \u0026lsquo;attack surface\u0026rsquo;. As said, the problem with this approach is not knowing where to start, and not understanding how to scale up.\nI have seen a few maturity assessments, and while the capabilities differ across organizations, a common theme is insufficient data governance. And that makes it hard to guide the efforts on the technology side.\nAnother pitfall of Zero Trust is to get stuck in not trusting anything, so where do you start with trust? Or, in scaling up, get twisted into \u0026lsquo;implement two factor authentication everywhere\u0026rsquo;, which is neither necessary nor sufficient.\nSynthesis In the end, these three approaches need to be merged, as they all bring relevant perspectives.\nStart with a top down inventory of the most strategic data. That allows to focus the other approaches and maximizes the risk reduced per invested effort. Zooming in on the most important data, relevant controls can then be applied there, while identifying the technology that is used. This helps to more selectively filter the vulnerabilities that have to be taken seriously.\nFor example, if the most important data is stored in a MySQL database on a Linux system with a single sign on system, only vulnerabilities in those technologies need to be taken into account.\nIt requires a common perspective on the value of data, that is a bit more nuanced than \u0026rsquo;everything is important\u0026rsquo;.\nIt also requires a nuanced perspective on risk tolerance in IT. For example, to an IT security professional leaking an individual record is as bad as leaking the entire database. After all, if an attacker can access one record, they can access them all, is the thinking. But from a company risk perspective they are not the same. Individual record leakage is already an accepted risk, just think of insider threats. The loss of an entire database is a compliance event, with completely different consequences. With that background, rate limiting of data exports now becomes one of the relevant controls.\nThis is the type of common ground that is required for truly effective and efficient IT risk management.\nBut this requires a fundamentally different dialogue between the business process owners, risk assessors, and technical practitioners.\nFor starters, it requires that conversations are driven, not by a fear of doing the wrong thing, but by a desire to do the right thing.\n","permalink":"/book/risk/darico/","title":"Data, Risk, or Controls: where to start?"},{"content":"AI systems, like most cloud systems, are composed of models, servers, software, and more, each of which can be provided by a different role.\nWe follow the roles outlined in the CSA AI Controls Matrix (AICM).\nEach role also has promises associated with them (read more on promise theory here).\nTogether these run AI systems, from image recognition systems to Large Language Model based customer support systems.\nAI Customer (AIC) End users of AI applications. This includes the actual users as well as their organizational units. Even though they are only providing a service to themselves, they are still responsible for certain security and control functions. Some of these responsibilities are in the interest of their providers, and those are typically included in an AUP (Acceptable Usage Policy). For example, customers should maintain appropriate authorizations of users, and refrain from overloading their providers. Customers are also responsible for the business use of the data that is returned by the AI application.\nThe customer promises:\n\u0026ldquo;I promise to use AI services responsibly and maintain appropriate authorizations for my users.\u0026rdquo;\nSecondary promise: \u0026ldquo;I promise to verify AI outputs before using them for critical business decisions.\u0026rdquo;\nApplication Provider (AP) These providers build and offer end-user applications that leverage generative AI models for specific tasks such as content creation, chatbots, code generation, and enterprise automation.\nThese applications are often delivered as software-as-a-service (SaaS) solutions.\nApplication providers focus on user interfaces, application logic, domain-specific functionality, including retrieval augmented generation (RAG), and overall user experience rather than underlying model development.\nThe application provider promises:\n\u0026ldquo;I promise to deliver secure, functional AI applications that protect user data and provide reliable service.\u0026rdquo;\nOrchestrated Services Provider (OSP) This refers to entities that create the technical building blocks and management tools that enable AI implementation.\nThis includes platforms, frameworks, and tools that facilitate the integration, deployment, and management of AI models within enterprise workflows.\nThese providers focus on model orchestration and offer services like API access, automated scaling, prompt management, workflow automation, monitoring, and governance rather than end-user functionality or raw infrastructure.\nThey help businesses implement AI in a structured and efficient manner.\nWhile the lines can be a bit blurry, you can think of OSPs as being independent of specific applications and models.\nThe OSP promises:\n\u0026ldquo;I promise to provide reliable AI model orchestration, API access, and workflow management independent of specific applications or models.\u0026rdquo;\nModel Provider (MP) Model Providers are entities that develop, train, and distribute foundational and fine-tuned AI models for various applications.\nThey create the underlying AI capabilities that other actors build upon. Model Providers are responsible for model architecture, training methodologies, performance characteristics, maintenance, and documentation of capabilities and limitations.\nThis is fundamentally about model quality, safety evaluations, and transparent documentation of what the model can and cannot do, and the training data that it is based on. Model providers are responsible for collecting and curating the data on which the model is trained.\nThey operate at the foundation layer of the AI stack and may provide direct API access to their models, at least according to the AICM.\nIn the case of so-called open models, there is a clear case for distinguishing between the responsibilities of the model provider, who effectively just hands over a large file with the trained model, and the \u0026lsquo;inferencing provider\u0026rsquo;, who completes prompts, as described earlier.\nThe Model Provider promises:\n\u0026ldquo;I promise to deliver AI models with documented capabilities, limitations, and performance characteristics.\u0026rdquo;\nCloud Service Provider (CSP) Non-AI specific cloud services for servers, storage, messaging, and more. If you can run a non-AI workload on it, it is probably a cloud service in this definition. An example would be a Kubernetes cluster, or other container orchestration platform.\nBeyond these AI specific roles, we can dig a bit deeper. For example, the AP and OSP may be linking to distinct other services that are outside their direct control, such as document management systems.\nThe Cloud Service Provider promises:\n\u0026ldquo;I promise to provide compute, storage, and infrastructure capacity as requested.\u0026rdquo;\nData providers (DP) AI runs on data, and the more specific the data is, the greater its potential in enhancing AI capabilities. A typical use case is to provide access to large collections of company-internal text and images, some of which may be classified and, therefore, should only be accessible to authorized users.\nThese systems are known under that names of DMS (Document Management System), CMS (Content Management System), or intranets.\nA popular approach for integrating text in an AI system is RAG (Retrieval Augmented Generation). Based on a user query, a selection of documents is retrieved from a data provider and then used in the context window of the large language model model to formulate a targeted response.\nFrom a security perspective, it gets more interesting if not all data should be accessible to everybody. That is why the service of a data provider includes promises such as:\nWhen asked for a document by an authenticated user, I promise to return the best matching answers. I promise to only return answers to which the user is authorized I promise to reveal the document classification to authorized users, but not to others. This makes these data providers enforcers of policy (or PEP in the Zero Trust jargon).\n","permalink":"/book/diginfra/ai-roles/","title":"AI Roles and Responsibilities"},{"content":"For people who care about risk in IT, compliance is a mixed blessing. Compliance regulations can lead to better risk management, but sometimes it is more of a hindrance than a help.\nCompliance in IT generally means compliance with regulations that are set up to reduce risk, for example, across a chain of actors. A great example is the PCI/DSS regulation, which governs everybody who touches a credit card transaction. The objective of this regulation is to protect card holders and card issuers from credit card fraud. The reason why the regulation exists in the first place is because negligence at one actor can lead to damages at another actor.\nFor example, it is not in the merchant\u0026rsquo;s primary interest to keep customer credit card numbers secure. Keeping that data secure involves work. The merchant\u0026rsquo;s prime interest is in getting paid, not in spending more money on security than absolutely necessary.\nThe customers, however, really would like their credit card to be safe, because it is them who bear the fraud risk. Actions by the merchant, or lack thereof, are an \u0026rsquo;externality\u0026rsquo;, as economists say.\nCompliance regulations are a way to force risk management on, in this case, the merchant.\nA similar pattern can be seen in privacy regulations. Personal data disclosure is primarily a risk to the individual involved, not to the organization that holds that data. Regulations on data privacy, such as the EU GDPR (General Data Protection Regulation), force risk management on the storing of personal data upon a lot of organizations.\nCompliance on IT risk management is also becoming a national security issue. The EU NIS2 (Network and Information Systems) Directive forces critical infrastructure providers, such as telecom and electricity companies to be resilient. This is because our society is more and more dependent on these infrastructure providers. Even if these infrastructure providers are not digital infrastructure providers, they need IT to operate. The threat landscape is also changing, with nation-state actors actively targeting these critical infrastructures.\nAs a side note, in the early 2000s I was part of a governmental working group investigating these critical infrastructure risks (or vital infrastructures, as we called them). Our research showed that there were many dependencies between them, but that they all depended on electricity. This highlights the need for critical infrastructure protection.\nWhile all these initiatives help, compliance does not imply security. Even if compliance is treated as more than a \u0026lsquo;box-ticking\u0026rsquo; exercise, there are many documented cases of compliant organizations being breached.\nTarget was PCI DSS compliant in 2013, yet more than 40 million card numbers were stolen.\nEquifax was ISO27001 certified in 2017, yet more than 140 million people\u0026rsquo;s personal data were exposed.\nBeing secure does not automatically mean that you are compliant.\nBut being compliant can be hard, especially with conflicting or ambiguous government regulations. For example, GDPR requires adequate protection of personal data. It requires that protection explicitly when that data is processed outside the EU. Legally, there have been a number of instruments for this protection deemed to be adequate when personal data is processed at e.g. a US cloud provider (though the situation is by no means US-EU specific). There have equally been many arguments that the US government still has control over such data, which would make it illegal to process personal data at a US provider. As an example consider the EU–US Privacy Shield (2016–2020), which was struck down in the Schrems II (CJEU 2020) ruling.\nEvery control, be it technical, managerial, or legal, involves interpretation, trade-offs, and residual uncertainty. Regulators, auditors, or courts may later disagree with your choices.\nIn the end this means that being compliant also involves a risk decision: you accept the risk that you are not fully compliant, in the same way that you accept the risk that you are not fully secure.\n","permalink":"/book/risk/uneasy-compliance-risk/","title":"Compliance is a Risk"},{"content":"Over the years, I have worked with many organizations, large and small. In one case, I implemented the exact same change in more than 15 organizations, whose size ranged from 35 to 35 thousand employees. You can imagine that this plays out differently across these organizations. But that is a story for another unit.\nIt led me to see patterns in decision making and trust. Who takes decisions in an organization? How do people even talk about decisions, especially when they concern digital technology? Who do you trust?\nI have come to identify four major categories.\nIndividuals First is the individual, who decides for themselves. They do not need to consult anybody, though they will be informed by friends and media. If they want a new app on their phone or laptop, they\u0026rsquo;ll just get it. And if it breaks, they will fix it themselves. Or a friend will. Or maybe not.\nSmall Companies Second is the small company, with 10-100 persons. They agree on IT decisions around the lunch table. And if anything goes wrong, we know who the go to guy is to fix it. He/she has lunch too, after all.\nLarge Companies Then we have the large company, more than about 150 people. Now 150 sounds like a random and weird number, but it is actually based on a scientific result by Robin Dunbar. It is called Dunbar\u0026rsquo;s number.\nIn groups with less than 150 people, you can know who you can trust, and who you can\u0026rsquo;t. When decisions are made, around the lunch table, for example, you can easily know who made the decision, how they made the decision, and why. And if it does not work out well, you know where your complaints go, who can fix your computer, or help you with that application.\nYou may not call a company of 150 large, but when groups are larger than that, you can\u0026rsquo;t keep track anymore of who you can trust or not. That really changes the social and power dynamics. Instead of knowing people by name, you know them by role. And the interactions between people are less governed by personal shared histories, but by company shared histories. These company histories can take the shape of myths, not to be challenged. In contrast, you can always try to dig deeper in a personal history. Processes are established, which have to be followed, reviewed, and controlled. Bureaucracy sets in, and every request has to go through a lot of standardized paperwork. And it does not matter if this is a government organization, or a large business. Above a certain size, they all work the same.\nSmall companies run on trust, large companies run on control.\nSociety at Large The fourth group is a bit different. This is society at large, or your social circles that are a part of it. They too make decisions on the technologies that will be adopted.\nThe technology and platform decisions of this category can be as fundamental as that of any of the other categories, but the forces driving them are a little harder to predict. For example, what is the social media platform that everybody uses? If all your friends are on a specific social media platform, sharing the fun they have and where the parties are, you are strongly encouraged to go there as well. And for reasons that we discuss elsewhere, these tend to be \u0026ldquo;winner takes all\u0026rdquo; situations, where one single choice dominates. Market forces are important here, but also regulatory pressures. Not to mention other circumstantial influences.\nIf you want to understand the differences and their impacts, start by looking out for the ways in which digital identities are managed. This differs widely between small and large organizations, as I have shown here.\nIn Real Life In real life, these categories overlap and influence one another. Often, technology decisions begin as individual choices, which then moves to be adopted by a small group, and then the whole organization. Large organizations typically consist of a lot of small groups, within which there are different decision cultures. And small companies often try to sell to large organizations, while misunderstanding the cultural differences between themselves and their prospective customers.\n","permalink":"/book/change/org-size-matters/","title":"Organization Size Matters - Dunbar's number"},{"content":"origin story promise theory\n\u0026lt;aangestipt in promise theory, maar niet uitgewerkt\u0026gt; suwinet reisplanner\ndesign patterns\nService quality e.g. response time. fulfillment time. Fulfillment time: months, weeks, days, minutes, seconds, …\nThese quantitative measures can be used as Key Performance Indicator (KPI) metrics in a Service Level Agreement (SLA)\nAverage response time for primary service Provisioning latencies of users, instances, network, disks Minimum/maximum volumes Cost per user; typically registered user, not per concurrent user Latency and volumes of calls. Network latency by location Software resources (e.g. # connections) Incident response times (and so on) (kan wellicht met mermaid annotations)\nDefines the qualitative and quantitative parameters of the service Contains promises Translate to assurance obligations Translate to penalties\nWithin larger corporations internal consumer/providers relations exist, which also require internal SLA’s\nexercise: Match the service element to the service model (SaaS, PaaS, IaaS), if any\nGet webpage from Intranet Create email Create mailbox Add virtual disk Ask external service to process a payment (in webshop) Request rack in data center\nManage the CMS content Configure the CMS Manage and maintain CMS code base Manage webserver and application platform Manage database Manage operating system Manage hypervisor Host hardware\nHistory and books. Cfengine 21 \u0026ldquo;/var/cfengine/bin/.\u0026rdquo; 22 create =\u0026gt; \u0026ldquo;true\u0026rdquo;, 23 perms =\u0026gt; usystem(\u0026ldquo;0700\u0026rdquo;); (idempotent operations\u0026hellip; of is dat iets anders?) “I promise that the directory will have permissions 0700 or report my failure\u0026quot;\n=- service agreements A lot of service management is about organizing promises, evolving them, and managing the risks of not keeping them.\nYou not keeping them Your providers not keeping them\nWe promise to prevent unauthorized access We promise to keep your information safe We promise to maintain according to vendor best practices We promise to make sure that there is a spare copy of your data off site We promise to add resources as needed We promise to apply updates and improvements We promise to have trained staff that reacts timely and professionally\n= risk and security Every promise is a risk: failure deception\nSecurity can also be about information leakage: I promise to not tell\nDDOS: denial of service Resource exhaustion\nIf a promise implies a resource reservation (commitment), and the amount of resources is finite, denial of service is a realistic risk Examples: TCP connections Processing capacity\nNog meer leftovers:\nend to end applicatie performance meten. Hoe. Link met SRE\nService example Type of organization: Public Government Challenge: procurement process spread over 171 agencies, most having their own IT systems, controlling $3B procurement Approach: Community SaaS procurement system (Ariba)\nProcurement by hundreds of government agencies, served by thousands of suppliers\nWhat is the data, what are the service elements?\nContractual framework in promises General terms and conditions Service Agreements Service Level Agreements (SLA) Acceptable Use Policy (like a reverse SLA)\n=\u0026gt; Contracts are the interfaces in the supply chain and should be matched to GRC requirements\n=-\nPromise Theory and Services: Peter explains that a service is actually a set of promises. He discusses how this framework applies to daily work, particularly with customers using services. He contrasts thinking in terms of buying products versus services. He also mentions a book by Jeff Sesna that dives deeper into this. • Contracts and Service Level Agreements (SLAs): Peter connects the idea of a contract to a set of complimentary promises, where if one party does something, the other will do something else. He clarifies that an SLA is a type of contract. He also notes that an SLA might be an \u0026ldquo;upstream SLA\u0026rdquo;. • Handling Broken Promises: Peter elaborates on what happens if a provider doesn\u0026rsquo;t keep their promise. He discusses standard contractual elements like guarantees or penalties. He also introduces two ways of handling broken promises: ◦ A hierarchy of contracts/promises, using the example of a restaurant transaction nested within higher-level promises like menu availability and societal promises about restaurant licensing and quality. This hierarchy can extend to international legal levels. ◦ A game theoretical approach where repeated interactions allow parties to punish each other for broken promises, fostering trust. He mentions the prisoner\u0026rsquo;s dilemma and the concept of credible retaliation as part of this. • Risk Management: Peter introduces the concept that every promise is a risk and that one significant risk is assuming a promise that is not actually there from a provider. He emphasizes that risk management involves finding somebody who suffers a bad consequence when a service isn\u0026rsquo;t working. He also contrasts the compliance perspective on risk (assuming internal is better than external) with potentially different \u0026ldquo;real\u0026rdquo; risks. • Diagram Analysis and Application of Frameworks: Regarding the project diagram Maria shared, Peter explains it as a deployment diagram showing data, processing, control boundaries (the boxes), and communication/messages (the lines crossing boundaries). He then explains how to apply the concept of service agreement items and promises to each boundary crossing in the diagram. • Zero Trust Principles: In the context of the diagram and sensitive data flow, Peter introduces Zero Trust principles. He explains thinking in terms of \u0026ldquo;allow rules\u0026rdquo; for specific transaction flows (e.g., allowing sensitive data to the local LLM but not outside) and showing where there is no \u0026ldquo;allow rule\u0026rdquo; to prevent unwanted flow. He mentions that a policy enforcement point would be where this control is implemented. • Intervention Layers for Governance/Controls: When discussing the complexity of risk, architecture, and zero trust, Peter suggests thinking in terms of intervention layers. These layers range from stopping specific data flow, to watching the controls, to ensuring people understand policies, up to the policy-setting level itself. He notes that if a higher-level control isn\u0026rsquo;t there, \u0026ldquo;you are the higher level control\u0026rdquo;, though acknowledging enforcement challenges. He suggests starting at a lower level and scaling up.\n","permalink":"/book/value/promise-theory-services/","title":"Promise Theory and service hierarchies"},{"content":"A great way to look at how value is created in interactions between autonomous actors is game theory. How do autonomous actors respond to other actors? This is the core question here. How do you respond to an offer from a service provider? But also, how do they respond to you?\nI have found game theory to be an effective model to think about the outcomes of sequences of interactions. This is because it clearly identifies the actors (or players) and their interests.\nI use this all the time to think about how I relate to other parties that I choose to work with, or just have to work with. It also helps me to understand how parties and stakeholders act upon one another.\nA game, in this view, has a number of players, who make moves that result in payoffs. The payoffs are defined by the rules of the game.\nA simple example is tic-tac-toe, where players take turns (make moves) in marking an X or O on a 3x3 board. Whichever player first aligns three in a row wins. The win is called the payoff.\nA strategy is a plan for the moves that you are going to make. A winning strategy is one that always wins, despite the moves of opponents. By the way, there is no winning strategy for tic-tac-toe. The best you can hope for is an opponent\u0026rsquo;s mistake.\nThe digital infrastructures world has many examples and applications of this. One example can be found by looking at a simple provider-consumer relationship.\nIn this relationship, the provider pools resources such as bandwidth and servers for multiple consumers, and charges a certain price to them. The moves they make are setting a price and setting the size of the pool of resources.\nThe consumers\u0026rsquo; moves, simply stated, are to buy the service from this provider, or not, and to consume the service, or not.\nThe rules of the game are that the more consumers use the same pool, the less performance they get, which reduces their payoff. Think of the cake at a birthday party: the more guests there are, the smaller the slice each gets. Note: for the consumer this is an example of an externality (an outside factor that influences the value), which we discuss elsewhere.\nThe payoff for the provider is the amount of revenue they get. Having more users results in more revenue. The payoff for the consumers is the performance they get.\nAs a provider, you are probably looking for a strategy that maximizes your payoff, by balancing between having too much expensive capacity, or by alienating consumers by not having enough capacity. I once consulted an Internet Services Provider on how to play that game.\nContracts are games Whenever you enter into a contract, you are also entering a game. The contract specifies the rules of the game, the allowable moves, and their payoffs.\nWhen you sign up for a mobile phone subscription, your allowable moves include making calls and sending text messages. Each of these moves has a payoff. Part of the payoff is the charge from the mobile operator, and that is part of the contract. Terminating your contract is also a move, and the contract specifies your notice period.\nContracts between business entities often get a lot of scrutiny from lawyers. An important part of the work of those lawyers is figuring out what the game is.\nWhat are the moves? What are the payoffs? Do other parties have a strategy that gives us negative payoffs? Negotiating a contract means trying to establish the rules of the game. These rules will apply when the contract goes into operation.\nInterestingly, and confusing to some, is that negotiating a contract is a game in itself. The moves are the various proposals, clauses, and amendments that are made. The payoff is a contract, which hopefully has value. But abandoning the negotiations is also a move. Negotiation experts therefore urge you to consider the payoff beforehand. BATNA, or Best Alternative To Negotiated Agreement, represents your moves if a negotiated agreement fails. Understanding it gives you power in a negotiation.\nTaking a risk is a game Whenever you make a bet, or take a chance, you are playing a game. In roulette for example, you are playing against chance.\nYou make a move, put your money on a color or a number, the table turns, and your payoff is either negative, you lose your money (likely), or you win and you get X times your bet (less likely).\nStatistics helps you figure out what you can expect to win (or lose, as the case may be) based on your strategy. If you play in a casino, you can assume that the casino has a winning strategy, and you don\u0026rsquo;t.\nIn cybersecurity we are playing games all the time. For example: your software has a vulnerability. Vulnerabilities may lead to hacks, where your data gets stolen, or other bad things happen. Your move is to either fix it (negative payoff, as it is an effort) or not (zero payoff). Then you either don\u0026rsquo;t get hacked (zero payoff) or you are (big negative payoff). Statistics won\u0026rsquo;t help you much here. If a vulnerability is easy to exploit, it will be exploited eventually.\nCheating is a game Cheating is a game too.\nThe cheater is taking a risk. If they are not found out, they win. If they get caught, they lose.\nThe move is clear, as is the payoff.\nBut it gets more interesting when two cheaters play together. One example of that is the game called the \u0026ldquo;prisoner\u0026rsquo;s dilemma\u0026rdquo;, which we will discuss in another unit.\nChange the game Automation often allows us to change the game, or at least change its rules and payoffs.\nConsider the following practice. When software is changed, it may have new bugs. That is why software is tested before it goes to production. But testing costs money, so the game is the following.\nConsider a test, now decide whether to run it, which is a move that brings cost, or don\u0026rsquo;t run it, and risk that it goes bad in production, which may bring a lot more cost. That is the game as it was customarily played before around 2010.\nEnter: automatic testing.\nIf you automate the tests, you will significantly reduce the cost of running them. This means you can afford to do them more often, thus reducing the risk of bugs getting into production.\nNow you are playing a different game. What are the tests that you are going to automate first? Automating tests costs money. The payoff is finding important bugs earlier. The move is to automate, or not.\nThis is a classic investment game. Do I invest in something, such as buying a server, and getting the payoff of low usage costs, or rent a cloud server, and have the payoff of not spending a lot of money upfront?\nUnderstanding the games being played also helps understanding how power flows, because it shows how decisions by actors (moves by players) lead to outcomes such as benefits and costs. Game theory shows that benefits are not always reaped by those who can influence them.\nMoves by one player can influence the moves by other players, because it influences their payoffs. In tic-tac-toe there are often forcing moves that leave the opponent only one choice except to lose. That also is power of one player over the moves of another player.\nIn a similar way, tech providers influence the choices of their consumers. A game a tech provider likes to play is \u0026lsquo;vendor lock-in\u0026rsquo;.\nOnce a consumer has started using a particular service, there will be a cost associated with switching to different provider. This is known as the switching cost. Providers can make several moves:\nkeep switching costs as low as possible, which will make it easy for customers to switch drive up switching costs, of which the payoff is higher revenue drive up switching costs to a really high level, of which the payoff is that they won\u0026rsquo;t be getting many new customers anymore. Customers can make defensive moves, if they plan ahead.\nAnd often, regulators step in to keep switching costs down, in order to protect customers. Phone number portability is an example regulatory move.\n","permalink":"/book/value/game-theory/","title":"Games of value and power"},{"content":"Customer service is a great thinking model for a lot of what is going on in digital infrastructures, even if the customer is not a human, as we will see. We are often buying products, but we really mostly want a service. In an earlier unit, we talked about promise theory\nAn IT services organization deals with customer requests all the time.\nCan I get a new laptop?\nJoe from accounting needs permissions to access this application. Can you fix that?\nI think I clicked on a phishing link. What now?\nThe list is endless.\nMost of these scenarios can be described very nicely with promise theory.\nQ: Can I get a unique IP address? R: Here is your address, let me know when you are done with it\nA: thank you, I am done with this address\nExample IP addresses allocation Example TCP/IP picture\nConnect Q: can you reserve buffer space for a connection? R: yes we promise, here is your initial window size A: thank you, here is your initial window size\nTransmission Q: please accept this data A: thank you, I will forward it, here is your new window size\nRinse and Repeat =-\nService elements: consumer actions and provider responses\nEvery service has multiple components/elements, i.e. Access resource (login, get webpage, …) Create resource (server, virtual disk, mailbox, …) Modify resource (bigger disk/mailbox, new functional module, add friend, …) Create user (provisioning) Create account Talk to a sales representative Negotiate and set up contract Reset password Delete account Delete data (deprovisioning)\nGenerally: anything that can be governed by a permission or can lead to a commitment or obligation\nHierarchy of services Extra note: can you group these in phases: contract, provision, use.. Contract (start – end) Provisioning users within a contract, deprovision Using resources by a user\n","permalink":"/book/diginfra/customer-service/","title":"Customer Service"},{"content":"The units so far have explored quite a few, seemingly unrelated, concepts and observations. Here we\u0026rsquo;ll embed them in a unified framework that illustrates how they fit together.\nFrom the title of this book you can see that the main pillars of that framework include value, power, and risk. To get there, we need a fourth pillar: change. For now, we\u0026rsquo;ll call these pillars layers, though there is no implied hierarchy between them.\nAt the core is the concept of promise-based interactions between autonomous agents (human and technical). Every digital infrastructure can be understood as a network of these promises across these layers.\nIn the value creation layer, we are looking at how these promises lead to value for customers and providers. What are these services? How do we measure their quality? How are they provisioned in a cost-effective way, and how does that lead to business models for the provider?\nIn the power distribution layer, we are looking at who is making which promises to whom (governance), how promises are enforced (contracts, standards, regulations), how control boundaries work between agents, and how scale shifts power dynamics.\nIn the risk management layer, we analyze what happens when promises are broken, how we can find vulnerabilities in these promise networks (security, compliance). We also look at trust assumptions, and how externalities distort risk across stakeholders.\nFinally, the change management layer is where we find feedback loops that stabilize or destabilize systems, technology maturity cycles (from manual to automated), and how promises evolve over time, perhaps as the result of new agents entering the ecosystem.\nThis framework shows how these layers interact. For example, how power structures affect what promises can be made (value), how those promises create potential failure points (risk), and how adaptive change processes respond to those risks (change).\nFor each real-world digital infrastructure (e.g. telecommunications, cloud computing, social media platforms, payment systems), the framework provides a consistent analytical approach that reveals the underlying dynamics shaping its development, adoption, and governance.\nWhat makes this powerful is that it creates a universal language for understanding everything from a simple client-server relationship to complex multi-stakeholder global systems, while acknowledging both technical and social dimensions of digital infrastructures.\nIn the next chapters we\u0026rsquo;ll dive deeper in each of these layers.\n","permalink":"/book/diginfra/unified-theory/","title":"A Unified Framework"},{"content":"\n","permalink":"/home/optimalisatie/","title":"Optimalisatie"},{"content":"Technologies are often called disruptive. But what makes a technology truly disruptive? What has made the PC a disruptive technology? Or artificial intelligence, for that matter? And at what time did it become a disruptive technology? While many would accept that AI was a very disruptive technology starting from 2022 onwards, most of it was available much earlier. GenAI, chatbots, etc. Think of ELIZA, the 60s era psychology chatbot by Joseph Weizenbaum.\nIf we understand the mechanics better, we can begin the see how we can predict these shifts better.\nTechnology power shifts: In the early 90s I saw the PC revolution come up and shortly afterwords client-server computing, including all the things that went wrong. A little later, the Internet revolution from boom to bust, and back up again. Then, early 2010s, cloud computing exploded, and I started teaching cloud security. All of these led to dramatic shifts of power in organizations, and therefore in the way IT was organized. Here I\u0026rsquo;d like to explore the underlying mechanisms.\nWhile there are many uses of the word \u0026lsquo;disruptive\u0026rsquo; in this context, I\u0026rsquo;d like to focus on the degree to which a disruptive technology will shift power in organizations and society.\nIn my professional career I have seen, as mentioned elsewhere, a few major disruptive changes. Most of these significantly changed power structures.\nThe mainframe was typically a central corporate strategic decision, necessitating a corporate IT department. That also implies that conflicts around its use would percolate to the top. This is one of the essentials of corporate governance.\nAI has been around for many years, even decades, but its use really took off after the introduction of a democratized tool that everybody could use: chatGPT.\nPower dynamics shift when we introduce new actors in the ecosystem. For example, minicomputers came within reach of department budgets, causing those departments to also start buying them. ChatGPT allowed people to try out GenAI and apply it to their work.\nMore affordable access to technology introduces new buyers in the game. Freemium business models make that even more accessible. The game is that value from these services is demonstrated with a free proof of concept, which opens the discussion to talk about bigger budgets. It is part of GitLabs official pricing strategy.\n","permalink":"/book/power/powershift-disruption/","title":"Disruptive Technologies"},{"content":"architecture-beta group frontend(cloud)[Frontend] service client(internet)[Client Browser] in frontend group backend(cloud)[Backend] service app_server(server)[Application Server] in backend service database(database)[Database] in backend client:B -- L:app_server app_server:B -- T:database ","permalink":"/posts/example-mermaid-cs/","title":"Example Mermaid Client-Server"},{"content":"Het nationale sentiment is negatief over de afhankelijkheid van \u0026lsquo;big tech\u0026rsquo;. Overheidsdata staat in een Amerikaanse cloud, we hebben geen eigen sociaal netwerk, enzovoort. En vergelijkbare sentimenten spelen bij andere organisaties.\nTerecht wordt daarom nu op overheidsniveau een initiatief in gang gezet om wat aan die afhankelijkheid te doen. Dit initiatief staat ook bekend als Cloud Kootwijk. Maar met een motie in de Kamer zijn we er nog niet.\nEmoties zijn vaak een goede indicator, maar geen goede inhoudelijke analyse. Ze leiden daarom nog wel eens tot beslissingen die onhandig, of zelfs contraproductief uitpakken. Hier legt de emotie wantrouwen bloot, maar waar die zich op richt moet een analyse uitwijzen.\nMijn zorg is dat we die analyse onvoldoende doen, en onze Cloud Kootwijk daarom te laat, te duur, te groot, en/of onvoldoende volledig wordt gerealiseerd.\nLaten we eens kijken welk risico we nu werkelijk lopen met deze afhankelijkheid. We willen voorkomen dat big tech onze nationale autonomie te veel beperkt, bijvoorbeeld doordat het als drukmiddel gebruikt wordt.\nMaar wie zet dan die druk? Deze vraag is nog niet zo eenduidig te beantwoorden. Is het big tech zelf? Is het de Amerikaanse overheid, die de meeste macht over big tech heeft? Of heeft big tech macht over de (Amerikaanse) overheid? Dat maakt uit voor de motieven, en mogelijk ook voor de oplossingsrichtingen.\nWelke digitale dreigingen zijn er eigenlijk? De gebruikelijke insteek bij informatiebeveiliging is: vertrouwelijkheid, beschikbaarheid en integriteit.\nHoe bedreigt big tech vertrouwelijkheid? De gedachte hier is dat als data op Amerikaanse servers wordt opgeslagen, de Amerikaanse overheid er dus bij kan. Dat zit wat genuanceerder. Cloud providers verzettten zich met woord en daad tegen ongebreideld data harken, en dat drijft de kosten voor de Amerikaanse overheid op. Maar veelal krijgt de Amerikaanse overheid haar zin, ook als de data op Europese servers van een Amerikaans bedrijf staan.\nDe bulk van de Nederlandse overheidsdata is echter openbaar, en dat is zelfs bij wet geregeld. Als het gaat om politiek en zelfs militair beleid, is er weinig geheim. Kijk maar eens wat bijvoorbeeld het Amerikaanse Departement van Defensie allemaal publiceert. Metadata en gebruikspatronen zijn minder openbaar, en kunnen gevoelig zijn. Tegelijk hebben buitenlandse mogendheden veel andere mogelijkheden om bij gegevens en informatie te komen. Daar hebben ze Office 365 niet voor nodig. Het vertrouwelijkheidsrisico is wel belangrijk, maar zie ik niet als de belangrijkste reden om te investeren in andere oplossingen.\nHoe bedreigt big tech beschikbaarheid? De Amerikaanse overheid kan dreigen met afsluiten, en zeekabels kunnen beschadigd worden. Dat is allemaal al eens gebeurd. En ook Microsoft kan gewoon plat gaan. Niemand is \u0026rsquo;too big to fail\u0026rsquo;. Vanuit het perspectief van \u0026lsquo;business resilience\u0026rsquo;, bedrijfszekerheid, is deze beschikbaarheid van steeds groter belang, omdat onze afhankelijkheid van digitale infrastructuren steeds groter wordt.\nMaar hoe ga je daar mee om? Is het nodig om een complete kopie of kloon van alle capaciteit en functionaliteit te hebben? Ik denk het niet. Resilient -veerkrachtig- zijn omvat ook wat in het engels \u0026lsquo;graceful degradation\u0026rsquo; heet. Een schade-event is nooit gratis. Er zijn altijd kosten, en honderd procent continuïteit is veelal te duur. Kun je echter de schade beperken, en tijd kopen om alternatieven op te bouwen? Met 20% van je capaciteit en functionaliteit zou je 80% van je resultaat moeten kunnen halen. In het geval van overheidsdata op Amerikaanse servers en software zie ik daarom meer in het hebben van een noodvoorziening die snel opgeschaald kan worden. De pandemie heeft laten zien dat in korte tijd overgeschakeld kan worden naar andere systemen voor communicatie. Dat geldt voor werkprocessen, maar ook technisch. Zoom kreeg in korte tijd een vertwintigvoudiging van het aantal gebruikers te verwerken, en op wat kleine incidenten na is de dienstverlening overeind gebleven. Met cloudtechnologie en cloudbeheermethoden is dat goed te doen. Voor de Nederlandse situatie betekent dat een noodvoorziening met enkele duizenden gebruikers. Dat moeten dan ook wel echte, dagelijkse, gebruikers zijn. Anders is de kans klein - tot verwaarloosbaar - dat dit in geval van nood gaat werken.\nHoe bedreigt big tech de integriteit van informatie? Daar zijn technische risico\u0026rsquo;s, maar die zijn niet vanzelf groter dan in alternatieven. Ik zie daarnaast een subtieler, maar minstens zo belangrijk risico. Social media leidt op een aantal manieren tot beïnvloeding van mensen en hun denkbeelden. De natuurlijke neiging van social media is om mensen in een eigen bubbel, een \u0026rsquo;echo kamer\u0026rsquo;, een \u0026lsquo;fabeltjesfuik\u0026rsquo; te stoppen.\nWe zien dat dat tot minder onderling begrip en meer radicalisering leidt. En het maakt vatbaar voor beinvloeding van buitenaf, zeker als die media in handen zijn van mensen met een politieke agenda. Er zijn bijvoorbeeld sterke aanwijzingen dat met hulp van Cambridge Analytica verkiezingen zijn beinvloed in onder meer Trinidad en Tobago, en de uitkomst van het Brexit referendum is gemanipuleerd. En na de tweede verkiezing van President Trump is er een offensief gestart om via sociale media nationalistische partijen in Europa aan de macht te brengen. Deze technologie kan dus denkbeelden van grote groepen mensen veranderen, ook als dat tegen het belang van een soevereine staat ingaat. Dat is een risico. Een nationaal of europees social media platform heeft niet vanzelf minder van deze risico\u0026rsquo;s.\nDe meest voor de hand liggende optie hier is regulering – hoe ethisch riskant dat ook is. Tussen het beschermen van groepen in de bevolking en censuur van uitingen die tegen de heersende politieke macht ingaan zit immers een flink schemergebied.\nMaar regulering kan wel effectief zijn. Dat blijkt wel uit het feit dat zowel big tech als de Amerikaanse overheid zich met hand en tand verzetten tegen regulering vanuit Europa.\nKortom: onze afhankelijkheid van \u0026lsquo;big tech\u0026rsquo; vergt genuanceerde, maar duidelijke actie.\n","permalink":"/posts/autonomie-van-bigtech/","title":"Big tech afhankelijkheid: wat is het echte risico?"},{"content":"Detection I should have acted on the first signals more aggressively. But let’s talk about that later in this story. Here is the story of my site being infected with malware, viewed by a professional cloud security expert. So I am going to apply all that cloud security theory to it.\nThe hack led to business damage at the end of one of my webinars. In 2016, on a Friday, I did a webinar, at the end of which I had two links to my site as a call to action.\nHowever, three participants reported in the chat that they could not access those links as their corporate firewalls blocked them. Three different security programs (Microsoft, McAfee, and Kaspersky) rated the site as unsafe for various reasons, ranging from detected Trojans to mention of “Malicious software threat: This site contains links to viruses or other software programs that can reveal personal information stored or typed on your computer to malicious persons”.\nSo, instead of continuing the conversation of how I could be of help to these people, and talk about my next program, I stalled. Nobody bought my program. Business lost. And my time suddenly had to be diverted to fixing this. Another loss. This is all real damage. The only upside is that I can write this article about it.\nThat was the detection phase, one of the phases of the NIST incident response process. As I mentioned, I could have found it earlier. For more information on the NIST incident response process guidance at the time of this incident, you can refer to the NIST Special Publication 800-61 Revision 2. A new version is in preparation.\nAnalysis and Eradication Now for the analysis and eradication phase. What the heck was going on? I had very little luck in getting the security programs to tell me what was wrong with the site. Virustotal, which aggregates reports from security providers, reported 1 hit by Yandex, though the diagnostics on their webmaster pages were vague. McAfee and Kaspersky did not seem to have any service that is helpful with this.\nIn the meantime, three more reports came in on the site, adding TrendMicro to the list of blockers. It took my site manager until Tuesday to fix it. Very disappointing. He also was not very communicative about the real underlying problem, other than that is was caused by a WordPress plugin that had not been updated. He did manage to restore the site and clean it. I think.\nAfter I discovered the problem, independently I got a report from a SEO expert, who noticed funny code in the pages, and weird statistics in the analytics. He told me that the malware was in fact a five-year-old Mozilla exploit, which is number 17974 on exploit-db (No link to that exploit, because it gives my site a bad reputation).\nIt appeared to be an automated infection targeted at Mozilla users who had not updated their browsers. My site did not store any customer data, all form submissions go to a separate autoresponder and shopping cart service. So no data was lost or breached.\nRecovery Now for the recovery phase. Malware gone does not equal business problem gone. Even though the malware was erased, my site’s reputation was still suffering.\nGetting off the blacklists is a hard process; they seem to parrot and echo each other. A week after the alleged site fix, I managed to get it off one or two engines. But it is still listed at Yandex, Clean MX, SCUMWARE and CRDF, all of whom don’t appear to have an expedient process of getting off their blacklist. http://www.urlvoid.com/scan/clubcloudcomputing.com/ actually increased the number of blacklisting sites in the past days and added Fortinet’s FortiGuard.\nOne of the engines rates my site as bad because it links to a bad site, namely itself. How Catch 22 can you become?\nSounds like a bad vigilante movie, where the main characters don’t care too much about the collateral damage they inflict. Listing malware sites is easy enough, delisting apparently is harder.\nSo this reputation might haunt me for who knows how long. Maybe the domain will never really recover.\nOn the positive side, some corporate firewalls reset the reputation after a few weeks. But be aware that most corporate firewalls are extremely paranoid, as they probably should be. Just having a simple link in my email message pointing to my homepage had that message marked as [SUSPICIOUS MESSAGE] by one of the big four advisory firms.\nPreparation Finally, back to preparation. What could we have done to prevent this, or at least reduce the impact of the problem?\nI have a backup running of this website. It is a WordPress plugin that dumps the entire site’s content in a DropBox which is synced to my PC. Weeks before the webinar, I had installed F-Secure on the PC, and it barked on one of the files in the DropBox folder. I reported this to my website manager, but I knew that it was in a part of the website that was not in use, nor accessible to the users of the website. That led me to believe it was a false positive, but I should have known better.\nIn the end, having the site itself generate a backup is not sufficient. The advantage is that the backup should be easy to restore, but malware might take the backup software or its configuration as a first target. In fact, I suspect that in my case the malware created a few hundred thousand files, which clogged my DropBox synchronization. However, I could not finish the forensics on that.\nThe site manager restored the site from a filesystem backup. I did not have access to that. Externally spidering the website, and versioning it may be better. At any rate, this is a case for generating fully static websites.\nSo, obviously the best direct preparation is regularly updating software and removing software you don’t need. Case in point: the malware was inserted into a piece of forum software that we never got to work properly. In the end we abandoned it in favor of a managed cloud solution (an e-learning platform).\nCloud security reference model The cloud security reference model of the Cloud Security Alliance asks us to identify who is responsible for what piece of the software stack. I don’t think there is much confusion about who was supposed to keep the site’s software up to date. My site manager never denied that he was. But he did not put in any warning system, and ignored my F-Secure warning. He also did not yet provide adequate forensics to me after the fact. Maybe a regular customer won’t need those details, I can see that. But I have professional interests beyond that, as this article proves. Of course, my site manager is not the only one responsible for the software. He did not write it. The site’s software and plugins are either commercial or open source. Both have their own update policies or lack thereof. Both can be abandoned by their developers. But somebody needs to track that too.\nManaging one custom WordPress website at a time is not likely to be a very viable business model in the long run. If your website is not very complicated functionally, you might consider static hosting, or move it to a cloud based website builder like squarespace.com or wix.com. You would still have to check their competence, but with thousands or hundreds of thousands of websites at stake, these companies are more likely to have the motivation and the resources to properly manage these risks.\nAs a business owner, I am ultimately accountable for all IT risks that affect my business. Remember, any provider, including a managed hosting provider, can fail. You need a plan B. I do have some backup of the most important documents on my site. I wrote them. But in the end, the most irrecoverable asset lost here might be the domain name. As a precaution against that, I could have considered to have the most important pages also hosted on another domain. In fact, I might have to do that, if this domain isn’t delisted quickly enough. It is a telling and disturbing sign that registrations for my newsletters these days mostly come from public email providers, not companies.\nWrapping up I am disclosing my misfortune so that it may be of help to people. Whether you work in a large corporation or a small one, are on the consumer or on the provider side, you can use this case to improve your own management of IT risk.\nWhat are the biggest lessons you should take?\nReputation damage that gets its way into the firewalls and proxies of customer companies leads to real and lasting business damage.\nExit and recovery plans can be considered on multiple levels. Sure, the basic backups matter, but at all times consider your business continuity from the top down, starting at your domain name.\n","permalink":"/book/cases/how-my-site-got-hacked/","title":"How My Site Got Hacked"},{"content":"Five elements of cloud security Historically, IT security started with infrastructure security. Just protecting the data center was good enough. But that was before we had data communications.\nWhen data started to escape the confines of the data center we needed to protect it. Typically through encryption. Hence we need data security.\nAs the world wide web developed, we saw applications being exposed to it, and frankly, be vulnerable. So that is when application security started to become more important.\nWith the proliferation of applications, both within the enterprises and outside of it, keeping track of user access became more important too. That is when we start talking more about user security (or identity management).\nFinally, as we are outsourcing to more and more individual software and cloud companies, we need to structure our oversight of those service relationships. That requires governance over contracts, SLAs, and more.\nCloud computing is having an impact on all of these five elements. Some are made easier, some increase in significance, some will change shape. Watch the video for more details.\nReview this video to learn more on these five elements of cloud security. Cloud security includes IT security as we know it, but will evolve to be more mature than that. In the video I elaborate on those five as they have evolved. Then I talk about how cloud changes our approach to those five elements.\nMore in other units.\n","permalink":"/posts/5-elements-of-cloud-security/","title":"5 Elements of Cloud Security"},{"content":"How cool would it be to let an AI do some of the grunt work in analyzing the risk of applications and services. This has the potential to speed up the work of risk assessors.\nBut, does it work in practice? Well, here is an example of AI-assisted risk classification. I downloaded some of the entries in the Dutch algorithm register, which is a public register of systems that use algorithms. For each entry about 30 fields are available, including name, classification, owner, et cetera. Some of the systems in the registry are AI-based. Indeed, we have AI to help check on AI\u0026hellip;\nMy approach was to do some dialogue with Claude 3.7 Sonnet on a few cases. You can get the full description of each case from the algorithm register.\nMe: Here are three examples. Please return the name of the system, and your assessment if it uses an LLM or not.\nClaude:\nI\u0026rsquo;ll analyze each of these systems and classify them as either LLM-based or fixed algorithm-based.\nVirtual municipality assistant Gem\nClassification: Uses Machine Learning, but not an LLM Reasoning: The description states it uses \u0026ldquo;supervised machine learning\u0026rdquo; to match questions with answers from a predefined library. It calculates which existing answer best matches the question rather than generating new responses. This is more characteristic of a simpler ML classification system than an LLM. AI WBSO pre-advice\nClassification: Machine Learning, but not an LLM Reasoning: The system is described as a \u0026ldquo;self-learning Machine Learning model\u0026rdquo; that makes predictions based on specific variables to estimate risk. It appears to be a predictive model focused on risk assessment rather than language processing or generation, making it a non-LLM algorithm. Energy label generator (EP-Online)\nClassification: Fixed algorithm Reasoning: This system uses predefined formulas and calculations to generate energy labels based on specific inputs. The description mentions algorithms but refers to calculation procedures described in technical documentation rather than any learning models. This is clearly a deterministic system using fixed rules and formulas. None of these three systems appear to use Large Language Models. They each use different approaches: supervised machine learning for answer retrieval, predictive machine learning for risk assessment, and fixed algorithmic calculations for energy label generation.\nMe: Which of these processes personal data, just based on the description?\nClaude:\nBased on the descriptions provided, here\u0026rsquo;s my analysis of which systems process personal data:\nVirtual municipality assistant Gem\nProcesses personal data: Yes Reasoning: Although not explicitly stated, this system interacts directly with residents and businesses through chat functionality on municipal websites. It collects questions from users and monitors their feedback. The system likely processes some form of user identifiers to maintain conversation context and improve answer selection based on prior interactions. AI WBSO pre-advice\nProcesses personal data: No Reasoning: The description explicitly states \u0026ldquo;No personal data are used in the algorithm in any way.\u0026rdquo; It mentions using data like number of projects, hours, wages, etc., but specifically notes that only the case number is used as an identification label. A DPIA (Data Protection Impact Assessment) was carried out with the outcome that no personal data were processed. Energy label generator (EP-Online)\nProcesses personal data: Yes Reasoning: This system likely processes personal data as it generates energy labels for specific buildings owned by specific individuals. The fact that a DPIA was conducted (and is being updated) suggests personal data is involved. The system records data about buildings that can be linked to their owners, especially since the labels are required when selling or renting properties. Based solely on these descriptions, the Virtual municipality assistant Gem and the Energy label generator appear to process personal data, while the AI WBSO pre-advice system explicitly does not.\n(end of chat interaction)\nThis is a promising beginning. There are around 800 of these cases to review.\nInteresting followup questions either on the entries or on the approach could be:\nIs the description consistent with its classification? For example, there is a \u0026lsquo;risk\u0026rsquo; field, but does it match the rest of the description? Which entries seem to be missing crucial information? Which entries store specific types of data? Can we automate this a bit more? Stuffing the entries in a chatbot prompt does not scale very well. What is the accuracy, and will other models have similar accuracy? ","permalink":"/posts/ai-risk-classification/","title":"How AI Can Help IT Risk Classification"},{"content":"The international arena has many actors that can influence digital infrastructures. But opinions differ on what the important ones are, or even what the relevant ones are, as we will see. But the international arena matters, because by the nature of scaling, very few digital infrastructures are influenced by a single national actor only.\nA word of clarification: I am using the word international here to mean all nations in the world, and their interrelations. In US vernacular, the word international appears to mean all nations, except the US. Instead, the word global is used to mean all nations, including the US. An example implication of this is that a US company would only consider ISO standards to be relevant to them if they also have operations outside the US.\nThe international arena is complex, and there are conflicting views on how it is made up. These conflicting views can best be seen as maps of the territory. And as I have mentioned earlier, a map is only relevant for a specific purpose.\nThe first category of actors is nations, obviously. The word nation is part of the word international. But we can see many other actors exerting influence, such as multinational corporations, NGOs (non-governmental organizations), treaty organizations, and so on. Let\u0026rsquo;s break this down a bit.\nNations make laws, multinational corporations make investments and offer products, NGOs such as ISO make standards, treaty organizations such as the EU make more standards and regulations. All of these may impact digital infrastructures. And sometimes these are conflicting.\nNot everybody shares this multifaceted view of the international arena. Some hold that nation states are the only actors that have real power. After all, they control the territory on which people live, and have a monopoly on military force and a legal monopoly on violence. Their power is a function of their population and their natural resources.\nIn this view, nations enable the other types of actors through law and agreements within and between them. Multinational corporations don\u0026rsquo;t really exist in this view. They are constructs enabled by agreements between nations, for example on recognizing property across borders. For example, how is it possible that a national of one country can hold property in another country? This is not universally the case. Many countries do not allow this, at least not unlimited.\nA multinational corporation, even if it has public shareholders across the globe, has a primary residence somewhere. And the legal options and obligations trickle down from there.\nSimilarly, NGOs such as ISO (International Standards organizations) and the International Criminal Court are also established somewhere, and recognized by other countries, or not recognized, as the case may be.\nDigital infrastructures don\u0026rsquo;t necessarily map easily to a single organization running them, or even governing them. The internet is a interesting and complicated example. On a day to day basis, internet service is largely provided by telecommunications companies owning the cables and radio base stations. Administering the coordination between these and other providers, is done by many actors. For example the use of IP addresses is coordinated by a non-profit established in the US. But there are many more players in that space, often independent.\nIn contrast to the multi-nation view of the world is the perspective that what really matters in the international arena are the multinational corporations. They have significant control over the international flow of goods, services and investments. Understand that many of these corporations have annual turnovers that are larger than the gross domestic product of 80% of the world\u0026rsquo;s countries.\nLarge businesses have the capability to drive government policies. Even US presidents see that. President Eisenhower warned about the military-industrial complex in 1961. President Biden extended that, and warned against the power of the tech industry and AI in particular in his last speech in 2024.\nThis is not hypothetical. There has been successful lobbying by US companies against international regulation that is seen as limiting to them.\nMany multinational organizations are largely legitimate, but there are quite a few whose main objective is to launder money outside of the control of nations. Beyond that, when it comes to cybersecurity, internationally organized crime has business models that include ransomware extortion and bitcoin mining on hacked computers.\nThen there is the perspective that the only really important international actor is the US. With more than 700 military bases in more than 80 countries, this is the single largest international military presence in the history of mankind. Additionally, since the end of world war II, the US has allegedly intervened in dozens of countries, through military or other means, three times more than Russia, the next contender. By the way, these numbers are hard to validate precisely, though the order of magnitude is uncontested.\nBeyond this, the US dollar is the currency of reserve for most of the world, and the US stock markets dominate international capital markets.\nAs a final alternative perspective, it is conceivable that there are people who think China has always been, and will be, the economic superpower of the world, with a brief 200 year interruption which is about to end.\nAll these actors may exert power over digital infrastructures. And to confuse matters even more, these actors do not always acknowledge the power, or even the existence, of other actors. We\u0026rsquo;ll discuss some examples of this elsewhere.\n","permalink":"/book/power/international-actors/","title":"International Actors"},{"content":"Who is really doing Zero Trust?\nWell, the US Air Force is. Here is my summary, with some comments, of their strategy document for the benefit of my Certificate of Competence in Zero Trust (CCZT) learners. In fact, this is an edited version of a conversation we had during one of our classes.\nYou can download the full strategy here, and the current roadmap here, all linked from this page.\nI think the fundamental first important point about the strategy document is that it exists at all. There is an actual organization of significant size that has a strategy and is implementing it. Many can learn from this.\nThe second major point is that its terminology and even its conceptual frame of reference is almost 100% CCZT compatible. Even better, it lists more specific initiatives than the Zero Trust courseware itself. So rather than talking about a strategy, it actually is a strategy with strategic goals and sub-goals that match.\nI am not repeating the strategic goals and subgoals here. They align with CCZT, and the strategy document is succinct enough.\nData is considered to be the strategic asset to protect. It is really focussed on protecting the data. Side note: for regular organizations, it is actually quite hard to have a top-down understanding of the value of data. Anyway, the focus on data represents a shift away from a network centric security strategy. In fact, the current strategy is defined as network focused, defense in depth, castle and moat.\nBenefits Already in the summary it mentions three important benefits of the strategy, instead of just saying \u0026ldquo;We need to be more secure\u0026rdquo;.\nReduction of architectures Unlock access Impose higher costs on adversaries The strategy summary states that it reduces the number of architectures. Later in the document, it\u0026rsquo;s a bit more specific about that, saying there are too many point solutions and stop-gap measures across that entire network. This is what happens - you start with a low-security network and then as you mature your requirements, if you don\u0026rsquo;t have an overall strategy, you get all these point solutions and they are expensive simply because you have so many different ones. So the zero trust strategy has, as one benefit, that you will have less of these.\nIn IT, migrating from a functioning system to a new one rarely has a strong business case. As a matter of fact, that\u0026rsquo;s true for a lot of technology. If it ain\u0026rsquo;t broke, don\u0026rsquo;t fix it. That\u0026rsquo;s for a number of reasons. One of them is the business case: it is too costly. But if you\u0026rsquo;re not happy with the current situation, you have a change imperative and the business case changes because your migration cost is a sunk cost and no longer something that needs to be recouped.\nThe most important functional benefit mentioned is that it unlocks access. And a little later it explains: \u0026ldquo;to shared and trusted information.\u0026rdquo; This is enabling warfighters. Well, also a lot of other roles. But the mission of the air force is to fight, or at least demonstrate the capability to fight, which is probably even more important than the actual fighting. It\u0026rsquo;s fairly obvious that you want to do this in quite adverse network circumstances. They even have an abbreviation for that - DDIL (denied, degraded, intermittent, and limited) - for situations where you may or may not have a connection to your drone, for example.\nThe third one that I liked from a security mindset perspective is that it imposes higher costs on adversaries. They don\u0026rsquo;t say we need to protect ourselves from adversaries, because that is not a goal that has a measurable KPI. It\u0026rsquo;s hard to say \u0026ldquo;okay, we\u0026rsquo;ve reduced our exposure to adversaries.\u0026rdquo; The adversaries are all over the place. In fact, without adversaries, you wouldn\u0026rsquo;t need to have an air force.\nSo what they\u0026rsquo;re saying is, okay, our defensive strategy is based on increasing the cost of the attacker to attack us. This is military doctrine - you end a war when the enemy no longer wants to fight you. That\u0026rsquo;s the military definition of ending a war, dating back to Sun Tzu. One way of doing that is raising the cost for them to continue attacking you.\nSo I liked these benefits very much. I think they\u0026rsquo;re understandable on a strategic level.\nScope In terms of coverage, the strategy sometimes looks like buzzword bingo. First of all, it mentions all new developments like AI and IoT. It includes top secret data and operational technology. Cloud and mobile is included, even non-IP devices. Microservice architectures.\nIt acknowledges that more endpoints are moving to the cloud.\nOld is new again? The strategy contains a lot of elements that you already see in mobile security infrastructures that are being build these days. Mobile, cloud, \u0026rsquo;new way of working'.\nIt is a theme that we\u0026rsquo;ve seen before - zero trust isn\u0026rsquo;t about reinventing the wheel. It is not about reinventing all great tactical security stuff we already know. Most of that is still useful.\nZero trust is a more comprehensive and consistent approach to stuff that we already know.\nPotentially a new technology that is explicitly mentioned is SDP (software defined perimeter). But even that has its roots in earlier technologies such as the knock knock protocol. SDP is a more structured variant of that.\nSDP is fairly directly stated as a tool to eliminate VPNs. This is a substantial driver of the benefits mentioned.\nMaturity and automation Section three includes a small maturity model, in which an important dimension is \u0026lsquo;automation\u0026rsquo;. In the document, the mantra is repeated regularly: we do this initially with manual efforts but we must evolve to a real-time and automated approach. I think the nice thing here is that it acknowledges that you need to get started on it and don\u0026rsquo;t overautomate in the beginning, but that manual processes are not sustainable in the long run.\nYou don\u0026rsquo;t want to automate what you don\u0026rsquo;t understand. So there\u0026rsquo;s a fine line there. As a matter of fact, I\u0026rsquo;ve written earlier about this in the context of automating system management and network management. And one of my former colleagues had a PhD thesis of which that was the most important result.\nThe big elephant Another interesting point, the ramifications of which are not immediately clear, is that without mentioning Microsoft, the document states: \u0026lsquo;We have Active Directory Domain Controllers all over the bleeping place.\nThis is the Microsoft Active Directory architecture where every location has its own domain controllers - and this is archaic because this is from the period that you had flaky connections to offices. In the old time at banks where I worked, every office had an active directory domain controller. In fact, two because of high availability requirements. But it\u0026rsquo;s an attack surface. The Air Force says we have over 180 sites, so we have more than 360 attack surfaces.\nOne of the stated objectives of the strategy is to drop the dependence on these Domain Controllers. Now, how they are actually going to do that, it doesn\u0026rsquo;t say, but I thought it was a really interesting point to make.\nLogging and shared responsibility What I liked also is the emphasis on comprehensive security event monitoring and logging, including application security events.\nThey also highlight the need for a \u0026lsquo;shared responsibility model\u0026rsquo; for handling those events, involving both external security service providers and internal security operations centers. I think that\u0026rsquo;s a nice frame of mind or a nice thinking model on how to roll that into your architecture.\nGovernance and risk Strategy can be a theoretical exercise. How do you pull this off in reality? The final part of the paper prescribes how the responsibilities for the implementation are delegated to various offices and units within the Air Force organization. A dozen of them are mentioned, and it even spells out where some of the deconflicting of priorities is going to happen. Deconflicting is a core element of governance - that you find out: where are the conflicts and how do we actually handle them?\nInstitutional resistance to change is identified as the greatest risk, as it requires \u0026lsquo;all communities to adapt in uncomfortable ways.\u0026rsquo;\u0026quot;\nAmen.\nOpen ends In a couple of places, it says we need to do discovery of everything on the AFIN - the Air Force Information Network. And then somewhere else, it says we have a cloud-first priority. My question: wait a minute, are those cloud services part of the Air Force Information Network or not? It depends a little bit on your definition of what a network is. This is, by the way, not new for this document. I\u0026rsquo;ve seen that ambiguity over the past 30 years in a couple of other ways and places. Is the network the stuff that routes packets? Is it everything that you can reach from a certain device? Is it all the servers? Does it include all the clients?\nIt\u0026rsquo;s a little less clear how that works. So there are some loose ends on the edge of the strategy.\nWhat I also did not see is how progress is going to be measured, and how you would audit or assess that.\nIn conclusion: read this if you are interested in enhancing your IT-based capabilities while reducing your security costs.\n","permalink":"/posts/airforce-zero-trust-strategy/","title":"The US Air Force Zero Trust Strategy"},{"content":"Here is the draft design of the graphic novel version of this book, which may or may not happen..\n","permalink":"/posts/graphic-novel-page1/","title":"Digital Infrastructures - the graphic novel"},{"content":"Building Our Own Cloud Kootwijk: Rethinking Digital Sovereignty In the Netherlands, we are currently engaged in a heated debate about the undesirable dominance of big tech, particularly over a significant portion of the digital infrastructure of the Dutch government. This includes email, file storage, and many other forms of digital storage and processing—most of which are handled by American big tech companies.\nI am sure a similar debate is going on in many other countries.\nGiven this reality, what can we do about it? How can we build our own \u0026ldquo;Cloud Kootwijk\u0026rdquo;?\nExploring Alternatives Setting up a comprehensive, government-funded solution does not seem like a viable approach. History has shown many failures in such attempts. Moreover, our current procurement processes do not lend themselves to agility. Due to the scale involved, any such initiative would likely end up with a large, well-established company.\nThis brings us to another challenge: every big tech company is, or ultimately becomes, an American company. The two largest software markets in the world are the U.S. and Germany. Even the largest German IT firms cannot afford to ignore the American market and are often listed on U.S. stock exchanges.\nAs a result, every big tech company—directly or indirectly—falls under the control of the U.S. government, regardless of its political orientation at any given time.\nRethinking the Approach With this in mind, we need to rethink our strategy. If big tech is not the answer, how can we organize \u0026ldquo;small tech\u0026rdquo; in a way that makes it a viable alternative for a large-scale buyer?\nWe are talking about digital infrastructures that are essential to the functioning of our society. These infrastructures have a certain \u0026ldquo;commodity\u0026rdquo; nature and do not primarily revolve around innovative applications. In principle, they should be deliverable by multiple companies.\nThere is no fundamental barrier to IT services being provided by a consortium of service providers. In fact, this is how the Internet has operated for decades. Its core consists of open standards that facilitate a market of service providers with sustainable business models. To prevent monopolization, these markets need some level of regulation, including enforcing open standards for interoperability and portability. In the case of strategic autonomy, additional rules regarding ownership of these companies may also be necessary.\nWhile having much of the underlying software available as open source would help, it is not essential. Open source is neither a sufficient nor a necessary condition for interoperability and portability.\nOpen standards (ideally with open-source reference implementations) are more important. They also contribute to another critical element of \u0026ldquo;small tech\u0026rdquo;: building sufficient expertise.\nKnowledge as the Foundation of Autonomy In my view, IT services consist of hardware, software, and systems management . Management can be broken down into processes and skilled personnel. Most of these elements are either commodities or readily available.\nFinding enough personnel competent in the relevant technologies is more challenging, but not impossible.\nTo achieve a sufficient level of autonomy in digital infrastructures, we need to develop and maintain this expertise. The best way I know to do this is to start small and scale up. Expanding by a factor of ten at each step is an ambitious yet achievable goal. This points towards managing our digital infrastructure through a consortium of smaller companies. The VNG’s Common Ground and Haven initiatives offer promising examples in this direction.\nA Call to Action I challenge both policymakers and society to launch a production pilot using a fully open-source office automation environment. I believe we could select the necessary open-source components for such a pilot in an afternoon. Managing this at a scale of 1,000 active users would be an excellent starting ambition. This will take months—perhaps longer—but if successful, it will provide a blueprint for a \u0026ldquo;Cloud Kootwijk\u0026rdquo; should the need become urgent.\nWill this be painful? Yes. But not as painful as realizing too late that we have lost our democracy and prosperity to a foreign power—or worse, to a group of multinational corporations that are not even under the control of any state.\n","permalink":"/posts/how-can-we-achieve-autonomy/","title":"How Can We Achieve Autonomy Over Our Digital Infrastructures?"},{"content":"A diagram should automagically appear here.\nsequenceDiagram actor Client actor Provider Client-\u0026gt;\u0026gt;Provider: Query Note right of Provider: Please promise me to bring a drink Provider-\u0026gt;\u0026gt;Client: Ack Note right of Provider: I promise to bring you a drink in a short while Provider-\u0026gt;\u0026gt;Client: Reply Note right of Provider: Please promise me that you are satisfied and will pay Client-\u0026gt;\u0026gt;Provider: Ack Note right of Provider: I promise to pay you for the drink %% icons from https://iconify.design architecture-beta group api(Storage)[API] service db(database)[Database] in api service disk1(disk)[Storage] in api service disk2(disk)[Storage] in api service server(server)[Server] in api db:L -- R:server disk1:T --\u0026gt; B:server disk2:T -- B:db block-beta in space llm:2 space out in[\u0026#34;Prompt\u0026#34;] --\u0026gt; llm[\u0026#34;Large Language Model\u0026#34;] llm--\u0026gt; out[\u0026#34;Completion\u0026#34;] style in fill:#fff,color:#000,line:#000;stroke-width:0px,color:#000,stroke-dasharray: 5 5 style out fill:#fff,color:#000,line:#000;stroke-width:0px,color:#000,stroke-dasharray: 5 5 ","permalink":"/posts/mermaid-example/","title":"A mermaid diagram example"},{"content":"A while back, I introduced my take on deployment diagrams for cloud and devops infrastructure. Some of the big points there are: it starts with intuitive drawings. Many people draw these things in similar ways, even without them having formal training. In fact, formal training in architecture diagrams will not necessarily make those drawings easier to understand for the uninitiated. But still. There are good drawings and there are drawings that can be improved. My other big point is that deployment diagrams can be a great tool for security analysis. I am in some conversations with friends at banks who use them. Recently I ran into the following example. Here is an explanation of the difference between VPC and security groups. Great story, but I have some comments on the diagram, which used to come from AWS itself, by the way, but has been removed.\nHere is the diagram. In my earlier post, I gave some informal principles for drawing these diagrams. In brief, they are:\nboxes denote \u0026rsquo;execution environments\u0026rsquo; where code runs and data resides lines denote connections between those execution environments closed curves enclose \u0026lsquo;control boundaries\u0026rsquo;. How does this diagram deviate from those principles? Let me know…\n","permalink":"/posts/network-diagram-fix/","title":"Deployment diagrams for network security; fix this"},{"content":"Cloud-native software development enables new practices. But it also requires them. It is a new level of working. However, putting all these new practices together requires integrating a lot of pieces. To illustrate this new approach, I have started to develop a minimal application. Although minimal, I run it in production. Its basic function is to regularly pull out data from an air quality sensor into a cloud-based database. Together it is a few hundred lines of code. Here are the major features of the example:\nAPI programming examples (Foobot, io.adafruit.com) \u0026lsquo;Server-less\u0026rsquo; architecture Google Cloud Platform focussed Continuous delivery through Google Cloud Build Version control Automated unit, integration and security testing BigQuery Continuous monitoring through StackDriver Slack integration for build and run notifications Secrets and credentials management in a DevSecOps world Workflow for Python-based development (atom, pyenv, pytest, bandit) You should be able to replicate this setup yourself. More tutorial explanation is in my GitHub repository. There you can find the code as well as a more detailed explanation. In that, I dissect the full approach theme by theme, topic by topic.\n","permalink":"/book/cases/tutorial-cloud-native/","title":"A Small Example of Cloud Native Development"},{"content":"Does security in the cloud ever bother you? It would be weird if it didn’t. Cloud computing has a lot of benefits, but also a lot of risks if done in the wrong way. So what are the most important risks? The European Network Information Security Agency did extensive research on that in 2009 already, and identified 35 risk categories. This analysis is used by a number of players in the industry, including certain banking regulators. From those 35, ENISA has selected 8 as the most relevant ones. This article explains them, not in any particular order. (And by the way: ENISA is pronounced as ‘eniesa’, not ‘enaiza’). You can also get the story on my YouTube video.\nLoss of governance As a cloud consumer you need to be sufficiently in control of your IT systems. If the cloud service agreement does not give you the proper tools, you have a problem. Example: you should be able to make a backup of your important data and get it out of the cloud provider system.\nLock-in Can you move your data and processes from one provider to another? It will always take you effort, but how much? On the infrastructure level it may be fairly straightforward to move to a different provider, but it may be significantly more expensive to move to a different CRM (Customer Relationship Management) system. Don’t get too scared though; remember that most companies have gone through similar projects before there was cloud.\nIsolation failure Cloud computing, by definition, is about sharing resources: i.e. processing capacity. Now if one tenant (cloud word for customer) can influence another’s resources that is considered isolation failure. One example is starving a tenant of CPU power. Another is hacking into another tenant’s virtual machine (which is pretty hard, by the way). A third example is leaking information between tenants, which happened to DropBox a while ago.\nCompliance risks A lot of cloud consumers need to demonstrate that they take proper care of their data, for example because it contains credit card numbers. If your cloud provider does not help you with that, you are in trouble.\nManagement interface compromise This is another of those ‘risk-speak’ jargon expressions. You probably control your cloud usage through some portal over the internet, which potentially allows a bad guy from anywhere in the world access.\nData protection This is similar to compliance risks. Can you check that all data is handled in a lawful way? Are you sure that their back end providers do the same? Certification can go a long way towards demonstrating that, by the way.\nInsecure or incomplete data deletion You are asking your cloud provider to store your data safely, which they probably do by making multiple copies. Then you ask them to delete that same data. That might be hard, as it probably is on multiple disks that are shared with other customers, so they cannot simply shred the hard disks. This problem is not very unique to cloud by the way. You may have it with your own servers, printers and copying machines, all of which contain a lot of storage.\nMalicious insider In a cloud provider you have a number of people who may have extreme powers because they can look at all data. One well know ridesharing website had implemented and used a ‘God View’, in which one person could look at all the data. If you are evaluating cloud solutions, it makes great sense to take a look at each of these eight risk categories first, to see how you and your cloud provider would be handling them.\nHere is a YouTube video going over these resources.\n","permalink":"/posts/top-8-cloud-risks-according-to-enisa/","title":"Top 8 cloud risks according to ENISA"},{"content":"Even in a cloud world, reducing server count is a lofty goal in itself.\nAfter all, you would be paying for all those servers anyway. Understand that sticking all your servers in a private cloud makes them more flexible, but not necessarily more efficient or cheaper.\nBack in 2012 I did an interview with a guy who has a full time job in keeping those server counts down. Ron Kaminski is a capacity planner at Kimberly Clark Corporation (KCC). This interview is a composite of several conversations I had with Ron at the annual Computer Measurement Group (CMG) conferences, and a number of messages Ron wrote.\nPeter van Eijk : Ron, when you joined KCC you helped stop their trend of building a new computer room every 6 months, down to no new computer rooms at all. Is that right?\nRon Kaminski : Yes Peter, that was basically what happened. As a result of the development of the business, there was a big growth in applications. Each of these applications brings in a lot of servers, because of the multi-tier architecture, and because you need test and development servers.\nPeter : Could you tell us a bit about the way your firm stopped the server growth? What are the most important tactics?\nRon : Invisible machines proliferate, so make them visible. To begin with, automate the measurement and maintain web delivered graphical displays of the resource consumption of each and every server. This will allow you to identify unused and under used servers, which you can then repurpose to projects and applications that have a real need for them. A lot of times, a detailed performance analysis suggests changes in the application that will drastically reduce its resource needs. Think bad/missing database indexes, memory leaks, and runaway/looping processes.\nPeter : Everybody loves clouds these days, and if they can’t get any public clouds, they will settle for private clouds. What are the most relevant lessons for those adopters?\nRon : Basically two lessons: You still need to do capacity planning, and you have to automate or you will fail. Many folks say “Why bother with capacity planning? The cloud is infinite!” and that is only true as long as your wallet is infinite too. We need to be sure that we have tracking and review of intended business volumes and costs, in order to make decisions about when we need to use or not use cloud resources intelligently and economically.\nPeter : Yes, computing is still not free. How far do you need to go with automation?\nRon : Well, what we have learned is basically “Automate or die!” both for creation and removal. If we expect to use either internal or external clouds, we need to stop doing setups that involve humans in any way. This means that we must have standardized services that are engineered and/or architected to be complete environments, including necessary databases and other services in place. There should also be administrative checking/post creation review, with removal if determined to be wasteful.\nA key point that we need to have is the notion of “server lifespan” and automatic deletion at end of life. Folks will fight this until they get comfortable with how easy it is to get a new one. If we don’t have “delete at end of lifespan” all this automation will lead to massive server sprawl and OS image proliferation, and all cloud vendors are counting on this for their profits. They know that firms left to their own devices will “create and forget” so they will continue to bill for unused servers. We need to get very good at noticing and removing dormant servers or risk large wasteful bills. We also need automatic “backup/ archive and restore” of cloud resources, so that they can be completely restored swiftly in a totally automated manner.\nPeter : So what about performance analysis?\nRon : The universally accepted best practice is to contractually demand collectors deployed in the clouds to allow performance analysis. Naive business people will have quite a shock when they still have slowness issues when running in giant clouds, when their applications are not engineered to succeed in the method they are deployed. Examples of these include single-threaded applications, chatty applications over long network distances, and architectures with locking/latching issues. These will still have poor performance in the biggest cloud in the world. The truth is we will still need development and testing in the cloud world, and check up on performance.\nPeter : The CMG community has a lot of technical deep dive experts, and they have taken to analyzing server virtualization in great detail. What where the most important lessons that you picked up from these presentations?\nRon : The depth and complexity of issues covered in many sessions on VMware really made me wish that we sent more VMware resources to the CMG conference. In a nutshell: We should be at the most recent versions, as the performance and scheduling losses on older ones sometimes exceed 30% or more of the physical machine’s resources. One particularly surprising item was that when current VMware has a 4 VCPU “guest” that is in a computable state, it waits to schedule it until all 4 CPUs are simultaneously free. More scarily, 8 VCPU guests wait to be scheduled until all 8 are free simultaneously. That means that there can be lots of waiting on relatively lightly loaded machines, say if there is a CPU loop in another guest slice. Since we have so many 8 VCPU mail systems, this really gave me the willies. We need to dig deeper on these and determine the performance losses this may be causing for us.\nPeter : What other policies come out of these experiences that you want to suggest to your IT management?\nRon : VMware still takes some measurable amount of resources/overhead, and we really should avoid VMware for servers of any significant continuous consumption. We need to set a corporate policy for maximum usage allowed to be virtualized.\nPeter : Thanks ever so much Ron, is there any place online where people can go to get to know more about this stuff?\nRon : Join CMG and get to the conferences.\n","permalink":"/book/cases/stopping-senseless-sprawl-of-private-clouds/","title":"Controlling Cloud Sprawl in 2012"},{"content":"One of the big projects I am working on right now (2006) is directory services for identity management. In these directories digital identities such as loginnames, addresses, access rights, etc. are stored. With an adequately structured directory service, the proper management of access rights becomes a lot easier, which translates into cost savings and better security.\nExamples of these include the internet\u0026rsquo;s Domain Name System (DNS) and Microsoft\u0026rsquo;s Active Directory. A lot of organizations however, have requirements beyond these systems, and for these a wide range of custom solutions are used.\nIn order to improve on that, we must see directories as infrastructures. The management of user names, their access rights and personal preferences can be separated from the applications and consolidated into a single directory. As an example, you can think of one login name to use for multiple independent websites. This will allow users to work with only a single digital identity, and it will allow systems management to have better control over who accesses what. As this infrastructure is separated from its applications one will get all the usual issues: it becomes more important to specify the services, the service levels, and the way in which demand is matched with supply.\nDirectories as infrastructures also differ from other infrastructures. Although the technical operation can often be centralized, the management of the actual user information is delegated in a hierarchical way. In addition, access control on the information in the directory itself, who can read or modify what, is very fine-grained.\nAll in all, we see that creating a directory infrastructure requires a lot of attention to management issues. Furthermore, it would make an interesting business case study as to why self-administered public directories for identities are not gaining a lot of traction.\n","permalink":"/posts/directories-are-also-infrastructures/","title":"Directories are also infrastructures"},{"content":"Network neutrality has become the topic of intense discussion and legislative action.\nSee the Washington Post , a Wikipedia article, and CircelID.\nWhat is the issue?\nOn the one hand people argue for \u0026lsquo;universal service\u0026rsquo; that say that one person\u0026rsquo;s bits should not be treated differently from another person\u0026rsquo;s. This compares to the idea that the phone company should not be allowed to treat your calls differently depending on what you want to say, or that red haired people would have a different monthly fee. There are laws against this type of discrimination (at least in most nations), and some people want to extend this law to Internet traffic. On the other hand there are some Internet providers who want to charge different customers different rates for different service. \u0026ldquo;We can\u0026rsquo;t have companies freeloading on our expensive pipes\u0026rdquo;, they claim. Clearly we seem to want both. We don\u0026rsquo;t want the phone companies to decide which traffic gets carried, and we also don’t want a bland one-size-fits-all service that is expensive for some and inadequate for others.\nMy idea is that the issue is a bit oversimplified, and will become more clear if we use the right model of who connects to whom, as well as who pays who. This model recognizes three types of players, instead of one or two as we were used to. There is the client ISP, which connects the access devices such as PCs, and the server ISP, which connects the website hosting to the network. They both charge money to the owners of the respective devices. Their interconnection is either direct, or through so called \u0026rsquo;transit providers\u0026rsquo;. They both typically pay the transit provider (unless the ISP is really big, in which case it can probably negotiate free transit with equally big ISPs).\nTo me it seems that the discussion on net neutrality can be framed in the following way. Can the client ISP charge the ISP of a specific server? I.e. can AOL charge Yahoo and not Google, for providing the bandwidth for videos? This would seem odd, as the entire service of hooking up Yahoo and Google is already provided by the transit provider. At the same time, AOL can charge the home customer more for higher speed service. The same holds for the provider of the hosting company. So the question will then be reduced to: can a provider charge another provider with which it does not have a direct business relationship as mentioned above?\n","permalink":"/posts/network-neutrality-who-pays-the-ferryman/","title":"Network Neutrality: who pays the ferryman?"},{"content":"🔎 Type to search through blog posts and book chapters.\n","permalink":"/search/","title":"Search"}]