---
date: '2025-04-16T21:11:32Z'
draft: true
title: 'Applications'
weight: 29
---
An application is roughly a data model plus a certain number of functions operating on that.
Networked applications typically live on servers, but will have a client component.
A word processor is an application. Its data model is formatted text, and the functionality allows you to manipulate that text.
Another example would be gmail, whose data model is a set of messages, and the functionality allows you to manipulate the messages and their flow.

Digital infrastructures are made up of processors, storage and networking. The costs of these change rapidly, but at different rates. Memory is becoming cheaper a lot faster than processing, and network bandwidth prices are dropping slower than that. The cost of humans to manage this technology is dropping slowest, if at all. What this means is that there will be continuing shifts in what the optimal design is for networked computing.

Now for the research questions. How fast is it actually changing? How do we organize this, technically and people wise, in order to control the cost, improve the quality, and speed up the change and development process?  
For example, technology development in this area is very much structured by standards. This allows people to collaborate on the design of system components so that those components then later work together. These standards can be set by a vendor for example, or agreed in a standardization committee. What is the dynamics of that?  
In which way can we best organize the development and in particular the management of large digital infrastructures?
